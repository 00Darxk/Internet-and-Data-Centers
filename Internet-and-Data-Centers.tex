\documentclass{article}

\usepackage{cancel}
\usepackage{amsmath,amssymb}
\usepackage[includehead,nomarginpar]{geometry}
\usepackage{graphicx}
\usepackage{amsfonts} 
\usepackage{verbatim}
\usepackage{mathrsfs}  
\usepackage{lmodern}
\usepackage{braket}
\usepackage{bookmark}
\usepackage{fancyhdr}
\usepackage{romanbarpagenumber}
\usepackage{minted}
%\usepackage{subfig}
\usepackage[italian]{babel}
\usepackage{float}
%\usepackage{wrapfig}
%\usepackage[export]{adjustbox}
\usepackage{contour}
\usepackage[normalem]{ulem}
\usepackage{svg} % to include svg images
\allowdisplaybreaks

\setlength{\headheight}{12.0pt}
\addtolength{\topmargin}{-12.0pt}
\graphicspath{ {./Immagini/} }

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    pdftitle={Appunti di Internet and Data Centers},
    pdfauthor={Giacomo Sturm},
    pdfsubject={Internet and Data Centers},
    pdfkeywords={}
}

\newsavebox{\tempbox} %{\raisebox{\dimexpr.5\ht\tempbox-.5\height\relax}}


\makeatother
\renewcommand{\contentsname}{Indice}
\numberwithin{equation}{subsection}
\newcommand{\tageq}{\tag{\stepcounter{equation}\theequation}}
\AtBeginDocument{%
    \renewcommand{\figurename}{Fig.}
}
\renewcommand{\ULdepth}{1.8pt}
\contourlength{0.6pt}
\newcommand{\myuline}[1]{%
    \uline{\phantom{#1}}%
    \llap{\contour{white}{#1}}%
}
\fancypagestyle{link}{\fancyhf{}\renewcommand{\headrulewidth}{0pt}\fancyfoot[C]{Sorgente del file \LaTeX\space ed ultima versione del testo disponibile al link: \url{https://github.com/00Darxk/Internet-and-Data-Centers/}}}

\begin{document}

\title{%
    \textbf{Internet and Data Centers}  \\ 
    \large Appunti delle Lezioni di Internet and Data Centers \\
    \textit{Anno Accademico: 2025/26}}
\author{\textit{Giacomo Sturm}}
\date{\textit{Dipartimento di Ingegneria Civile, Informatica e delle Tecnologie Aeronautiche \\
Università degli Studi ``Roma Tre"}}

\maketitle
\thispagestyle{link}

\clearpage


\pagestyle{fancy}
\fancyhead{}\fancyfoot{}
\fancyhead[C]{\textit{Internet and Data Centers - Università degli Studi ``Roma Tre"}}
\fancyfoot[C]{\thepage}
\pagenumbering{Roman}

\tableofcontents

\clearpage
\pagenumbering{arabic}

\section{Introduzione: ISPs ed IXPs}

%% yapping 

Gli \textit{Internet Service Provider} ISP o \textit{Autonomous System} sono gestori autonomi della rete che hanno una responsabilità su un certo territorio. Su queste reti indipendenti viaggiano i pacchetti, gli ISP sono infatti responsabili di inoltrare i pacchetti che passano al loro interno per raggiungere la destinazione. 
In totale sono presenti circa 170000 ISP al mondo, alcuni di questi sono pubblicizzate e pubbliche per offrire servizi ad utenti comuni, altri offrono servizi a grandi compagni o altri ISP. 
Questi ISP formano una gerarchia, non dichiarata, che si può inferire, non essendo questi ISP governati da una struttura o organizzazione sovrastante. Alcuni di questi ISP sono privati e non si mostrano, per cui è possibile solamente inferire la gerarchia considerando questi ISP privati. Ogni ISP si cura solamente dei suoi interessi specifici, attraverso i loro clienti, permettono di connettersi ad un prezzo economico con altri servizi o utenti nel loro territorio. Questi ISP pagano altri ISP più grandi per raggiungere obiettivi sempre più remoti, in questo modo si può determinare una gerarchia che parte dagli ISP più piccoli ai più grandi. 

Queste regioni geografiche che identificano i territori di un certo ISP non sono separate, ma sono fortemente sovrapposte, è solamente una divisione logica e parzialmente può essere interpretata come una suddivisione geografica. 

Questi ISP comunicano tra di loro attraverso una connessione privata di rete \textit{Private Network Interconnects} PNI, queste possono essere dei cavi fisici di proprietà degli ISP oppure possono essere affittati, che collegano due router tra questi due ISP. Il costo per questa PNI viene pagato in base ad accordi privati tra i vari ISP ed in base al traffico. Questo è un rapporto commerciale a varie livelli, ci può essere un cliente che paga per utilizzare i servizi di un altro ISP, oppure bilaterale o peer-to-peer, dove i due ISP si scambiano pacchetti destinati all'altro ISP, ed pagano entrambi insieme il costo del PNI. 

Generalmente si paga sul picco di traffico giornaliero. 


Questo processo tuttavia non è più efficiente, con il concetto di economia di scala, invece di stendere fili singoli tra tutti gli ISP, si creano di punti di scambio comuni dove tutti i provider portano una loro macchina ed un filo che la collega alla loro rete, a questo punto per comunicare con altri ISP si crea una connessione logica con uno degli ISP presenti nel punto di scambio. Questo si chiama \textit{Internet eXchange Points} IXP. Questi sono governati da associazioni che mettono a servizio dei propri consorziati questi punti di scambio in modo sicuro. 
Quando si offre un servizio si cominciano ad offrirne di ulteriori, quindi oltre alla comunicazione offrono servizi di housing, di computing, etc. formando i tradizionali \textit{Data Centers}. 
In questi punti di scambio ci sono interconnessioni di diverso tipo, commerciali, peer-to-peer, gratuiti, ma sempre offerti nello stesso punto di scambio. 
Al mondo sono presenti circa un migliaio di questi IXP, in Europa il più grande è ad Amsterdam: AMS-IX. 

La rete di reti non è più una rete di macchine connesse tra di loro, ma coagula considerando questi punti di scambio comuni dove sono presenti delle macchine. Un \textit{Data Center} è uno spazio dedicato contenente computer, risorse di massa e sistemi di telecomunicazione. Questi si trovano generalmente in scantinati, ed i più grandi in zone dove l'energia costa poco o è facilmente procurable, oppure in zone dove la temperatura è pressoché bassa, per diminuire il costo di raffreddamento. In questi data center si brucia una quantità molto elevata di energia. 
Per l'importanza di questi data center, sono costantemente sorvegliati e protetti. Ogni macchina ha una procedura di recupero e sono pubbliche e quindi si assume che chi è in grado di avvicinarsi ad un macchina può effettuare queste procedure di recovery ed entrare in possesso della macchina. Quindi la sicurezza deve essere anche fisica per impedire alle persone di avvicinarsi a questi macchinari. 

C'è una differenza tra l'\textit{hosting} e l'\textit{housing}, nel primo l'hardware è posseduto dal data center, mentre nel secondo l'hardware non è fornito dal data center me viene procurato dal cliente. 
Altri centri invece hanno un solo cliente che è il proprietario, questi generalmente vengono realizzati solo dai più grandi come Google, Microsoft, etc. 


Questa tendenza è nata negli ultimi decenni, quando oltre ad offrire connettività gli ISP cominciarono ad offrire hosting ed housing, creando propri data center. La connettività è ormai diventata un bene di consumo a basso costo, quasi dato per scontato. 
Questi data center possono essere interni ad una singola rete o condivisi tra varie reti. 

Dentro un IXP si può facilmente inserire un data center, avendo già la struttura e l'organizzazione per ospitarli, unendo i router e macchine dei vari ISP a risorse di calcolo offerte dal data center. 

%% !! Cloud

La definizione di \textit{cloud} fornita dal NIST, \textit{National Institute of Standard and Technology}, è caratterizzata dalla possibilità di scalare su richiesta, un accesso a banda capiente, la possibilità di attivare risorse su richiesta, risposta rapida e misurazione accurata. 

I servizi offerti da piattaforme cloud sono IaaS, \textit{Infrastructure as a Service}, macchine virtuali, risorse di massa, firewall, tutti realizzati virtualmente; PaaS \textit{Platform as a Service}, la gestione di macchine virtuali database, risorse; Saas \textit{Software as a Service}, il software che viene eseguito su queste macchine virtuali può essere comprato o affittato direttamente da queste piattaforme cloud. 
Altri servizi specializzati possono offrire calcolo massivi. Alcuni servizi di cloud sono reti pubbliche, altri possono essere privati o ibridi. 
I leader del settore sono AWS, \textit{Amazon Web Services}, Microsoft Azure e Google Cloud. Questi cloud possono popolare diversi data center, AWS si trova su 25 regioni, in questo caso macro-regioni geografiche. Microsoft si trova su più di 60 regioni mentre Google principalmente in America del Nord. 


Quando si compra un servizio su una piattaforma cloud, questo è sparo non necessariamente su uno stesso data center, poiché per trasferire una macchina virtuale è estremamente facile. Le risorse acquistate su piattaforme cloud sono distribuite ed in base alla necessità del gestore possono essere trasferite facilmente. Questo vale sia per macchine virtuali che per la memoria di massa. 

In Europa è stato creato un sistema federato di ISP europei, GAIA-X, per realizzare hub nazionali indipendenti dall'hardware per garantire servizi specificando un modello con garanzia di controllo sulla locazione delle macchine e la strada che percorrono i dati. 



In Italia l'Agenzia per la Cybersicurezza Nazionale ha fondato un cloud marketplace per offrire alla pubblica amministrazione di acquistare risorse cloud da parte di provider qualificati. La CONSIP ha un servizio di supporto per i servizi cloud dedicati alla pubblica amministrazione. 
Inoltre c'è un programma per portare ed abilitare la pubblica amministrazione all'uso dei servizi cloud. 
Questo è previsto dal PNRR, nel primo obiettivo, attraverso una migrazione ad un cloud nazionale PSN, oppure ad un provider certificato. Anche la stessa migrazione ad un altro cloud viene trattato come un servizio senza dover necessariamente conoscere il suo funzionamento tecnico. 

\subsection{PSN: Polo Strategico Nazionale}

%% TODO smt


Questo progetto ha l'obiettivo di creare un grande data center nazionale che fornisca vari servizi cloud. 

I principali servizi offerti dal PSN sono housing ed hosting, cloud IaaS Private e Shared, può offrire cloud pubblica gestita dalla PSN garantendone la sicurezza, utilizzando sistemi offerti da produttori certificati, si può realizzare un sistema ibrido con elementi interni alla rete. 

I public cloud esistenti che parteciperebbero a questo progetto sono Azure, Google Cloud ed Oracle. 

%% cringe

Sulla rete privata del PSN, sul suo hardware, vengono offerti servizi IaaS dedicati e condivisi, CaaS e \textit{Disaster Recovery} (DR) e PaaS, fornendo elementi applicativi e middleware come servizio. 

Servizi di Cloud ibridi vengono gestiti nel territorio nazionale dal PSN, utilizzando un'infrastruttura ibrida utilizzando cloud pubblici di partner commerciali e privati sulla rete del PSN, installati sull'infrastruttura locale. Questo come il Public Cloud PSN Managed ed il Secure Public Cloud garantiscono la presenza dei dati sul territorio nazionale. Per il resto dei servizi cloud, i dati sono localizzati presso il \textit{Cloud Service Provider} (CSP) e non garantisce la \textit{data sovereignty}

L'infrastruttura del PSN è un data center a doppia regione, interconnessa via \textit{Virtual Data Center Network} (VDCN), simulando una stessa LAN, duplicando i dati tra le due regioni. 


Servizi PaaS messi a disposizione da parte del PSN su una piattaforma per erogare elementi applicativi e middleware, astraendo l'infrastruttura sottostante. Questi servizi sono \textit{Database as a Service} (DaaS), verifica dell'identità e gestione degli accessi, big data e servizi AI. 

Analogamente fornisce applicazioni basate su container con servizi CaaS. 


L'accesso a questi servizi avviene solamente tramite la rete TIM, uno dei consorzianti che ha vinto il contratto, questa implementa dei sistemi di sicurezza per garantire che eventuali attacchi non riescano a penetrare la rete interna del PSN, utilizzando dei tunnel per inviare il flusso di dati all'infrastruttura del PSN. %% ??


% Il public cloud PSN managed, sviluppato in partnership con Oracle e Google Clout, viene gestito internamente dal PSN, 

%% ?? idk



I quattro data centers sono collegati su due regioni, tra queste regioni il traffico viene gestito tramite il protocollo \textit{Multi Protocol Label Switching} MPLS, sul backbone IP di TIM. %% descrizione MPLS

Tra DC della stessa regione le VLAN sono trasportate con VXLAN, \textit{Virtual eXtensive LAN}, queste utilizzano espedienti tecnologici per duplicare infrastrutture fisiche utilizzando dei tag per dividere i pacchetti destinati alle varie copie.  
Il protocollo VXLAN permette di connettere reti diverse condividendo pacchetti di livello due tra le reti, trattandola come una singola LAN, trasparente dal punto di vista delle macchine nelle varie LAN. 

\subsection{SPC: Sistema Pubblico di Connettività}

Questo è un bando multi-fornitore, il vincitore del bando ha preso la parte più grande del mercato della pubblica amministrazione, mentre i restanti fornitori hanno ottenuto il rimanente. 


%% cringe af

Questa rappresenta una rete di grandi dimensioni dedicata a connettere le sedi di ogni singola Pubblica Amministrazione tra di loro ed all'internet. 
Offre diversi servizi di trasporto wired e wireless, su rete elettrica, ottica o da parte di dati satellitari. 

Per questi servizi viene definito un \textit{Service Level Agreement} (SLA). 
Ad ogni servizio il fornitore assegna una misura di qualità, il jitter è la distanza tra i vari pacchetti, se è pari a zero questi arrivano tutti allineati. Se la misura della qualità dovesse scendere al di sotto di terminate soglie, sono previsti rimborsi, chiamati ``penali'' all'amministrazione. 
Gli SLA contemplano anche guasti o anomalie. 
Vari ISP realizzano questo SPC, a ciascuno è assegnato un gruppo di PA, l'accesso ad internet è gestito dai singoli fornitori, in base all'esito dell'asta multi-fornitore. 

Gli ISP realizzano le reti delle PA usando MPLS, per comunicare tra di loro su una rete QXN, \textit{Qualified Exchange Network}, attualmente collocato presso gli IXP di Roma (Namex) e Milano (MIX).  

\clearpage

\section{Algoritmi di Instradamento}

Si considerano algoritmi di instradamento solo per infrastrutture fisiche, connessi da reti fisse. 

Esistono due tipi principali di algoritmi di instradamento, \textit{distance vector} e \textit{state packet}. In TCP si utilizza una variante del distance vector. Queste sono due filosofie opposte. 

Si vogliono delle certe qualità da questi algoritmi, si vuole avere algoritmi efficienti, per evitare che il calcolo dei cammini abbia un peso eccessivo rispetto all'instradamento dei pacchetti. 
La tabella di instradamento dentro ai router non viene realizzata con un tabella, ma con strutture ad albero specializzate per avere un accesso il più veloce possibile. 
SI vuole mantenere la maggior quantità possibile ci computazione sull'hardware, inoltre la dimensione dei pacchetti è piccola, e dipende dalla dimensione dei pacchetti ethernet di 1500 byte, definita dal primo consorzio NIX. %% TODO o VIX? idk 
Inoltre le risorse computazionali dei router non sono necessariamente sufficienti per poter gestire la complessità della rete. 
%% riassunto dei pacchetti ethernet standard 1.0, 2.0, 802.3:
Questi pacchetti sono piccoli, poiché essendo in competizione dovevano realizzare schede di rete più economiche dei loro competitori. Utilizzando meno memoria si hanno schede di rete più economiche, e questo rappresenta un errore da parte del consorzio NIX, anche se si è affermato come lo standard per le comunicazioni via filo, è necessario avere operazioni di inoltro estremamente veloci poiché i singoli pacchetti sono estremamente piccoli. 


Un router è diviso nel \textit{data plane} e nel \textit{control plane}, gli algoritmi di routing sono presenti nel control plane, e la tabella di instradamento composta da questo control plane viene inoltrata al data plane. 
Parlando con le altre macchine i protocolli di routing devono determinare la tabella di instradamento. 
Si vuole che questi protocolli siano efficienti, poiché su un router sono presenti molti altri servizi aggiuntivi, quindi il tempo del processore è limitato. 

Inoltre si vuole individuare un cammino ottimo, un cammino che impieghi il minor tempo possibile per raggiungere la sua destinazione. Per determinare l'ottimalità del cammino si utilizzano criteri come il numero di hop o il costo delle linee, talvolta assunto inversamente proporzionale alla velocità. 

Questo cammino se minimizza il numero di hop, minimizza il numero di immissioni da parte dei router che attraversa. 
Un'altra risorse è l'utilizzo delle linee, avendo una banda limitata, non può mandare i pacchetti su una stessa linea, avendo anche un buffer limitato per le singole linee. Il carico corrente della rete è tuttavia difficile da calcolare. 
Se si considerasse solamente il carico della rete, si creerebbe un fenomeno di retroazione causando un oscillazione della rete incontrollabile. Altrimenti si potrebbero scegliere linee con un packet loss minimo. 

In genere si scelgono algoritmi che si basano sul numero di hop. Questi algoritmi devono essere robusti e dinamici, poiché alcune linee riscontrare malfunzionamenti, errori di configurazione da parte di amministrazioni di rete, etc. 
Nello stesso tempo, si vuole essere stabile, non si vuole cambiare il routing durante la trasmissione. Tutti i pacchetti devono essere inviati e ricevuti nello stesso ordine, anche se esiste il livello TPC per riordinarli, nessuna macchina deliberatamente invia pacchetti fuori sequenza. Per questo un'oscillazione del routing non è accettabile, poiché grava sul livello TPC, aumentando il tempo necessario per sistemare questi pacchetti. 

Si è realizzato un protocollo inter-dominio che oscilla in continuazione, dato che il suo effetto non era completamente compreso. Per cui è possibile realizzare esperimenti dove la rete diventa instabile. 


Il traffico può essere classificato, quando entra in una rete di un ISP, per determinare se si tratta di traffico utente generico o mission critical o privilegiato o VoIP. 
Inoltre questi algoritmi devono essere equi, nessun nodo deve essere privilegiato o danneggiato. 

L'ultimo criterio è l'economicità, si vuole ridurre ic osti di configurazione e manutenzione dei protocolli di routing. 


Questi criteri sono talvolta contrastanti, e bisogna scegliere l'algoritmo migliore per un dato caso d'uso. 



Si possono classificare questi algoritmi in statici e dinamici. GLi algoritmi dinamici applicano un instradamento in funzione della topologia e del carico della rete, mentre algoritmi statici hanno applicazione ristretta poiché prendono decisioni indipendenti dallo stato della topologia della rete. Questi algoritmi statici vengono utilizzati in casi semplici. 
La configurazione manuale delle macchine è una configurazione statica, questa è sempre presente anche in piccole parti in ogni rete. Se in una rete sono presenti topologie ad albero, queste non hanno bisogno di una configurazione dinamica. 
Invece per topologie magliate è opportuno utilizzare un algoritmo dinamico, poiché al taglio di un link o allo spegnimento di un nodo, bisogna ridistribuire il carico e riorganizzare la rete in modo veloce, senza compromettere l'operabilità delle altre macchine. 

%% TODO immagine rapporto tra routing statico e dinamico

Uno di questi algoritmi statici è il \textit{flooding} che consiste nell'inoltra ogni pacchetto a tutte le interfacce connesse al router. 

Gli algoritmi dinamici possono essere successivamente divisi in routing isolato, dove ogni router decide senza comunicare con altri router; il routing centralizzato, dove un router centrale determina la scelta migliore, questa strategia è rimasta per molto tempo sottovalutata; il routing distribuito, questa è la strategia corrente della rete, dove ogni router informa i propri vicini le informazioni note. 
Nel distance vector i router informano i propri vicini rispetto alla condizione globale, mentre nel link state packet i router inviano alcuni pacchetti verso tutta la rete che raccontano della topologia locale. 

Algoritmi di routing isolato sono \textit{hot potato} e \textit{backward learning}, l'algoritmo utilizzato dai switch o bridge, che determinano in base alla provenienza dei pacchetti le destinazioni possibili rispetto alle varie interfacce. 


Per comunicare sulla rete è richiesto un indirizzo di rete associato ad una scheda di rete, ed una netmask associata. Una netmask indica da un indirizzo qual è la parte di rete e quale di host. Per mandare il pacchetto apparentemente non serve, ma è necessaria per determinare la rete dentro cui la macchina è presente e può raggiungere direttamente. 

Si controlla prima se la macchina destinazione è direttamente raggiungibile, inviando un pacchetto MAC di livello due, poiché non è necessario un pacchetto di livello 3. 

Ogni macchina almeno in questo senso ha meccanismi di routing. Inoltre per tutti i destinatari che non sono locali è presente un default gateway, il primo indirizzo disponibile nella rete. 
Inoltre è necessario conoscere l'IP del DNS per risolvere gli indirizzi. 
Una macchina avendo queste quattro informazioni può navigare in rete. 

Anche un router ha interfacce e netmask differenti per ogni rete su cui è connesso. Queste vengono inserite nella tabella di instradamento e rappresentano le reti direttamente connesse, queste non possono essere rimosse dalla tabella di instradamento, per configurazione. 

In ogni router è presente una parte di routing statico, che rappresenta questa configurazione di interfacce. 

Se il routing è completamente statico questa tabella contiene per ogni nodo da raggiungere le linee da usare, compilata dall'amministratore di rete, chiamato ad intervenire in presenza di guasti. 
Una variante quasi-statica consiste l'amministratore fornisce più alternative in ordine di priorità. 


Se il destinatario è direttamente connesso, bisogna determinare l'indirizzo MAC della scheda di destinazione con una richiesta ARP, oppure verso il next hop. Questi pacchetti di livello due vengono creati localmente nelle varie reti locali che attraversa, mentre rimane invariato il pacchetto di livello tre, eccetto per il campo ttl ed il checksum che viene ricalcolato. 



Una versione del flooding chiamato selective flooding viene utilizzato come sotto-protocollo di altri protocolli per inoltrare solo su un insieme di linee selezionato, scartando pacchetti troppo vecchi, scartando un pacchetto  al suo secondo passaggio per un nodo. 


Nel routing isolato ogni \textit{intermediate system} calcola in modo indipendente le proprie tabelle. L'hot potato invia il pacchetto alla linea con coda più breve, di interesse solo teorico. 


Nel \textit{backward learning} dai pacchetti in ingresso vengono determinate le macchine raggiungibili su quella linea, IEEE 802.1D a livello due, questi protocolli non aprono pacchetti di livello superiore. Per effettuare il backward learning è importante che non siano presenti maglie, altrimenti un pacchetto potrebbe entrare da più interfacce, accoppiandolo ad un algoritmo per il calcolo dello spanning tree. 
Può essere raffinato aggiungendo un campo che specifica il costo di un cammino, incrementandolo ad ogni hop. Si possono mantenere alternative ordinate. 
Quando la destinazione è ignota si effettua flooding. Per la sua necessità di avere una struttura ad albero non è presente in internet, dato che non è possibile tagliare arbitrariamente connessioni. 


Il routing centralizzato è un meccanismo di routing gestito da un'entità centrale, supponendo l'esistenza di un \textit{Routing Control Center} (RCC) che conosce la topologia della rete, questo spesso non è realistico. 
È rimasta per molto tempo teorica, ma recentemente sono apparse esigenze di trasferire un grade volume di traffico tra due macchine. Quindi un'autorità centrale tramite dei protocolli, \textit{Software Defined Networking} (SDN), determina la topologia della rete in quel momento e stabilisce la strada migliore per poter trasferire quella grande quantità di dati. Si può scegliere di effettuare routing guidati da protocolli noti o imporre flussi di traffico. 


Nel routing distribuito non esiste un RCC, ma tutte le funzionalità sono da tutti gli is, seguendo lo stesso paradigma, comunicando con i propri vicini. Il primo distance vector invia ai propri vicini una parte della tabella di routing, una proiezione rimuovendo colonne relative a macchine locali. Mentre il link state packet invia informazioni sui suoi vicini verso il resto della rete. 


\subsection{Algoritmi Distance Vector}

Ogni is invia una tabella detta distance vector, ad ogni is adiacente. Questa tabella contiene la parte essenziale della sua tabella di instradamento, da cui vengono omessi dettagli locali. 
Ogni is ricevendo queste tabelle dei propri vicini ricalcolano la tabella di instradamento integrando queste informazioni. 

Le destinazioni vengono apprese con un meccanismo di passa-parola. Inizialmente la tabella di instradamento non può essere vuota, altrimenti rimarrebbe vuota ad ogni iterazione dell'algoritmo. La prima informazione da inserire sono gli indirizzi direttamente connessi, a distanza di un singolo hop, nel data plane. Queste informazioni vengono prese nel control plane ed inviate ai suoi vicini. Questi effettuano lo stesso inviando i propri indirizzi direttamente connessi. 



Ogni destinazione nella tabella è corredata dal costo del cammino, dalla destinazione all'is stesso. Questo vengono calcolati dal distance vector ottenuto dai vicini, sommando i costo della linea di ingresso da cui è stato ricevuto. 


Molte aziende e produttori cercando di vendere di più aggiungono caratteristiche e modificano questi protocolli. Il protocollo di distance vector originario appartiene a Cisco. 

Per passare l'informazione bisogna inviare i vari distance vector, questi possono essere inviati secondo vari criteri. Possono essere inviati periodicamente oppure ad ogni modifica della tabella di instradamento. 

I nodi adiacenti da aggiornare vengono appresi in base a protocolli di servizio appositi, oppure sono ignoti, inviando i pacchetti di distance vector in multicast. 


Il tempo necessario affinché tutte le macchine conoscano tutte le altre è abbastanza lungo, fino a decine di secondi, un tempo estremamente lungo per ingegneria delle reti. Non si può intasare la rete inviando distance vector molto grandi, con più di 1000 nodi. 
Si preferiscono protocolli come SPF per reti più dinamiche. 


Per ogni linea il distance vector è composto da due colonne, una prima che contiene la rete e la seconda il costo per raggiungerla. 
I costi delle linee vengono sommati, e vengono inseriti nella tabella di instradamento dell'is le connessioni alle reti di costo minore, per ogni LAN determinata. 

Questi is non devono essere sincronizzati altrimenti periodicamente tutte le macchine smetterebbero di funzionare per mandare e ricevere i vari distance vector. Per questo il tempo da attenere per inviare i distance vector vengono sfasati di una certa quantità. Sono presenti inoltre meccanismi per garantire che questo processo non sia sincrono. 


Il problema cruciale che si crea con i distance vector è il \textit{count to infinity}, riescono a reagire rapidamente a buone notizie, e lentamente alle cattive notizie. 

Una buona notizia può essere l'aggiunta di una nuova rete, questa propaga il suo distance vector e l'informazione viene propagata sull'intera in un tempo relativamente breve. 

Se questa connessione viene tagliata, il vicino non può aggiornare la sua tabella di instradamento. Queste macchina avrebbero raggiunto la rete ora disconnessa passando per macchine altre macchine adiacenti. Poiché non possono eliminare questa entry nella tabella di instradamento, ad ogni nuovo distance vector la distanza alla rete disconnessa incrementa continuazione, tendendo all'infinito. Si crea una specie di eco. 

Una buona notizia arriva a distanza $k$ in $k$ passi. Le cattive notizie invece si propagano in un tempo che è funzione del valore convenzionalmente attribuito ad infinito. Questo valore si attribuisce alla lunghezza del cammino più lungo più uno. 


Se un componete ha inviato la rotta al vicino, e questo gliela rimanda, non dovrebbe considerarla, questo fenomeno si chiama \textit{split horizon}, ma non sempre è efficace, in reti circolari, l'eco propaga in un'unica direzione perpetuamente provocando il fenomeno del \textit{count to infinity}

% Questo protocollo inerentemente ha questo problem brutto perché è scemo

Il valore ottimale di infinito per ogni rete dipende dalla sua topologia, e dal modo in cui l'eco viene propagato. Bisogna determinare il costo del cammino più lungo possibile nella rete, ed al massimo prende tutti i router presenti. Non tutte le reti ammettono un cammino che prede tutte le reti. 

%% TODO img add propagazione count fo infinity

Quando il costo di un cammino supera il valore di infinito nella tabella di instradamento, viene rimossa e non più condivisa. Restituisce pacchetti ICMP \textit{destination unreachable} se si prova ad accedere alla rotta. 

Se a rete è connessa è possibile dimostrare con il modello di Bellman e Ford che l'algoritmo converge sempre ad una soluzione ottima, anche se all'inizio le tabelle di instradamento provengono da una situazione diversa. 
Il numero di passi è lineare se la metrica è il numero di hop. 
Negli distanze condivise tra i router ci sono due elementi, le buone notizie e le cattive notizie. 
Ci sono vari modi per valutare l'efficienza di un algoritmo di instradamento. 


Si può utilizzare il numero di passi come metrica per determinare l'efficienza dell'algoritmo distance vector. In una rete dove ci sono $n$ nodi ed $m$ link, la metrica è relativa solo al numero di hop, una buona notizia si propaga tra i nodi più lontani al massimo $n-1$ link in $n-1$ passi, analogamente per una brutta notizia, attribuita al valore $n$. 

Un altra metrica è il lavoro svolto dai router, questi inviano ad ogni passo $m$ distance vector, dove $m$ è il numero massimo di linee interno al router. Ogni tabella ha al più $O(n)$ righe, in ciascuno dei passi il router spende tempo $O(mn)$, dato che la convergenza richiede tempo per propagarsi, nel caso peggiore di $O(n)$ passim ogni router calcola per un tempo $O(n^2m)$. 

\subsection{Algoritmi Link State Packet}

Questi algoritmi utilizzano un pacchetto che viene chiamato \textit{link state packet} (lsp) che descrive lo stato dei link di ogni IS. Un router su questa mappa si calcola l'instradamento ottimale per ogni rotta. Usano un algoritmo di calcolo di costo minimo, in questo caso usa Dijkstra. Il router compone da queste informazioni una tabella di instradamento per il valore del next hop per ogni rotta. 
La mappa della rete viene costituita usando questi pacchetti speciali, qui sorge un problema, poiché i link non sono componenti attivi, al massimo un router può descrivere le macchine presenti intorno all'IS. Questi pacchetti vengono mandati ai vicini e si suppone che i vicini li propaghino in selective flooding da ogni IS ad ogni altro IS della rete. 

Se viene modificata la topologia, aggiorna la sua mappa e la propaga nella rete. Ogni IS conserva i un database il lsp più recente, per aggiornare la topologia della rete, questi link hanno dei costi e per questo si utilizza un algoritmo come Dijkstra invece di un BFS. 
Questo database è importate sia identico tra tutti gli IS, le informazioni devono essere propagate, tenendo solo l'ultima copia del lsp. Se la topologia non cambia non è necessario inviare periodicamente l'intero database. 
Si tratta di un protocollo molto più silente, è sufficiente un unico pacchetto lsp per aggiornare il database correttamente tra tutti gli IS della rete allo stesso stato. 


Algoritmi distance vector inviano pacchetti molto grandi per calcolare direttamente la tabella di instradamento, mentre algoritmi link state packet inviano pacchetti piccoli con l'obiettivo di calcolare la mappa della rete, e da questa calcolare la tabella di instradamento. 
A differenza deu distance vector, questo algoritmo può gestire reti con migliaia e migliaia di nodi, convergendo rapidamente. 


%% !! ALGORITMI DI DIJKSTRA
Si considera un insieme $V=\{1,\cdots,n\}$ di vertici numerati, con archi orientati. Si indica con $A(i)$ l'insieme dei vertici $j$ per cui è presente un arco orientato $(i,j)$. Per ogni arco è presente una metrica $a_{ij}\geq0$, questa è infinito se l'arco è assente. La somma di un cammino è la somma delle metriche degli archi attraversati. 

La distanza corrente dal vertici 1 al vertice $i$ è $d[i]$, la distanza minima tra questi è $m(i)$, si definisce $S$ l'insieme dei vertici in cui il cammino corrente ha distanza minima $d[i]=m(i)$. 


L'algoritmo di Dijkstra calcola il costo minimo tra il primo nodo ed ogni altro nodo della rete, questi vengono inseriti in $S$ per valori crescenti della distanza da 1. All'inizio contiene solo il primo elemento. Nel secondo passo, per ogni nodo $i$ dal successivo all'ultimo $n$ si pone $d[i]=a_{1i}$. In seguito si ripete finché $V\setminus S$ non è vuoto scegliendo un nodo in questo insieme tale che $d[i]$ sia minimo, aggiungendolo ad $S$, e per ogni nodo $j$ adiacente ad $i$, si pone $d[j]=\min(d[j],d[i]+a_{ij})$. 

\begin{gather*}
    S=\{1\}\\
    \forall i\in\{2,\cdots,n\}\rightarrow d[i]=a_{1i}\\
    \mbox{se}\,\, V\setminus S\neq\emptyset,\,\, i\in V\setminus S \mbox{ t.c. } d[i]=m(i)\implies S=S\cup\{i\},\,\,\forall j\in A(i):\,\, d[j]=\min(d[j],d[i]+a_{ij})
\end{gather*}

%% !! LEMMA DELL'INVARIANTE

Se $d[v]=m(v)$ per ogni nodo $v\in S$, allora quando $i$ viene aggiunto ad $S$, anche $i$ ha per $d[i]=m(i)$. 
Supponendo per assurdo che $d[i]>m(i)$. Sia il cammino minimo $p$ tra 1 a $i$ necessariamente $|p|=m(i)<d[i]$. Sia $j$ l'ultimo nodo di $p$ e $k$ il nodo seguente. Allora deve essere $k\neq i$ altrimenti l'algoritmo avrebbe computato $d[i]=|p|=m(i)$, poiché il sottoinsieme di un cammino minimo è anch'esso un cammino minimo. 

%% !! DIMOSTRAZIONE DEL LEMMA
$d[k]=m(k)$, ovvero il cammino è ottimo poiché è calcolato da $d[j]$, per ipotesi $d[j]=m(j)$ ed l'arco $(j,k)$ è utilizzato da $p$. %% TODO finire



Supponendo che in una rete ci siano $n$ nodi e $m$ link. 
Un'implementazione semplice richiede tempo $O(n^2+m)=O(n^2)$, in questa si scorrono tutti i nodi ad ogni passo, mentre un'implementazione più sofisticata scorre tutti i nodi ordinati per costo minore, senza doverli scorrere tutti ha una complessità $O(n\log n+m)$. 

Calcolati i cammini minimi, questi formano un albero ricoprente dei cammini minimi, ogni IS crea la sua tabella di instradamento in base a questo albero. Può essere che i cammini minimi calcolati non coincidano perfettamente, poiché possono esistere più cammini ottimali tra due nodi. 

ALcuni algoritmi gestiti da CISCO utilizzano cammini tra due nodi dello stesso costo, \textit{Equal Cost Multi-path}, in questo modo può distribuire il traffico su più rotte. Questi router hanno due entry per ogni rotta, dividono il traffico in queste linee, se non viene gestito bene i pacchetti vengono disordinati ed il livello TCP non è in grado di riordinarli. Per gestirlo correttamente prendono gli indirizzi IP del sorgente e destinazione e ne calcolano l'hash ad un bit, se è uno lo mandano su una rotta, altrimenti lo mandano all'altra. In questo modo instradano interi flussi su rotte diverse. 


Poiché i link sono inerti, non è possibile comunicare direttamente con questi. Esiste un protocollo di \textit{neighbor greetings}. Questo si utilizza per mantenere aggiornate la adiacenze, inviato periodicamente su tutte le interfacce. Quando un IS rileva una modifica della topologia invia un lsp per propagare la modifica. 

Ogni pacchetto lsp ha un numero di versione relativo al router, il pacchetto non cambia durante la sua propagazione con un processo di selective flooding. Si utilizza questo numero di versione per verificare se è già stato ricevuto un pacchetto con quel numero di versione, in caso non compie alcuna azione, altrimenti se il pacchetto ricevuto ha una versione più recente aggiorna il suo database e lo propaga, oppure se ha una versione precedente, trasmette quello posseduto al mittente, per allinearlo con i database. 

Una LAN su cui si affacciano diversi router si presta male ad essere modellata come un grafo, uno dei router si prende l'onere di rappresentare la LAN come uno pseudo nodo, e gli altri vedranno la LAN come una stella. 
% isan al gaib
Per questo alcuni interlocutori sono dei link, sono pseudo nodi che impersonano la connessione. Ogni connessione ha un \textit{designated router} che rappresenta la LAN al resto del mondo, ogni altro router vede la LAN come se fosse attiva. 

\subsection{Protocolli di Routing}

Il termina gateway è un termine antico che indica il router utilizzato per accedere all'internet da una LAN. 
Alcuni protocolli sono detti \textit{Interior Gateway Protocol} (IGP) all'interno di una stessa LAN, questi sono RIP, OSPF, IS-IS. Altri protocolli si chiamano \textit{Exterior Gateway Protocol} (EGP) che sono utilizzati all'esterno delle LAN, questi sono EGP e BGP. 
Gli IGP vengono utilizzati per aggiornare le tabelle di instradamento all'interno del sistema. 
I protocolli usati per trasferire informazioni di routing tra diversi domini amministrativi passano per BGP, il protocollo standard esterno. 

\subsubsection{RIP}

Il \textit{Routing Information Protocol} (RIP) è un IGP introdotto nel TCP/IP nel 1982, implementa l'algoritmo distance vector con invio del distance vector ogni 30 secondi. 
%% questi due strati sono legati tra loro poiché TCP usa indirizzi IP per individuare processi diversi. eg indirizzo IP processo mittente e processo destinatario
Usa una sola metrica, basata sugli hop, con un numero massimo di hop permetti pari a 15, sono reti piccole. Non vengono considerate altre metriche, tuttavia è compatible con ogni macchina, e converge sempre. 

Nella prima versione venivano inviati in broadcast, da RIPv2 i pacchetti vengono inviati alla lista di subnet, ottenute dal proprio indirizzo IP e la netmask. 

I pacchetti di richiesta chiedono ai vicini i rispettivi distance vector, i pacchetti di risposta trasferiscono i distance vector richiesti. 

Vengono inviati ogni 30 secondi, aggiungendo un piccolo offset random, per evitare che la rete si sincronizzi globalmente. 

\subsubsection{OPSF}

L'\textit{Open Shortest Path First} (OSPF) è un protocollo non proprietario, standardizzato dall'IETF, probabilmente il più diffuso IGP per TCP/IP. Abbastanza stabile come protocollo, con le ultime variazioni per IPv6 avvenute nel 2008. 
Sfrutta l'algoritmo link state packet, pensato per scalare molto. 
È organizzato gerarchicamente, dividendo la rete in aree connesse dell'intera rete, dove il routing che avviene all'interno di una stessa area, non è necessariamente uguale a quello interno ad un'altra area. Per comunicare tra queste aree si usano router contenuti da più di un'area, per fare da ponte tra queste aree. I router che si trovano sulla backbone hanno una visione di tutto il resto del mondo, mentre quelli  nelle parti marginali hanno una visione molto ristretta.  

Ci potrebbero essere configurazioni di nicchia, per tecnologie speciali che non corrispondono esattamente a questa suddivisione. 
Generalmente ogni area ha una topologia invisibile alle altre aree, i router di frontiera sono gli unici a cui si può accedere per comunicare con l'interno dell'area. 


Questo protocollo assegna ogni interfacce ad un'unica area. Un router può essere interno se ha interfacce su una stessa area, backbone se ha almeno un'interfaccia backbone, area border se ha almeno due interfacce diverse su due aree diverse, e AS boundary o frontiera se ha almeno un'interfaccia verso l'esterno, altri domini amministrativi. 


%% TODO add img aree e suddivisione router

Ai router di frontiera vengono iniettate rotte, come se fossero locali, dentro al protocollo OSPF, ed inietta sulla sua rete locale queste rotte prendendosi la responsabilità di inoltrarli eventuali messaggi alle altre aree. 
%% TODO add protocollo IS-IS

\subsubsection{Coesistenza di Protocolli Diversi}

I protocollo di rete permettono la consegna di un pacchetto da una qualsiasi macchina che si trova in internet ad un'altra qualsiasi macchina che si trova in internet. Per effettuarlo è necessario uno schema di indirizzamento, questo viene gestito dal protocollo di livello tre. Molti protocolli hanno deciso di essere più capillari, individuando solamente un'interfaccia in una porzione specifica della rete. 
Si determina il formato del pacchetto di rete, questo contiene il pacchetto di trasporto di livello quattro, che non può esser eletto e gestito da questi. 
Offrono un servizio di consegna ai protocolli del livello di trasporto. 
I servii di consegna per livello tre sono a commutazione di pacchetto. 

Un protocollo di routing fa specifico ad uno specifico protocollo di rete. 

In generale sono presenti più protocolli di rete e quindi più protocolli di routing diversi contemporaneamente presenti su una stessa macchina. Su una stessa macchina possono essere presenti più protocolli di routing, anche relativi allo stesso protocollo di rete. 

Queste macchine devono permettere a più protocolli di condividere. Se sono presenti due protocolli di rete le macchine vengono dette dual-stack. Gli ES hanno due pile protocollari, in corrispondenza di due librerie API. Le applicazioni devono scegliere quale pila da usare. 

Gli IS sono in grado di instradare pacchetti relativi ad entrambi i protocolli di rete. 

La filosofia è ``navi nella nebbia'', i diversi protocolli convivono in modo totalmente isolato. 
Per questi motivi non è possibile effettuare una transizione completa da IPv4 a IPv6, la rete ha un'inerzia elevata, dato che le macchine devono poter operare su tutti questi protocolli. 

Tipicamente le tabelle di routing sono separate ed i database dei distance vector sono invisibili l'uno dall'altro. Tutte queste tabelle di instradamento vengono a determinare un mix di tutte le tabelle di instradamento. 
Ma questi protocolli utilizzano metriche tra di loro non confrontabili, tipicamente l'amministratore di rete decide in che modo gestire questi vari protocolli. 

L'amministratore può governare queste rotte per determinare in che modo i pacchetti tra i vari protocolli comunicano l'un l'altro. Le rotte trasferite vengono viste dal protocollo ricevute come rotte statiche. Iniettare dentro un altro è un'operazione delicata, se si inserisce un protocollo che contiene tutte l'internet, la sa solo dall'iniezione, ma pubblicizza di poter raggiungere tutto l'internet creando un buco nero, se viene diffusa fuori. 


Due ISP che comunicano usando due protocolli di routing differenti, utilizzano dei router appartenenti ad entrambi i loro domini. Questi possono comunicare attraverso router contenenti rotte iniettate da entrambi i protocolli. Questo può pubblicizzare le rotte apprese da entrambi i protocolli. 
Il fatto che non ci sia una chiara divisione delle competenze su questo router è un problema di natura gestionale. 
%% TODO smt
Se la rotta attraversa diversi domini, questo processo di iniettare rotte ignorando le metriche, è un processo non ottimale se attraversa molti domini. 

\subsubsection{BGP}

Per evitare di avere questi problemi di carattere amministrativo, invece di cogestire una macchina e separare le competenze, ci si inventa una struttura dove tra le due rete si condivide un filo e la cogestione di un filo è più semplice. 

Il protocollo EGP è adottato tra domini amministrativi diversi. Su queste connessioni viene adottato un solo protocollo. Può prediligere le rotte che attraversano meno domini amministrativi. 
Consente l'implementazione di politiche commerciali, non tutte le rotte possono essere attraversate da un dominio amministrativo, le rotte che attraversano uno specifico dominio possono essere preferite. Alcune di queste scelte sono dovute a motivi economici come accordi tra ISP. 
Persegue la trasparenza rispetto agli IGP. 

Le informazioni apprese tramite EGP sono ridistribuite in un IGP, quando sono raggiungibili.
Una rotta che passa per EGP deve avere metriche di distanza, e non può essere calcolata dal protocollo IGP interno. Questa distanza deve passare attraverso router altri router di frontiera. 
Queste informazioni sono condivise agli altri router di frontiera dello stesso dominio amministrativo tramite connessioni TCP. 


Il primo protocollo EGP ha cominciato ad essere usato nel 1984. Utilizza un protocollo simile al distance vector, ma solo con indicazione di raggiungibilità. 
Molto elementare, funzionava esclusivamente con reti ad albero. spf

%% TODO 
Usa lo strato di trasporto connesso per scambiarsi informazioni tra strati BGP, sulla porta 179. Tipicamente prova a connettersi in maniera incrociata, e si prova a fare connessione sia come client che come server, la prima che instaura una connessione la crea. In connessioni TCP non c'è differenza tra client e server, le connessioni sono essenzialmente peer-to-peer. Una connessione può essere attiva in un senso e non in un altro. 


Questo protocollo BGP è uno dei protocolli più intriganti e complessi, consente di effettuare tante operazioni ed è difficile da conoscere. Richiede una conoscenza molto profonda della rete, le configurazioni su questo protocollo è molto costoso.

\subsubsection{Routing Inter-dominio}

%% TODO join
%% !! BGP
Tutti gli ISP utilizzano un protocollo di comunicazione intra-domini, che sia IS-IS, OSPF o RIP, sotto c'è comunque un instradamento IP tradizionale, come per SDN. 

Ogni organizzazione è formata da una collezione di router e LAN con una sola amministrazione. Un algoritmo di routing può essere utilizzato per aggiornare le tabelle di instradamento. 

Quando più organizzazioni uniscono le proprie reti, si crea l'internet, aggiungendo zone di demarcazione, le LAN aggiuntive per connettere diverse organizzazioni. 
Per avere una connettività globale è necessario che vengano passate informazioni di routing attraverso queste zone di demarcazione per far comunicare le diverse organizzazioni. 
Si vorrebbe poter aggiornare le tabelle di instradamento di tutte le macchine. 

Si potrebbe realizzare un singolo algoritmo di instradamento per gestire tutte le reti, ma non è realizzabile anche con un algoritmo scalabile come OSPF. 
Si potrebbero aggiornare le tabelle manualmente, ma questo non è affidabile. 
Altrimenti si possono usare algoritmi per aggiornare automaticamente le tabelle di instradamento. 


Agli albori della rete si usava un unico protocollo e le configurazioni di ciascuna macchina influiva sulla configurazione complessiva della rete. 

Questa soluzione è tecnicamente difficile, e lento a convergere, sarebbe difficile da implementare e rilasciare su più organizzazioni con risorse vastamente diverse. 

Aggiungere rotte statiche è un'opzione alternativa, ma sono difficili da aggiornare e mantenere. 

L'unica ipotesi praticabile è utilizzare un protocollo diverso per comunicare tra diverse organicazioni. Questo protocollo ignora l'interno e guarda solo alle zone di demarcazione. Sono le macchine di frontiera ad annunciare che al loro interno è presente una certa rete. 
È una tecnica di routing statico, ma nel senso opposto, in modo da indirizzare il traffico verso la propria zona. 
Se non viene trovato il destinatario all'interno, non è un problema poiché il traffico non avrebbe trovato altre rotte possibili. 

Le connessioni tra i vari router di frontier è gestito attraverso connessioni TCP, chiamate \textit{peering}. 
In questo modo si semplifica l'instradamento considerando intere organizzazioni come singole destinazioni. Poiché è necessario comunicare tra i router di frontiera, se questi si trovano in una stesa organizzazione, servono connessioni TCP interne. 
Si determina in questo grafo virtuale la soluzione al problema di routing. Dopo che la rotta per obiettivi remoti è stata decisa dai router di frontiera, questi iniettano le rotte esterne all'interno della loro organizzazione. 

Il protocollo \textit{Border Gateway Protocol} ha l'obiettivo di rendere disponili ed aggiornate le tabelle di instradamento.. con informazioni di routing inter-dominio. 
Questo è un protocollo tra i più complessi ed importanti. Può prendere in considerazione anche vincoli commerciali, preferenze locali, priorità, problemi legali, ecc. BGP è stato introdotto nell'89 ed adottato per la prima volta nel 94. Con IPv4 è stato aggiornato nel '94 e migliorato nel '98. 
La versione del 2006 di BGP include la compatibilità con il protocollo IPv6. 

% È un protocollo complesso, non sono definite le scorciatoie e l prassi. 

BGP è usato da chi è connesso ad uno o più ISP, dai provider del transito, da ISP che scambiano traffico su IXP o NAP, o clienti con reti di grandi dimensioni. Generalmente organizzazioni comprano un pezzo dello spazio di indirizzamento sulla rete. 

BGP si fonda sul concetto si sistemi autonomi, \textit{Autonomous System} (AS), questi rappresentano una rete sotto una singola amministrazione. Controllati ad un unico gestore, amministratore. Sono società dichiarate per il protocollo e vengono identificati da un numero da 32 bit, aumentato dall'iniziale 2 byte. 
Questo identificativo viene chiamato \textit{Autonomous System Number} (ASN). Alcuni di questi sono dedicati all'uso privato, poiché se si ha una rete molto grande su più continenti è utile fare routing in base a policy, come fossero policy commerciali, e quindi bisogna utilizzare BGP, organizzando la rete come se fosse composta da AS diversi. 
Gli identificatori da 0 a $2^{16}$ sono dedicati ad uso pubblico o privato. 

Il numero 23456, indica una comunicazione con una macchina che ancora non conosce l'esterno, viene usato per convertire un numero da 16 bit a 32 bit, contenendo nel pacchetto regole per convertirlo. 



L'organizzazione centrale IANA che gestisce l'assegnazione di indirizzi IP li concede ad organizzazioni regionali. Queste risorse vengono assegnate quando necessario. 
Questi registri regionali assegnano anche l'ASN globale ad un AS. Per comunicare con un certo provider con numero privati bisogna chiederlo direttamente all'ISP. 

Non c'è nessun controllo di alcun tipo, eccetto controlli di indirizzi IP uguali. 

% Nel grado degli AS più si diminuisce il valore più sono comuni, nasce da esigenze commerciali non filtrate da alcuna regola 

BGP permette lo scambio di informazioni solo se è attiva una sessione di peering. 
Questa è una connessione TCP sulla porta 179, tra due router di frontiera. 
Poiché questi possono appartenere ad uno stesso AS, si distinguono in connessioni e-BGP e i-BGP, \textit{external} e \textit{internal}, questi devono essere direttamente connessi in connessioni e-BGP, mentre può non essere diretta in i-BGP. La connessione TCP rimane viva nonostante i cambiamenti di routing e la perdita di connettività. 

%% TODO I accorgimento

In e-BGP i pacchetti vengono inviati con un TTL pari ad uno. Invece in i-BGP è possibile propagare le informazioni di instradamento da un bordo al bordo opposto di un AS. 


BGP apprende l'esistenza di destinazioni remote attraverso e-BGP, con annunci che possono essere affermativi. Per ogni meta remota viene selezionato un percorso migliore tra tutte le alternativa, applicando le varie politiche di interesse. 
Questa viene indicata nella tabella BGP e solo questa viene propagata all'interno e può essere propagata ad altri vicini BGP esterni. 


La notifica delle LAN interne non è automatica, viene richiesta manualmente, e rappresenta sia una forza che un limite per BGP. Permette di annunciare solo LAN specifiche, mentre se si commettono degli errori è possibile impedire ad altri utenti di connettersi a certe LAN. 

Le connessioni di peering tra due AS potrebbero essere attive per anni. 

I pacchetti di annuncio contengono nel path una sorta di distance vector, dove sono presenti tutti gli AS attraversati, in questo modo gli echi vengono affrontati a priori. Se un AS riceve un pacchetto contenente il suo ASN, lo scarta per non creare rotte cicliche. 

Gli annunci vanno in un verso, ed il traffico uscente va nel verso opposto, poiché gli annunci sono rotte statiche che vengono inoltrate. 

\clearpage

\section{Algoritmi e Protocolli di Livello Due}

\subsection{Spanning Tree Algorithm: STP}

Questo protocollo di instradamento è pensato per essere utilizzato in una rete locale, dove sono presenti switch, quindi opera sul livello due. 
Gli switch compilano automaticamente le proprie tabelle di instradamento in modo backward learning, su questo fanno filtering. Questo funziona fino a quando non è presente un ciclo nella rete. 
Gli hub invece operano su pacchetti di livello uno, si sincronizzano sul preambolo e lo accorciano e con un tempo di ritardo molto basso lo inoltrano completamente. 
Se è presente un ciclo in hub, è impossibile individuare un ciclo. 
Gli switch invece sono macchine di tipo store and forward, è conveniente avere cicli nella rete per evitare fallimenti dovuti a guasti, ma non devono essere attivi altrimenti non funzionerebbe il meccanismo di apprendimento degli switch. La LAN si deve organizzare per chiudere questi cicli. 

Con dei cicli uno stesso pacchetto può percorrere il ciclo e quindi uno switch non può sapere su quale interfaccia effettivamente si trovi l'host mittente. 

Molti switch venivano venduti con lo spanning tree disabilitato, per cui era molto semplice creare cicli accidentalmente ed inviare perpetuamente pacchetti. 
Per evitare questi cicli bisogna bloccare temporaneamente delle porte, queste continuano ad ascoltare, ma non inoltrano i pacchetti. L'algoritmo di spanning tree è tra i più famosi poiché reti con switch sono molto comuni. 
Questo algoritmo rende la rete un albero e mantiene ridondanze ed è in grado di rispondere ai cambiamenti della rete. 
Questo albero ha una radice che viene chiamato \textit{root bridge}, alla fine della configurazione delle porte vengono messe in \textit{blocking}. L'amministratore della rete può configurare minimamente secondo alcune necessità. 
Questo algoritmo è robusto, efficace, efficiente ed è realizzato per garantire un basso costo di banda. Viene descritto nello standard IEEE 802.1D. 

Si usano dei pacchetti chiamati \textit{Bridge PDU} o BPDU, sono tra i rarissimi pacchetti che non usano lo standard ethernet 2.0, ma IEEE 802.3, dentro questi pacchetti non è neanche presente il codice per indirizzare il protocollo IP successivo. Sono pacchetti devo sono state rimosse tutti i superflui. 

Questo protocollo essere veloce, flessibile ai cambiamenti della topologia e di facile uso. 

Lo standard chiama LAN il dominio dove vengono collegati gli switch, un insieme di domini di collisione. 
Si assume che ognuna LAN possa contenere un numero arbitrario di macchine. 

L'algoritmo parte da uno scenario con queste LAN e quando ci sono dei cicli li aprono, senza chiudere nessuna LAN. Ogni bridge ha un identificatore, gli spareggi si fanno sull'id più basso. Anche le porte hanno un identificatore, analogamente più basso meglio è. 
Hanno un valore di costo per ogni LAN, definito dalla velocità della LAN. Per cui lo standard viene aggiornato per aggiornare questa tabella dei costi quando vengono rilasciate nuove tecnologie da prestazioni più elevate. Se questi costi vengono messi a zero, l'algoritmo non necessariamente converge. 

Le macchine devono essere raggiungibili da qualsiasi altra macchina senza che nessuna LAN viene isolata. 
Si vuole creare un albero di cammino a costo minimo, ma questo non è vero per ogni cammino individuato. Possono esserci cammini a costo minore per due specifiche macchine, ma che sono stati bloccati. 

L'id del bridge, \textit{bridge-id}, è rappresentato da due byte che indicano la priorità, di default si trova a metà dell'intervallo possibile \texttt{80:00}, i restanti sono corrispondenti all'indirizzo MAC della prima porta del bridge. Il valore di priorità si può modificare per rendere alcuni bridge più probabili ad essere scelti come radice. 

L'id della porta, \textit{port-id}, è costituito dalla concatenazione di varie parti, un byte di priorità, spesso il valore di default è \texttt{80}, ed un byte corrispondente al numero della porta sul bridge, dato un contatore delle porte sul bridge. 

Il costo di una LAN è gestito da una specie di distance vector. Non si contano gli hop, ma la somma dei costi, ogni tecnologia ha un costo inversamente proporzionale alla sua velocità. Su ogni porta viene specificato questo costo, in ingresso. 

Questo algoritmo è diviso in fasi, che possono essere realizzate in un singolo pacchetto. Nella prima fase viene eletto un bridge da radice, si identifica per ogni bridge una porta radice, la più conveniente da lasciare accesa. Si determinano le porte designate per ogni LAN, una porta di un bridge viene scelta come quella che connetterà la LAN all'albero. 
Vengono poi bloccate tutte le porte ridondanti nell'ultima fase, tutte quelle inutilizzate dall'albero, non designate e non radici. 

Sono previsti due tipi di BPDU, di configurazione, che contiene le informazioni necessarie per l'algoritmo dell'albero ricoprente e pacchetti di notifica del cambiamento della topologia, che non contengono nessun dato. 
I pacchetti LLC hanno un indirizzo di sorgente e destinazione pari a \texttt{0x42}, questi sono contenuti in pacchetti MAC con sorgente l'indirizzo della porta mittente, e con destinazione l'indirizzo multicast \texttt{01:80:c2:00:00:00}. 

I campi importanti sono l'identificatore della radice dell'albero ricoprente, tutti riportano qual è la radice. La distanza dalla radice, l'identificatore del bridge mittente e l'identificatore della porta mittente. 

%% TODO add img campi

Nella prima fase si deve capire qual è il bridge da radice, all'inizio ogni bridge si crede la radice ed invia come primo parametro il suo stesso id, ed invia questi pacchetti. Nel tempo quando un bridge legge un pacchetto con un campo radice con un id minore, si accorge di non essere la radice e propaga questa informazione nei suoi pacchetti. In questo modo la rete converge ad uno stesso bridge radice. 

Inoltre per configurare il costo dalla radice, all'inizio viene posta a zero, poiché si crede la radice, se arriva un pacchetto con campo radice minore, utilizza il costo di questo pacchetto incrementato con il costo attribuito alla porta ricevente. 

Questi pacchetti vengono inoltrati modificando i campi di uno stesso pacchetto, modificando se necessario il campo radice, aggiornando il costo, e sostituendo l'id dello bridge e della porta mittente. 

Questo algoritmo è perfettamente deterministico, sono presenti criteri di spareggio affinché sia convergente ad uno bridge radice specifico. 
Quando arrivano due pacchetti da due bridge diversi a parità di radice, si sceglie quello a costo minore, altrimenti si sceglie il pacchetto inviato dallo bridge con id più basso. 
In caso questi vengano mandati dallo stesso pacchetto, inoltra il pacchetto con id di porta più basso. 

Alla fine di questi spareggi c'è sicuramente un bridge radice, e le porte dei bridge che ricevono questo pacchetto configurazione diventano le root port dello bridge. 


Nella terza fase bisogna identificare le LAN, uno dei bridge su ogni LAN deve mantenere una porta aperta che viene chiamata designated port. 
Questa è quella che invia i pacchetti di configurazione con costo più basso, a parità di questo, il bridge di id più basso, altrimenti la porta ad id più basso. 

Nell'ultima fase tutte le porte root e designated vengono messe in stato di forwarding, mentre tutte le altre vengono messe in blocco. 
Tuttavia si continuano a mandare BPDU anche dalle porte bloccate. Per questo la suddivisione in fasi non è propriamente corretta.  


Nel momento in cui un bridge rileva un cambio di topologia genera dei pacchetti di topology change che raggiungono la radice e vengono propagati a tutti gli altri bridge nella rete. 
Questi pacchetti vengono inviati fino a quando la radice non invia un pacchetto che conferma di aver ottenuto questa informazione. 
A questo punto tutti i bridge abbassano i valori di timer del protocollo in risposta temporanea all'instabilità della rete. 

%% TODO 

\subsection{VLAN}

%% TODO add 9/10/25

\subsection{Software Defined Network}

Questo approccio centralizzato è ritornato di moda recentemente. 
Questa tipologia di algoritmi dinamici di instradamento prevede un routing controllato da un centro che elabora le informazioni disponibili, e decide l'instradamento nella rete. 
Questi algoritmi sono utili in reti piccole, e non è affidabile in reti di grande dimensione, con traffico intenso intorno al nodo di controllo. 

A causa di questi problemi è stato sempre scarsamente adottato. 
Si è creata una fondazione ONF nel 2011 dedicata alla promozione e adozione di SDN. 

La definizione di SDN è riportata nella RFC 7426, è un approccio programmabile di reti che supporta la separazione dei piani di controllo e di inoltro attraverso interfacce standardizzate. 
QUestaQUesta computazione viene realizzata su di una macchina centralizzata. 

Le prime idee risalgono al 2004. 

Divide il routing ed il processamento del traffico, quindi il control ed il data plane. 

Le funzioni del control plane vengono realizzate in un server che è in grado di determinare per ogni flusso di traffico specifico un cammino nella rete, questo percorso può essere configurabile dall'amministratore della rete. 
Le funzioni del data plane rimangono distribuite. 


Il controllo centralizzato vuol dire che una macchina deve poter comunicare con tutti. Si suppone sia presente una linea di conversazione diretta, estranea alla rete. Questo protocollo viola la separazione tra il livello due ed il livello tre. 

Si assume che sia presente questo canale di comunicazione. La parte di control plane, distribuita tra le macchine ora viene spostata su questo controllore. L'instradamento viene definito da questo. Si applica a delle reti che sono locali, di una singola amministrazione. l'operatore di rete non interviene sulle macchine modificando la configurazione, questo operazioni sono troppo costose su reti complesse. 

Il numero di switch, link e macchine virtuali in un datacenter è considerevole. 

L'ONF è un'organizzazione che promuove standard aperti, chiamati \textit{OpenFlow}. L'ultima versione dello standard è la 1.5.1 uscita nel 2015, la versione 1.6 è disponibile solamente ai membri di ONF. 
Molti produttori, ISP e OTT, grosse reti di telefonia che offrono anche servizi di altro tipo, fanno parte di ONF. 
Cisco ha la sua implementazione di OpenFlow, chiamata Cisco ONE, \textit{Open Network Environment}. 


Altre attività di standardizzazione sono IETF, ITU-T, IEEE. 
%% ??

Le applicazioni potenziali sono molteplici, si possono realizzare applicazioni in virtualizzazione  di middleware. Oppure routing ottimizzato per certe tipologie di traffico. 
Si possono realizzare servizi specific per certe applicazioni. 

Il controller parla fisicamente con un API che chiamano southbound diretto verso gli elementi della rete, un'altra comunicazione chiamata northbound è orientata verso applicazioni di rete per determinare i requisiti dei vari servizi proposti. 

Questo protocollo si basa sul concetto di flusso, i pacchetti vengono classificati ed attribuiti ad un flusso, definito sulla base di diversi criteri, la porta, l'indirizzo MAC o IP o altre informazioni contenute all'interno del pacchetto. 

Lo switch inoltra il traffico seguente entry in una tabella di flussi. SDN separa il control plane dal data plane. Il controller esegue il software, anche algoritmicamente complesso su un hardware general purpose. 

Le macchine per l'instradamento si comportano sia come router che come switch, in bae al loro comportamento, quando utilizzano l'indirizzo MAC si comportano come switch, quando inoltrano pacchetti si comportano come router, vengono chiamati \textit{datapath} per identificarli. 

La comunicazione tra il controller ed i datapath avviene tramite lo standard OpenFlow. 
La tabella dei flussi aiuta a smistare il traffico di questo switch. 
Nel momento in cui uno switch riceve il primo pacchetto di un flusso, può effettuare una richiesta ad il suo controller per determinare il flusso di questo pacchetto. Le entry vengono quindi inserite dinamicamente nella tabella. 

Lo switch si occupa solo dell'inoltro dei pacchetti secondo queste istruzioni, si occupa del data plane, mentre il controller si occupa del control plane. 

%% TODO flussi di traffico 
Ogni switch ha uno o più tabella di flussi usate per inoltrare i pacchetti, una tabella è composta da una flow entry, una tripla di \texttt{match}, \texttt{action} e \texttt{stats}. Il primo controlla il pacchetto e determina se esiste un entry corrispondente in base a vari indirizzi o dati contenuti nel pacchetto. L'azione da svolgere per quel pacchetto può essere di inoltrare ad una data porta, oppure inviarlo al controller, oppure operare come uno switch o un router. Queste azioni sono molte e rendono questo protocollo molto versatile. 


Queste entry possono essere distribute con due tempi di timeout, \textit{idle} e \textit{hard}. Se c'è un flusso che non si presenta per un certo periodo questo viene cancellato in tempo idle. Mentre l'hard timeout è indipendente, impone di scartare il flusso dopo che è passato. 

Il controller è un'entità software che deve conoscere l'intera rete in modo dinamico, producendo flow entries ed inviandole alle macchine. 
I tipi di messaggi principali sono \textit{PacketIn}, \textit{PacketOut} e \textit{FlowMod}. 

Il pacchetto PacketIn viene inviato al controller quando uno switch non riesce ad effettuare match sulla sua tabella di flussi. 
Questo può essere inoltrato per intero al controller, che può guardarlo completamente, oppure più semplicemente prende l'header, di default i primi 128 byte. 
In questo caso il controller riceve anche l'id del buffer nel quale il pacchetto viene memorizzato in attesa della risposta. 

Il messaggio PacketOut può contenere un pacchetto modificato, usato dal controller per istruire allo switch l'invio di un singolo pacchetto. Non necessariamente sono inviati in risposta ad un PacketIn. Quando sono in risposta indicano ad uno switch il flusso da usare, altrimenti l'azione è specificata dall'id del buffer nel quale lo switch ha dichiarato di conservare il pacchetto. 
Se non è in risposta ad un PacketIn, allora contiene un pacchetto ad-hoc creato dal controller, può essere usato per ricostruire la topologia. 

Il messaggio FlowMod invia una flow entry, può essere in risposta ad un datapath. PUò avere una priorità, quindi le tabelle di flussi potrebbero essere ordinate per priorità creando una gerarchia, per ordinare meglio il traffico. Per un certo periodo c'è stat una grande ricerca per inserire le flow entry e creare una tabella più piccola con meno flow entry per avere più prestazioni. %% non sono cosa ho scritto. 

Se la regola è già presente, allora la nuova regola sovrascrive la vecchia. 
Con questo pacchetto si possono modificare, rimuovere flow entries, oppure notificare al controller l'istante di eventuale rimozione, o può richiedere una verifica. 


Il controller deve avere una mappa della rete, per farlo utilizza dei pacchetti appartenenti al \textit{Link Layer Discovery Protocol} (LLDP), questi appartengono al livello 2 link state, non hanno bisogno di pacchetti IP, questo protocollo già esistente, mantiene questi pacchetti all'interno della rete. Questi sono spediti periodicamente per esplorare la rete. 
Il controller fa handshake con tutti gli switch, e questi dichiarano al controller l'elenco delle loro interfacce. 
Usando un FlowMod manda a tutti gli switch una regola che li istruisce su come trattare i pacchetti LLDP, tutti questi pacchetti ricevuti da uno switch devono essere rimandati dentro ad un PacketInt
Dopo aver ricevuto questi pacchetti, il controller invia a ciascun switch, e per ciascun sua porta, un pacchetto LLDP, in un messaggio di tipo PacketOut, specificando nell'action che il pacchetto LLDP deve essere inviato sulla specifica porta. Uno switch diverso che riceve il pacchetto LLDP, inviato da uno altro switch su una certa porta, lo spedisce al controller in un pacchetto PacketIn. 
Questi pacchetti non possono passare attraverso eventuali switch o link, poiché essendo al livello 2 rimangono nel link. 
In questo modo il controller determina che una certa porta di uno switch è connessa ad una certa porta di un altro switch. Ottiene per ogni link una risposta simmetrica per identificare la topologia. Nei pacchetti PacketIn viene specificata la porta di ricezione. 

%% TODO add img sta cosa sus

In base a quanto detto finora ogni rete ha un solo controller, ma ci sono soluzioni distribuiti con controller organizzati in maniera gerarchica, per gestire il traffico in maniera distribuita, dove ogni controller controlla un numero limitato di switch, a cui delega di distribuire regole ad altri switch. 

Anche negli switch ci sono limitazioni, non hanno un buffer illimitato, né tabelle abbastanza grandi. È comunque presente una rete sottostante con i loro protocolli di instradamento, su queste è possibile costruire una rete SDN. 

%% TODO discussioni finali, qualità, ecc. 

Questo garantisce grande libertà per la gestione di una rete. 

\subsection{Network Address Translation}

Lo spazio di indirizzamento IPv4 è limitato, con 32 bit di indirizzi si hanno $2^{32}$ indirizzi diversi, circa quattro miliardi. 
Questo spazio non è allocato nel modo più efficiente, poiché gli indirizzi sono raggruppati in LAN, i cui indirizzi possono essere solamente potenze di due. 
Inoltre per molto tempo si erano esclusivamente con classi, A B e C, con 8, 16 e 24 bit di prefisso. 

Per risolvere questo esaurimento si sono sviluppate varie soluzioni. Il primo è l'indirizzamento per barre e non per classi, in modo da frazionare delle reti in subnet, chiamato CIDR, \textit{Classless Inter-Domain Routing}. Un'altra soluzione semplice è la diminuzione dell'assegnazione di indirizzi. 
Ci sono state delle campagne di renumbering su grosse organizzazioni che avevano \texttt{/8}, alcuni organizzazioni con barre anche abbastanza grandi non si sono mai esposte verso la rete. 
Si può utilizzare diffusamente l'indirizzamento privato, con blocchi di indirizzi privati non validi in internet e non instradati, ma validi per la LAN. 
Un'altra soluzione è il DHCP, \textit{Dynamic Host Configuration Protocol}, che assegna dinamicamente indirizzi privati o pubblici per uso temporaneo. 
Il NAT, \textit{Network Address Translation} è un meccanismo per la condivisione di indirizzi pubblici da parte di diverse macchine che hanno indirizzi privati. Non si possono instradare direttamente i pacchetti per una destinazione remota, quindi devono essere tradotti gli indirizzi mittenti per poter ritornare al router di inoltro, che sostituisce nuovamente l'indirizzo privato. 
Si può moltiplicare ancora con il PAT, \textit{Port Address Translation}, che opera a livello di porte. 
La soluzione definitiva è il passaggio a IPv6, con uno spazio di indirizzamento di 64 bit. 

Un altro problema che si è dovuto affrontare è l'esaurimento delle memorie dei router, queste sono molto più costose di memorie dedicate ad applicazioni general purpose. 
Soprattutto grazie a CIDR si sono moltiplicate le entry abbordo delle macchine, e quindi questo problema è peggiorato ulteriormente. 

%% TODO add cronologia morte di ipv4

\subsubsection{CIDR}

CIDR consiste nell'adozione della notazione barra per la suddivisione di reti in sottoreti. 
Rende possibili il subnetting, ed ulteriori frazionamenti ricorsivi su una stessa LAN. Inoltre è stato utilizzato per delle campagne di supernetting per riunire insieme diverse LAN IPv4 che condividono lo stesso instradamento, riducendo la dimensione delle tabelle di instradamento dei router. 
Queste operazioni hanno effetti opposti sulle dimensioni delle tabelle di instradamento sulla rete. 


\subsubsection{Private Address Allocation}

Definiti nell'RFC 1918, alcuni indirizzi sono dedicati ad utilizzo privato, non indirizzabili nell'internet. Nessun pacchetto può avere questi pacchetti come indirizzo di destinazione, ma può essere presente come indirizzo sorgente. Perché se dentro una LAN si ha uno schema di indirizzamento privato, quando arriva ad una macchina intermedia se avviene un qualche errore deve mandare un pacchetto ICMP a quell'interfaccia ed avranno un indirizzo privato come sorgente. Se questo intermediario è nella LAN, avrà un indirizzo privato come campo destinazione. 

Questi sono sottratti agli indirizzi globalmente unici di internet. Questi possono essere utilizzati anche senza essere connessi alla rete, riutilizzando la pila protocollare TCP/IP in un ambiente chiuso, sfruttando le sue capacità. 
Gli indirizzi IP configurati in queste reti sono indirizzi privati, univoci solo all'interno della rete. 

Gli indirizzi privati sono 10.0.0.0/8, da 10.0.0.0 a 10.255.255.255, equivalente ad una classe A. 
RFC 1918 consiglia di utilizzare due numeri casuali per l'indirizzo 10.0.0.0/8 al posto dei due zeri centrale per evitare conflitti in caso due reti vengano unite in futuro. 
172.16.0.0/12, da 172.12.0.0 a 172.31.255.255, equivalente a 16 reti di classe B. 
Infine 192.168.0.0/16, da 192.168.0.0 a 192.168.255.255, equivalenti a 256 reti di classe C. 

\subsubsection{NAT}

Utilizzando questi indirizzi privati per comunicare sulla rete è necessario convertirli in indirizzi validi in internet. 

Il NAT ha uno scopo più ampio, di collegare due interfacce su due \textit{realm} diversi. Un realm è una rete dove gli indirizzi IP hanno un significato univoco. In queste reti non ci sono ambiguità sui numeri IP. Internet è un realm. 

Diversi realm possono avere indirizzi sovrapposti, ogni rete che utilizza indirizzi privati è un realm a sé stante. 
Il pacchetto in transito deve essere convertito per essere compatibile tra i due realm. I router realizzano una comunicazione trasparente dal punto di vista degli ES. 
I realm attraversati potrebbero essere molteplici. 
La macchina che fa NAT possiede un blocco di indirizzi IP, anche annunciati se parla BGP. 
I pacchetti diretti ad un indirizzo pubblico in questo blocco viene mandato a questo router. 

Data un ES nella LAN gestite da un router NAT, con un indirizzo privato $x$. In condizioni normali il pacchetto attraverserebbe il router senza modifiche, ma per poter accedere alla rete bisogna sostituire l'indirizzo privato dal pacchetto. Allora il NAT sceglie tra uno dei suoi indirizzi pubblici $y$ e lo sostituisce a $x$, salvando su una tabella di traduzione, \textit{NAT table}, quest'associazione $x:y$. Dopo aver modificato il pacchetto lo inoltra sulla rete. Al ritorno del pacchetto questo viene tradotto nuovamente, sostituendo nel campo del destinatario $y$ con $x$, l'indirizzo privato. 
Quest'associazione dopo aver terminato la conversazione può essere gestita secondo varie discipline. In alcuni NAT si usano gli stessi indirizzi pubblici per una macchina privata, oppure per ogni connessione di macchine private, oppure lo assegna per un certo periodo di tempo. Ci sono molte politiche di gestione, ma rimane comunque alla base quest'associazione tra un indirizzo pubblico ed uno privato. 

Questo può consentire di migrare da un provider ad un altro, invece di effettuare renumbering si può inserire un NAT. 

Il router gestisce la corrispondenza o \textit{binding} tra gli indirizzi dei due realm tramite una tabella di traduzione. QUesto binding può essere statico, dove la tabella viene  configurata manualmente, oppure dinamicamente, in cui la tabella cambia nel tempo a seconda del traffico, e gli indirizzi pubblici vengono assegnati alle macchine che ne hanno bisogno. 

In una rte locale gli apparecchi sono classificati in base a diverse esigenze di connettività, in base questi criteri si individuano macchine che non richiederanno mai NAT, alcune macchine che lo richiederanno solamente come client, ed altre macchine che lo richiedono completamente, queste possono offrire servizi raggiungibili dall'esterno. 

Bisogna modificare sia il pacchetto IP che TCP. 
Bisogna modificare l'indirizzo destinazione e mittente, ed anche l'header checksum. Anche se la maggior parte dei router non controlla questo campo, poiché vuole aumentare la velocità a cui può inoltrare i pacchetti, e quindi sospendono il controllo del checksum. Anche se non è controllato, deve essere ricalcolato.    
Mentre nel pacchetto TCP bisogna ricalcolare il checksum, poiché viene calcolato anche sui campo campi del pacchetto IP. 

\subsubsection{PAT}

Poiché bisogna avere un numero elevato di indirizzi pubblici per effettuare il NAT, spesso si preferisce il PAT, chiamato anche \textit{IP Masquerading} o \textit{Network Address and Prot Translation} (NAPT). 
Questo consente a molte macchine con indirizzamento privato di utilizzare lo stesso indirizzo pubblico, si può diminuire il numero di indirizzi pubblici assegnati ad un unico router, fino ad un singolo indirizzo pubblico. 
È il sistema operativo ad assegnare una porta, quando realizza una socket, si può influire su questa scelta, ma dal lato client non si ha alcun interesse per questo. 
In questo modo però si cancella la porta effettiva utilizzata del router. Quando si usa più di un indirizzo IP pubblico si parla anche di multi-PAT. Effettuando la traduzione l'indirizzo pubblico è necessariamente l'unico indirizzo pubblico disponibile. Sulla tabella NAT quindi vengono specificate le porte. A questo punto non si hanno più problemi di scalabilità. 
Nel pacchetto TCP bisogna modificare le porte di ingresso ed uscita e ricalcolare la checksum. 

Queste due tecniche NAT e PAT sono ampiamente utilizzate, ma violano il principio end-to-end, definito nell'RFC 1958, che afferma che lo stato di una connessione deve essere gestito solamente dagli ES, e non può essere condiviso con le macchine intermedie. Il livello di trasporto si assume faccia comunicare due macchine, in modo trasparente rispetto ai livelli sottostanti. 
Questo ha effetti sulla connettività end-to-end. 

I protocolli che menzionano gli indirizzi IP non funzionano correttamente come FTP, per ricostruire la connessione bisognerebbe ricalcolare tutti i campi ed i sequence number che dipendono dal cambio delle porte ed indirizzi IP. Inoltre la sostituzione degli indirizzi devono essere coerenti in ogni frammento. 
I DNS devono rispondere in due modi diversi per le macchine interne ed esterne, per le prime i nomi privati devono corrispondere agli indirizzi privati mentre quelli pubblici ad indirizzi pubblici. 
La necessità di ricalcolare vari campi riduce notevolmente le prestazioni di router con NAT e PAT abilitato. 

\subsubsection{DHCP}

Il protocollo DHCP assegna dinamicamente ed autonomamente gli ES di una rete. È un'alternativa alla configurazione manuale, distribuendo indirizzi pubblici o privati di un insieme di macchine. 
Può essere utilizzato per configurare utenti temporaneamente attivi sulla rete. 
Le configurazioni distribuite dal DHCP contengono almeno l'indirizzo IP e l netmask, e gli indirizzi del default gateway e del server DNS. Queste sono le informazioni che consentono ad un host di afferire ad internet. 

Un server DHCP ha una serie di indirizzi pubblici o privati, molto spesso sono fissi, il server risponde solo ad alcune macchine in base al loro indirizzo MAC, abilitato dall'amministratore. 
L'assegnazione di una configurazione è temporanea, per un prefissato intervallo di tempo breve. 

Questo protocollo è diviso in quattro fasi. Il protocollo prevede un DHCP DISCOVER, un client manda in broadcast in cui annuncia che non ha una configurazione, il server, o i server, DHCP sulla LAN offrono una possibile configurazione con un DHCP OFFER. Il client in base a queste configurazioni accetta esplicitamente una di queste configurazioni con un pacchetto DHCP REQUEST. Il server conferma l'assegnazione temporanea con un DHCP ACK. 

Viene effettuata una discovery all'avvio di una macchina, quando scade un'assegnazione o quando richiesto dall'amministratore. In mancanza di una risposta viene iterata ogni cinque minuti. Il pacchetto DHCP viaggia su UDP. 

Più server possono rispondere contemporaneamente allo stesso client, che sceglie una delle possibili configurazioni. Le richieste essendo broadcast non attraversano i router, ma un router potrebbe essere configurato come proxy DHCP ed inoltra la richiesta ad uno specifico DHCP remoto. 

\clearpage

\section{BGP}

\subsection{Scalabilità di BGP}
%% TODO move to kathar?
Su BGP il problema della rumorosità è risolto dal \textit{route refactors}, inoltre ci sono problemi di scalabilità con per realizzare le policy, tramite route map. Si vorrebbe esprimere preferenze su ogni prefisso, ma questo non è possibile con le route map. Si possono risolvere con le \textit{communities}. 


%% !! ROUTE REFRESH

Il route refresh è un meccanismo che risolve il problema di modifica delle policy. 
Quando viene modificata una policy, il router deve ricompilare tutte le rotte di instradamento. Il router potrebbe richiedere dai suoi vicini tutte le rotte, in un \textit{hard BGP peer reset}, ma questa possibilità comporta un lavoro notevole e non garantisce la continuità del servizio. 
Altrimenti quando si ricevono gli annunci dai vicini, si mantengono in memoria, ed avendo una copia di tutto in memoria, si può ricalcolarsi tutto, \textit{soft reconfiguration}. 

Entrambi hanno dei vantaggi e svantaggi. L'hard reset consiste nel ricreare buttare giù tutti i peering e riattivarli, e dopo aver ricalcolato le rotte, vengono ri-annunciate con effetti che riverberano sulla rete. 
Invece di consumare risorse di calcolo, si consumano risorse di memoria per la soft reconfiguration. 


La route refresh, descritta in RFC 2918, mantiene attivi i peering BGP, e chiede ai suoi vicini di ri-annunciare i prefissi, sfruttando la memoria dei vicini invece di usare memoria aggiuntiva propria. 
Impatta solo i prefissi affetti dai cambi di policy, e facilita il cambiamento di policy non distruttive. 
Inoltre, non è richiesta configurazione aggiuntiva, tutto ciò che viene negoziato dai router è automatico. 


%% !! NEXT HOP

In generale il next hop coincide con l'interfaccia di peering del router BGP. QUando la rotta viene annunciata con iBGP, il BGP canonico prevede che la rotta rimane la stessa interfaccia remota. Quando viene annunciata fuori, il next hop diventa di nuovo l'interfaccia di uscita. È un attributo che canonicamente ha sempre l'interfaccia di uscita dell'ultimo AS da cui è uscita. 

Quando un router deve inserire una rotta BGP nel data plane una rotta verso un IP remoto, non appartenente allo stesso AS. Il next hop è l'indirizzo su cui viene eseguito ARP, ma possiede un next hop remoto, deve quindi determinare a quale interfaccia vicina inviare il pacchetto. 
Il router esegue un lookup sulla rete dov'è presente l'indirizzo del next hop. Per inserire la rotta sulla tabella di instradamento quindi inserisce il valore di next hop della rotta appena trovata. 

L'iBGP che compila la tabella di instradamento prima che BGP inietti le rotte di instradamento, deve iniettare tutte le rotte esterne, altrimenti non sarebbe possibile effettuare il recursive lookup. In generale queste non servono, poiché protocolli IGP non si interessano di queste, ma sono necessarie per iniettare rotte BGP. 
Per risolvere questo problema, si può inserire una clausola che impone di cambiare il next hop ad ogni passo, anche se ci si trova in uno stesso AS. In questo modo non bisogna portare in IGP tutte le rotte interne:
\begin{minted}{bash}
    neighbor x.x.x.x next-hop-self    
\end{minted}

Altrimenti si possono configurare peering iBGP su indirizzi di loopback. Questi possono essere aggiunti arbitrariamente, anche con indirizzi globalmente unici. Il pacchetto indirizzato all'interfaccia di loopback, risale al livello IP della macchina che lo riconosce come proprio e lo elabora. 

Si può usare uno schema di enumeratone semplice nelle loopback per tutti i router. Questi diffondono sul protocollo IGP dei prefissi unici /32. Fino a che il router ha un'interfaccia attiva, è raggiungibile. Invece di usare un'interfaccia vera è possibile mantenere la connessione indipendentemente dallo stato delle sue interfacce. Questo è estremamente comodo anche in configurazione, le loopback vengono usate come identificatori di router. Tutti gli altri IP sono accidentali e non è necessario memorizzarli. 

Quando si realizzano dei peering, non si realizzano tra due interfacce vera, ma tra interfacce di loopback, che non cadano a meno che non viene disattivato l'intero router. Le sessioni iBGP non dipendono neanche dallo stato della rete interna. Fino a che l'AS è connesso, possono comunicare tutte le macchine. 
Tuttavia, bisogna forzare l'indirizzo di peering, con quello di loopback, e non l'indirizzo dell'interfaccia da cui esce il pacchetto:
\begin{minted}{bash}
    neighbor x.x.x.x update-source y.y.y.y    
    neighbor x.x.x.x update-source lo:z    
\end{minted}
Questo comando accetta un indirizzo IP o il nome di un'interfaccia. 

%% !! ROUTE REFLECTORS

Questo non toglie che il numero di peering BGP non scali, rimane quadratico. Poiché devono essere in full mesh, in modo che non rimbalzino annunci BGP costantemente. 
\textit{Route reflectors} è una soluzione semplice, descritta in RFC 4456. Un route reflector è un router come gli altri, questo computa delle rotte, esattamente come un router BGP, e seleziona le sue best e le inoltra ai suoi vicini con una particolare policy. 

Ogni macchina è connessa ad un unico stesso router, chiamato route reflector, questo quando riceve degli annunci, decide qual è il migliore e lo invia a tutti. Il comportamento da parte dei router di frontiera è buona, tutti ottengono la scelta migliore. Il route reflector si comporta come uno specchio che riflette rotte specifiche. 

Esiste un route reflector che si comporta come server, una macchina BGP standard, con una serie di client che sono i router di frontiera. 
Alcuni peering iBGP diretti possono sopravvivere e possono diminuire la latenza in caso il route reflector sia troppo lontano. 

Per sostenere la scalabilità si può creare una full mesh di route reflector, dove ogni annuncio compie un singolo rimbalzo. Tra loro sanno che stanno comunicando tra route reflector. 
Quando un route reflector riceve un annuncio tra un client o un non client, seleziona la rotta migliore, se la riceve da un client, la rimanda a tutti i client ed ai suoi non client. Se invece viene da un non client, si suppone che tutti gli altri route reflector la sappiano già, e la manda verso i suoi soli client. 

Si può scalare ulteriormente aggiungendo un altro livello di route reflector. Ciò che è importante è avere una full mesh solo al livello superiore. È possibile avere connessioni aggiuntive, per tollerare una ridondanza, un client potrebbe avere più server, ma non è necessario creare un albero. 

Ad ogni livello gerarchico un roue reflector serve un cluster della backbone, questo può avere due o più router. 

Si crea un problema, poiché connessioni ridondanti potrebbero introdurre dei cicli. Per evitare il campo infinity in BGP si è introdotta la full mesh, e per evitare i problemi della full mesh si sono introdotti nuovamente dei cicli. 


La soluzione è una specie di as-path, l'idea è quella di avere un attributo BGP che si memorizza l'ID di ogni router attraversato. 
Si vuole un attributo che porti tutti gli ID dei router attraversati, in modo che chi riceve un annuncio con il suo ID dentro lo scarta come un ciclo. 
Questa attività la devono realizzare i route reflector, non le macchine normali, poiché vedono questo come peering BGP, devono partecipare a questo meccanismo senza saperlo. 
Ognuno si deve comportare in una certa maniera, ma ci sono degli attori inconsapevoli. 
Si realizza allo stesso modo di OSPF, impersonando quei router. 

Il campo originator ID contiene l'ID del route reflector che lo ha generato, la cluster list contiene la lista dei cluster attraversati nella gerarchia dei route reflector. L'identificativo di un cluster viene aggiunto quando viene inviato un annuncio da ruote reflector. 
Se un router riceve una rotta iBGP con il suo ID contenuto nel campo originator ID lo scarta, se invece nell'attributo cluster list è contenuto l'ID del cluster lo scarta. 


Queste connessioni TPC potrebbero non coincidere con le connessioni fisiche, ma si consiglia di seguire la topologia fisica della rete, in modo da non influenzare l'instradamento dei pacchetti. 
Tipicamente la PoP, \textit{Point of Presence} ha due router principali, route reflector, con due cluster definiti sull'intera rete. 


La metrica igp viene considerata nel processo di selezione della best. 
Il passaggio a cluster e route reflector è semplice, con una migrazione facile che non impatta i servizi, riducendo le ridondanze, inserendo un route reflector per cluster. 


%% !! COMMUNITIES

Le communities sono dei meccanismi di scalabilità per permettere ad un insieme di macchine di comportarsi in maniera omogenea. Questo viene realizzato raggruppando insiemi di prefissi in classi o community, sono delle etichette inserite in annunci. Ogni etichetta ha significati diversi. Si possono appiccicare ad annunci in iBGP o eBGP. 

Venne introdotto l'attributo community in RFC 1998, dopo essere descritto in RFC 1997. Se queste etichette non vengono rimosse, rimangono nell'annunciano e vengono propagate in rete. 
È un intero a 32 bit, rappresentato da due numeri da 16 bit. I primi due byte sono il numero dell'AS, si annuncia l'AS che ha deciso il significato dell'etichetta, non necessariamente l'AS che l'ha generato. 
Ogni destinazione potrebbe essere membro di più comunità, si può trattare ogni comunità con un'unica policy, per aggregare più prefissi. 
Si possono realizzare route map sull'etichetta. 

Ci sono delle community abbastanza standard, con il prefisso \texttt{65553}:
\begin{itemize}
    \item \textit{No-export}, rotte da non annunciare ad alcun peer eBGP \texttt{:65281}
    \item \textit{No-advertise}, rotte da non annunciare ad alcun peer BGP, \texttt{:65282}
    \item \textit{No-export-subconfed}, rotte da non esportare fuori dall'AS locale, \texttt{:65283}
    \item \textit{No-peer}, rotte da non annunciare a peer bilaterali, \texttt{:65284} 
\end{itemize}

\subsection{Anomalie di Internet}

BPG è stato progettato intorno al 1994, all'epoca il concetto di cybersecurity non è vivo quanto oggi. È noto che BGP è vulnerabile ad attacchi, e questi sono in molti casi totalmente invisibili agli utenti. 
È estremamente facile modificare l'AS path di un annuncio, per indirizzare il traffico verso il proprio router ed analizzare il traffico, a seguito di operazioni malevole. 

Non ci sono firme digitali o validazione degli annunci, mancano i principi basi delle politiche di sicurezza. Alcuni attacchi BGP sono talmente banali per cui CAIDA, per il dipartimento dell'Homeland Security, monitora BGP per settori critici di interesse. 

Alcune anomali sono BGP leaks, una leak è un prefisso che non dovrebbe uscire da un AS, ma viene annunciato verso l'esterno. Generalmente è un errore, e può trasformare un AS non di transito in un AS di transito. 

Questo avviene in vari modi, alcuni prefissi viaggiano disaggregati per annunciare i prefissi in modo più specifico. 
Il numero di BGP leaks è stimato intorno a qualche centinaio al mese. 

Nell'agosto del 2017 Google annunciò a Verizon rotte apprese tramite link peer-to-peer, diventando transito per 135 mila rotte causando un outage in Giappone. 

Il BGP hijacking consiste nel rubare un prefisso, annunciando un prefisso che non si possiede realmente. Si possono realizzare hijack parziali rubando un sotto-prefisso più specifico, diffondendosi in modo più veloce. Oppure si può realizzare un hijack completo, per far vincere il proprio prefisso aggiungendo determinati attributi. 

L'effetto immediato può essere di deviare il traffico, rimandarlo all'origine, analizzarlo, ecc. 
Ci sono centinaia di attacchi di questo tipo al mese. 

Nel 26 Aprile 2017, rotte appartenenti a più di una dozzina di altri servizi finanziari sono state annunciate da un AS russo. 

Il 12 Dicembre 2017 molti prefissi americani sono stati annunciati da un AS russo generalmente silente. 

Nel Gennaio 2017 l'azienda Telecom iraniana ha annunciato dei prefissi commerciali allo scopo di censurare dei siti web, generando dei leak. 


Ci sono stati vari interception, i dati non sono molto chiari, poiché l'utente non se ne accorge, solo l'AS difficilmente, per cui l'incidenza è ignota. 


BGP outage è quando si perde visibilità di un certo prefisso, non necessariamente è un attacco, spesso è solo sparito. 
BGP è dimostrato che non è stabile, esistono configurazioni per cui la best oscilla in continuazione.  
% bgp=calabrone: non sa di poter volare quindi lui vola

% BGP new upstream un nuovo 
%% TODO add smt 

\subsection{Gerarchia Internet}

Nel mondo reale sono presenti più livelli di astrazione per BGP. 
Esista una gerarchia di AS, in modo che l'operatore che fornisce la connettività possa fornire il proprio servizio, attraverso provider di più alto livello. 

Il customer è un AS e va a pagare il provider, l'AS che fornisce connettività di più alto livello. Queste relazione sono di tipo economico. 

Il secondo tipo di relazione è chiamata peer-to-peer, in questo tipo di relazione due provider circa dello stesso livello si mettono in accordo per scambiarsi traffico gratuitamente. 

Normalmente i costi sono proporzionali alla quantità di traffico passato sul link. Se si riesce a mandare il traffico su un peer-to-peer l'unico costo è quello di manutenzione del link, diviso tra i due peer, e tutto ciò che passa sopra è gratis. 
È il customer a pagare il traffico sul link offerto dal provider, indipendentemente dalla direzione del traffico. 

Da questa base logica si può arrivare al concetto della gerarchia di internet. 
Quando si raggiunge la parte più alta, sono tutti in peer-to-peer in full mesh. 


Ad un provider conviene inviare traffico ai suoi customer, per cui un provider propaga traffico prominente dal suo AS, da un suo customer o un peer, dove ci guadagna, oppure proveniente da un suo provider, supponendo i costi uguali a somma zero, poiché paga il link verso il suo provider. 
In discesa passa tutto ed è conveniente per il provider. 
In salita il customer invia il proprio traffico, ed il traffico proveniente da un suo customer, poiché è il motivo per cui si ha un contratto tra due AS, a somma zero, supponendo i link equamente costosi. 

Ricevendo traffico da un peer, gratis, se lo si inoltra verso l'alto, si ha una perdita quindi non viene inoltrato. 
Analogamente non si manda traffico proveniente ad un provider verso l'alto. 
Il traffico peer-to-peer non permette due hop, poiché si considera anche il costo dell'infrastruttura interna, se questa viene saturata, bisogna aumentarne le prestazioni. Quindi se si facesse passare il traffico peer-to-peer si avrebbe una spesa, quindi non lo si inoltra. 

Il modello customer-provider di BGP viene chiamato \textit{valley free}, poiché nel momento in cui si crea una valle, si realizza traffico vietato poiché comporta una perdita. Questa politica viene implementata dda chi ci perde. 

Fino a che si sale soltanto e si scende soltanto il traffico è accettato. In qualche caso queste catene potrebbero essere mancanti. Non sono permessi peer-to-peer solo se dopo si scende, quindi non esistono percorsi, con un peer-to-peer non alla massima altezza, poiché uno dei due peer ci perderebbe economicamente. 

Le relazioni customer provider sono esclusivamente dei filtri. Il modello economico spesso si associa al modello \textit{prefer-customer}. Se si deve scegliere dove mandare il traffico, si preferisce verso il basso, o in orizzontale, dove non si perde. Mentre come ultima scelta si inoltra verso l'alto. 


La configurazione vera di un router BGP è costituita da una serie di filtri, ed un insieme di route map per settare le preferenze tra i vari AS. 
L'internet non è shortest path, nonostante BGP lo sia in assenza di policy, non sempre lo è nel mondo reale, poiché implementa policy legate anche a rapporti commerciali. 


Una stima realistica degli AS sono 75 mila, ma è difficile da stabilire, poiché viene effettuata su quelli annunciati, non quelli assegnati, che non vengono riassegnati. 


Gli AS in questa gerarchia si dividono in tre tipi, i provider di livello uno sono tutti in una full mesh tra tutti loro, sono tra i 7 ed i 12 ??, non vengono pubblicati gli accordi commerciali, quindi vengono dedotti dagli annunci BGP sulla rete. %% TODO 7k?12k?

Il customer cone di un AS è la parte dell'internet che può raggiungere attraversando solamente connessioni di tipo customer-provider, l'insieme dei suoi customer diretti ed indiretti. Poiché possono essere disgiunti, dovendo offrire la piena raggiungibilità di internet, devono realizzare una full mesh tra i coni dei vari provider. 

Più in alto sono difficili da capire i rapporti, la rete è estremamente densa, con un numero di link molto alto rispetto al numero di nodi. 

La rete di BGP è molto densa ed anche molto piatta, poiché una volta raggiunto tutto l'internet, non è necessario aumentare i peer. 

Il sito asrank è gestito da un'agenzia di ricerca CAIDA, per classificare AS. Questo fa girare un algoritmo una volta al mese per determinare com'è fatto l'internet, realizzando un ranking degli AS per dimensione del cone size. 
RIPE offre molti strumenti, tra questi RIPEstat fornisce statistiche aggregando informazioni provenienti da BGP. 
Lo strumento chiamato \textit{looking glass}, portali web pubblicati da certi AS, per vedere lo stato BGP del router, realizzando delle query. Si possono fare dei ping, ed eseguire comandi limitati. 
Questi sono convenienti per AS grandi, poiché BGP è una comunità. 

\subsection{MPLS VPN}

Il \textit{Multo-Protocol Label Switching} è una tecnologia usata dai data centers, che risponde ad esigenze di diversi attori. 

Il cliente vorrebbe avere un filo, mentre il provider vorrebbe  utilizzare la rete che già possiede. 
I provider hanno una grande disponibilità di banda, ed è molto difficile saturarla, vorrebbero vendere connettività punto-punto ai loro utenti, vendendo fili virtuali ai suoi utenti. 

Le sedi periferiche di un'organizzazione si connettono alla sede centrale tramite il provider, per voler collegare punto-punto queste diversi sedi, con possibilmente gli stessi prefissi tre le varie sedi. Per cui il provider deve realizzare un filo virtuale mantenendo invariati gli indirizzi dell'organizzazione del customer. 
Vuole che questo traffico sia segregato rispetto al traffico di altri utenti, poiché potrebbe contenere informazioni sensibili, o ha esigenze di riservatezza. Almeno lo vuole isolare logicamente. 

Il provider vuole realizzare una configurazione economica e scalabile, e non vorrebbe avere delle prestazioni minori. 

%% TODO add smt
Per soddisfare i vincoli del provider e dei customer, si usano i VPN, \textit{Virtual Private Network}, si comportano come una rete privata, ma è implementata solo virtualmente, e MPLS, \textit{Multi-Protocol Label Switching}, un protocollo altamente scalabile per il trasporto di dati. 

Il label switching è un meccanismo di instradamento dei pacchetti, si inserisce sopra ad ethernet, e sotto IP. Però mentre nella rete attraversano pacchetti MPLS, passano anche pacchetti IP. 

Un nodo per inviare un pacchetto, si calcola il suo cammino, al pacchetto non lo si guarda più all'indirizzo, si inserisce in un altro pacchetto contenente un'etichetta. Le macchine successive instraderanno in base all'etichetta. Ci sono tante etichette quanti sono i flussi che stanno attraversando la rete al momento, un numero molto minore rispetto allo spazio di indirizzamento di internet. 
Quando si definisce questo flusso si possono fare considerazioni di banda, per il flusso dei dati. 

Per ogni tratto si usa un'etichetta diversa, il calcolo deve essere effettuato dalla macchina che assegna l'etichetta. 
Prima bisogna avere delle tabelle di etichette. All'inizio un qualche protocollo decide il cammino e determina per ogni tipo di flusso un tipo di etichetta. La macchina che determina se un pacchetto appartiene ad un dato flusso determina la sua etichetta. 
Lo inserisce in un circuito virtuale indirizzato su una strada già determinata, in base ai protocolli di instradamento del livello sottostante. 


Il pacchetto MPLS incapsula i pacchetti con un header contenente uno o più etichette, in uno stack. Ogni stack ha quattro campi, il valore, la classe del traffico, una flag che indica l'ultimo pacchetto ed il TTL. 
Molte volte il TTL non viene aggiornato, quindi non sono visibili i nodi intermedi con un traceroute. 

Si potrebbe sovrapporre un certo numero di etichette in maniera arbitraria. Inoltre, si potrebbe creare un tunnel dentro ad un tunnel. 

In generale i router dei provider o di backbone si indicano con P, i router di frontiera sui customer si indicano con PE, i router dei customer si indicano con CE. 

Per implementarlo la prima azione da eseguire è assegnare un indirizzo IP di loopback ai PE, garantendo che siano connessi. 

QUesti indirizzi di loopback vengono propagati attraverso un protocollo IGP. Sulla macchina router si definisce un'interfaccia dove si vedono le destinazioni di questo traffico, si passano per questa interfaccia, ed essendo un interfaccia virtuale, di loopback, viene incartato in un altro pacchetto che possiede l'indirizzo destinazione dell'altro estremo del tunnel, ed esce alla fine del tunnel, lo scarta e lo ripassa attraverso la tabella di instradamento e lo passa all'interfaccia. 

In questo modo non si hanno problemi di sovrapposizione delle reti. Questo sarebbe difficile da configurare, e bisognerebbe configurare un numero quadratico di tunnel. 


La seconda fase consiste nell'usare BGP per annunciare un'opportunità di instradamento. QUesto utilizza una variante di BGP, MP-BGP. 
Ogni iBGP instaura un peering iBGP con tutti gli altri PE nella rete del provider. Queste sono informazioni di instradamento sulle reti del customer. 


La terza fase consiste nell'usare MPLS come tunnel, il pacchetto IP di un CE attraversa tutta la rete dopo essere incartato in un pacchetto MPLS dal PE, assegnando due etichette, indicando qual è il customer e qual è il PE di destinazione. Quando il PE giusto rimuove la prima etichetta, e rimane solo l'etichetta che indica il customer mittente. 

In realtà l'etichetta finale la toglie il penultimo così toglie il pacchetto effettivo al destinatario. 

L'etichetta più profonda che non viene usata per instradare viene usata per identificare quel tipo di traffico. Quella che emerge viene utilizzata per attraversare la rete. 
L'ultima etichetta identifica la VPN, è usata in maniera simile della VLAN, definita in IEEE 802.1Q. 

Il protocollo che assegna queste tabelle di etichette è il LDP, \textit{Label Distribution Protocol}. 

%% TODO add smt

Per inoltrare un pacchetto in questo modo si usa il costrutto \textit{Virtual Routing and Forwarding} (VRF), questo virtualizza il router, creando delle istanze di routing. 
Questo permette ad un router di avere diverse tabelle di instradamento, ogni tabella è un'istanza di VRF, sia il control plane che il data plane. 


Ogni PE mantiene più istanze di VRF ed ogni contiene le rotte ricevute da CE direttamente connessi, associati ad una specifica istanza di VRF, inoltre ogni VRF contiene le rotte propagate da BGP dagli altri PE. 

Per distinguere gli indirizzi IP si usa un \textit{Route Distinguisher}, (RD), e nessuna VPN ha lo stesso RD. Questo converte indirizzi IP non univoci in indirizzi VPN unici. Questo permette di evitare conflitti se due customer hanno spazi di indirizzamento sovrapposti. 
%% TODO add def RD

In MPLS i router si distinguono in LER, \textit{Label Edge Router}, il primo router che incapsula il pacchetto dentro un MPLS LSP. Mentre LES, \textit{Label Switching Router}, si occupa di instradare pacchetti MPLS all'interno della rete. 

Un LSR può ricevere la stessa etichetta da più interfacce, in questi casi sono presenti dei meccanismi per evitare problematiche. Questo si basa sul label space usato, e dipende dall'implementazione ed a volte dall'interfaccia, non dalla configurazione.   

A volte avere solamente un RD non è sufficiente, si vorrebbe avere una VPN che non è punto punto, ma una mesh. In questi casi il RD indica solo una rete virtuale e non riesce a stabilire una topologia. 

Quindi si è introdotto un altro attributo \textit{Route Target} (RT), che specific specifica quali rotte devono essere importate o esportate all'interno di un VRF. 
RT è una comunità estesa, che supporta topologie complesse. Si assegna un RT ad ogni VPN, e si usa un singolo VPN. 

Oltre a specificare il RD, si indica anche il RT, che è una comunità di VPN. 

Questo sistema di amministrazione interno di un AS permette di creare dei tunnel all'interno, cno la massima flessibilità senza che il customer sia a conoscenza di quello che sta avvenendo dentro l'AS, vedendo la connessione come un'effettiva connessione via filo. 
La configurazione del provider inoltre è relativamente semplice. 

\clearpage

\section{IPv6}

Lo scopo di IPv6 implementa strategie per sostituire il protocollo ARP. 

L'indirizzo è composto da 128 bit, ed ha meccanismi per accorciare la scrittura, utilizzando indirizzi molto corti principalmente per macchine importanti. 

L'header IPv4 contiene campi rimossi da IPv6, alcuni non sono mai stati utilizzati, come i campi relativi alla frammentazione. Potrebbero esistere tecnologie che prevedono una dimensione massima dei pacchetti più piccola. In questi casi il router deve spezzare un pacchetto in frammenti, questi campi rimossi si usano appunto per determinare se un frammento appartiene allo stesso pacchetto. 
Questi frammenti vengono ricomposti a destinazione, aumentando il carico per la macchina destinazione. 
Se viene specificato che un pacchetto non può essere frammentato ed un router sul tragitto individua una strettoia, questo viene scartato e viene inviato un pacchetto ICMP. 


La scheda di rete di una macchina condivide le MTU dei singoli livello protocollari a quelli superiori. È stato rimosso il campo checksum, che andava ricalcolato ed in teoria controllato ad ogni hop. Questo non viene quasi mai controllato dai router per aumentare l'efficienza. 

In IPv6 mancano le opzioni, campi dinamici, per rendere la struttura del pacchetto stabile. 
Ogni pacchetto ha un'etichetta, diversa per ogni pacchetto, in modo da effettuare un'instradamento veloce dalla cache. 

%% TODO descrizione campi ipv6


Il campo next header permette di specificare degli \textit{extension header} che contengono anch'essi il campo next header, quindi è possibile realizzare una catena di header, simile alle opzioni in IPv4. 

L'extension header rappresenta un nuovo metodo per implementare le opzioni, questi extension header possono essere di routing, o di codifica, o header di livelli superiori. 
% catena di margherite
Ci sono alcuni header che se sono presenti devono essere letti necessariamente. Un IS guarda gli header fino a quando lo riguardano, sono ordinati in modo da avere opzioni diverse, dedicate. 

%% TODO vari extension header

Gli indirizzi IPv6 vengono rappresentati in notazione esadecimale, in un URL gli indirizzi IPv6 sono inclusi tra parentesi quadre. 
Scompare l'indirizzo di broadcast, che causava per IPv4 un interrupt a tutte le macchine che lo ricevono, indipendentemente dal fatto che sia effettivamente indirizzato loro o meno. 

In una configurazione DHCP, la macchina registra sulla sua scheda di rete gli indirizzi MAC del server DHCP in un insieme per realizzare un insieme di indirizzi multicast. 
Via software si può dire ad un scheda di rete di raccogliere altre tipi di pacchetti. 
Utilizzando uno sniffer, questo raccoglie tutti i pacchetti come se fossero direttamente inviati alla macchina. 
Dal numero IPv6 si può estrarre l'indirizzo MAC, per aggiungerlo alla lista di indirizzi anycast.  


C'è una forte presenza di macchine con uno stesso numero, queste macchine anycast sono macchine che offrono servizi, e la richiesta viene soddisfatta dalla macchina più vicina. 

Gli indirizzi IPv6 possono essere privati per vari livelli di privatezza. È molto più frazionato rispetto ad IPv4. 

%% TODO indirizzi


Ci sono indirizzi che contengono dentro indirizzi IPv4 nascosti, usati in alcuni tipi di transizioni IPv4-Ipv6, ora deprecati. Mentre nelle reti IPv4 c'è un'alta frammentazione e subnetting applicando il CIDR, in IPv6 la lunghezza del prefisso è fissa e diversa dal'identificativo dell'host. C'è comunque la notazione barra per aggregarle a criteri di routing, ma negli indirizzi è sempre presente un prefisso di 64 bit, e quindi hanno una netmask stabile. 


La parte di prefisso è utile ad identificare la subnet, mentre l'identificativo dell'host può essere specificato manualmente oppure automaticamente. Aggiungendo q questo indirizzo prefissi diversi si ottengono indirizzi differenti per la stessa macchina. 
Quando la macchina trasmette sceglie uno di questi indirizzi da utilizzare per la trasmissione. 



%% TODO smt

Per link si intende una rete fisica come esempio una LAN, un collegamento punto-unto o anche una rete geografica comune. 
Nodi sullo stesso link sono detti neighbor, o vicini. Per site invece si intende un insieme di link gestiti da un unica organizzazione. Questi hanno un loro prefisso \textit{link local unicast} ed analogamente \textit{site local unicast}, utilizzabili dentro la LAN. 
Mentre i prefissi \textit{global unicast} vengono assegnati dalla IANA alle organizzazioni continentali e regionali, ed in seguito vengono assegnati pi facilmente ai singoli IPS, e successivamente utenti. 

La distribuzione degli indirizzi verso il basso è automatica, e potrebbe essere possibile sostituire gli indirizzi in modo trasparente. 
Si potrebbero assegnare tutti gli indirizzi che iniziano per una certa sequenza in una zona geografica limitata Tutti questi pacchetti vengono instradati osservando una barra molto corta. 
Quindi questi prefissi sono suddivisi, i primi 32 bit di prefisso sono assegnati per un ISP, mentre blocchi più grandi a RIR. Successive suddivisioni in barra 48 vengono affidate alle singole organizzazioni, da 48 a 64 è possibile fare subnetting sul site dell'organizzazione per realizzare link. 


Invece di avere indirizzi broadcast si utilizzano indirizzi multicast. 
Indirizzi multicast cominciano sempre con \texttt{FF}, questo è seguito da una flag, per indicare se si tratta di un indirizzo permanente o temporaneo. I seguenti quattro bit individuano uno scope specifico che può andare da nodo, a link, site, fino a globale. I seguenti 112 bit identificano il group ID; un gruppo multicast valido su uno scope. 

Indirizzi multicast importanti sono dati da \texttt{FF02::1:FFxx:xxxx}, questi indirizzi sono chiamati \textit{solicited-node}. Si crea un gruppo multicast per ogni indirizzo che non è multicast. 

Questo indirizzo solicited node viene usato per sostituire il protocollo ARP e ICMPv4. 

\subsection{ICMPv6}

Pacchetti ICMPv6 riprendono le funzionalità di ICMPv4, ed assumono nuove funzionalità e responsabilità gestite da protocolli ARP e IGMP su IPv4. 
Il pacchetto ICMPv6 presenta una specie di header dove viene specifico il tipo ed i sottotipo, degli header precedenti, seguito dai dati di ICMP. 

Il primo bit del campo type distingue tra due classi di messaggio, di segnalazione di errore o di messaggi informativi. 


I pacchetti IPv6 non vengono frammentati, quindi bisogna garantire che non vengano scartati durante il percorso, si vuole determinare l'MTU pià piccola da considerare collo di bottiglia per ridurre la dimensione del pacchetto IP. 
La procedura di \textit{Path MTU Discovery} è basata su messaggi ICMPv6 per segnalare pacchetti troppo grandi. 

Prima di interpretare il livello quattro deve l'indirizzo del livello tre, convertendo con un DNS il dominio ad indirizzo IP. 
In IPv4 il processo si ferma e lancia un processo di discovery di livello due per individuare l'indirizzo MAC del destinatario, con un'ARP. Questo può esistere sulla rete, e quindi raggiungile direttamente, altrimenti si deve inviare al router di default. 

Questo processo di neighbor discovery in IPv6 viene effettuato tramite ICMPv6. Questi pacchetti si occupano della risoluzione degli indirizzi. Sostituendo ARP request e reply con neighbor solicitation e advertisement, utilizzando gli indirizzi multicast all'interno di un link. I messaggi non possono uscire dal link. 


Il messaggio ICMPv6 redirect è simile alla controparte IPv4. QUesta informa il router che è presente un router migliore sul link per raggiungere lla destinazione, oppure che la destinazione si trova sullo stesso link. 


Indirizzi solicited node multicast vengono calcolati a partire dal prefisso \texttt{FF02}, seguito da 72 bit di zero, seguito da \texttt{01FF}, seguito dagli ultimi 24 bit dell'indirizzo. La probabilità che due macchine abbiano questo stesso indirizzo multicast è molto bassa, poiché gli ultimi tre byte corrispondenti sono quelli dell'indirizzo MAC assegnati dal costruttore, quindi è improbabile siano uguali. Ogni interfaccia viene iscritta ai gruppi multicast corrispondenti a tutti gli indirizzi assegnati da essa. 
L'uso degli ultimi 24 bit dell'indirizzo IPv6 diminuisce una riduzione delle collisioni, poiché dipendono dall'indirizzo MAC. L'indirizzo destinatario a livello due si può ottenere dall'ID del gruppo a cui è iscritta la macchina. 

Chi deve risolvere l'indirizzo IPv6 in un indirizzo di livello MAC, invece di mandare un pacchetto broadcast, si calcola l'indirizzo multicast IPv6, da cui si ottiene l'indirizzo MAC di livello due per inviare il pacchetto sull'indirizzo multicast. 
Rispondendo a questo messaggio inviando all'indirizzo specifico, un pacchetto di neighbor advertisement con il suo indirizzo IPv6 specifico nella porzione dati del pacchetto. 


In IPv6 c'è una cache che sostituisce l'ARP cache, una sorta di mappa che tiene conto della mutua raggiungibilità dei nodi vicini. Per i nodi vicini controlla che siano raggiungibili da neighbor solicitation, per i nodi remoti controlla che siano raggiungibili attraverso il router next-hop. 
Questo algoritmo permette di individuare rapidamente cambiamenti di indirizzi fisici o guasti nella rete; chiamato \textit{Neighbor Unreachability Detection} (NUD). 

Un'altra funzionalità interessante di IPv6 è l'autoconfigurazione degli indirizzi. 
Permette ai singoli di nodi di generare un indirizzo IPv6 stabile in modo stateless, senza utilizzare server DHCP. 
La macchina può prendere l'indirizzo dell'interfaccia, mentre come prefisso di rete utilizza indirizzi link-local. In questo modo può comunicare con il router per ottenere un prefisso da utilizzare sulla rete. 
Il server DNS deve essere necessariamente specificato a mano, oppure tramite protocolli diversi. 


Il meccanismo di router advertisement è un algoritmo dove i router inviano periodicamente su ogni link dei pacchetti di questo tipo, dove si identificano e specificano se siano disponibili agli host per diversi servizi. 
Specificano il loro indirizzo di livello due e indirizzo IPv6 link-local, indicano se sono disponili come default router. Specificano altri parametri come TTL, MTU, ed inoltrano una lista di prefissi utilizzabili sulla rete, assegnati al link, oppure globalmente unici. 

Quando un router comunica un prefisso, gli altri 64 bit si possono ottenere dall'indirizzo MAC, per comunicare con il resto del mondo. 

Questi router advertisement vengono inviati ad intervalli regolari, c'è anche la possibilità di richiedere queste informazioni, tramite una router solicitation, inviato all'indirizzo multicast del link, quindi a tutti i router del link. 
Questa è una richiesta per un router advertisement, inviato in unicast a questo indirizzo. 

Ci sono meccanismi di riconoscimento di indirizzi duplicati, a bordo della macchina si controlla se un'altra nodo ha già lo stesso indirizzo, specificando come indirizzo sorgente l'\textit{unspecified address}, \texttt{::}. 
Se non riceve alcuna risposta, adotta quell'indirizzo. 


Si può generare un indirizzo link local di ciascuna interfaccia, in modo da poter comunicare sulla rete locale. 

%% TODO smt

I prefissi contenuti in un router advertisement sono associati ad un tempo di vita, un timer oltre il quale quel prefisso è da non considerarsi più valido, e non può essere riassegnato all'interfaccia. 
Questi tempi associati agli indirizzi sono \textit{valid lifetime} e \textit{preferred lifetime}, il primo è il tempo per cui un indirizzo può essere associato all'interfaccia, ed il secondo è il tempo per cui l'indirizzo può essere utilizzato per nuove connessioni. 

Questo permette il renumbering automatico degli host, tramite nuove router solicitation, e configurazioni automatiche. 

Gli indirizzi e gli altri parametri di configurazione come i server DNS possono essere configurati manualmente. 
È possibile effettuare una configurazione interamente manuale, con DHCPv6, su specifica dell'autoconfigurazione stateless. 

Le specifiche stateful nella stateless riguardano due flag dedicate nel router advertisement. Queste sono \textit{managed address configuration}, che indica se l'host deve ottenere indirizzi da parte di DHCPv6, mentre un secondo campo indica se deve utilizzare quest'ultimo per ottenere altre informazioni di configurazione. Se è il primo è settato, lo anche questo. 

%% TODO smt


Il router assegna tanti indirizzi, poiché ne riceve tanti dall'esterno e poiché una stessa macchina potrebbe avere più provider, ed ogni provider inietta su routing diverso. 
Quando si decide di parlare con un interlocutore remote, è possibile entrambi abbiano un indirizzo globalmente unico, ma questo potrebbe avere diversi indirizzi IPv6 diversi. Questa scelta impatta le prestazioni, influisce sulla rotta attraverso cui avviene la comunicazione. 
La scelta migliore può cambiare nel tempo, inoltre un provider potrebbe avere dei problemi e quindi bisognerebbe cambiare provide e quindi rotta, attraverso un altro insieme di indirizzi IPv6. La scelta degli indirizzi di comunicazione è una parte critica. 

Ci sono diverse scelte, tipicamente si preferisce IPv6, anche se è possibile andare ad IPv4, in base alla condizione del destinatario. 

Su IPv4, si provano gli indirizzi di destinazione uno per volta per valutare quale sia più appropriato. 



Il multihoming si basa su BGP, se si vuole comunicare tra due provide diversi, attraverso BGP. Se le due zone sono separate e sono stati assegnati più indirizzi, BGP è costretto ad inoltrare tutti questi indirizzi. Se questo router connesso all'altro provide è dello stesso provide che assegna gli indirizzi, deve inoltrare solamente questa subnet dove si trova la macchina. 

Gli effetti di questo fenomeno sono l'aumento esponenziale delle tabelle di instradamento a causa della frammentazione delle reti, e quindi dell'inoltro di queste nuove rotte. 

In IPv6 avendo due indirizzi diversi, si ha un insieme di indirizzi, e si sceglie quale di questi utilizzare, così mitigando questo problema. 

Se non si parla BGP non si ha possibilità alternativa, tutte le connessioni che usano questo link potrebbero andare in fault. Inoltre, non si ha bilanciamento. 

Un approccio proposto per risolvere questo è avere una scelta dinamica dell'indirizzo IP, sia per identificare la macchina sia per identificare il provider attraverso cui la si raggiunge. Separando queste due funzioni si separa il locator, la posizione del nodo nella topologia della rete, dall'identifier, per indirizzare il nodo agli strati superiori. 


Si utilizza un ID per i livello superiori, per identificare il nodo e comunicare con nodi esterni. 
Questi indirizzi usati sono solamente identificativi, appartengono effettivamente ad un'interfaccia del destinatario, ma rappresenta solamente un ID della macchina, che può essere per ogni nodo o per ogni processo all'interno del nodo. 

Il locator è l'indirizzo IP usato per instradare il pacchetto, identifica la posizione del nodo nella rete. 
L'idea è quella di usare il locator solamente al livello tre nella fase di instradamento, seguito da uno strato \texttt{shim6}, sempre al livello tre, per separare l'indirizzo utilizzato e l'indirizzo rappresentativo delle due macchine nella comunicazione. Gli strati superiori sono convinti di utilizzare questi indirizzi. Questo decide la coppia di indirizzi sorgente e destinazione da utilizzare anche rispetto alla disponibilità e le tempistiche dei pacchetti. 
Si riesce a cambiare i pacchetti senza far cadere la connessione. 

Lo stesso si può usare con meccanismi sofisticati di SDN. 

%% TODO smt shim6


Questa separazione non è stata introdotta nel protocollo quando è stato realizzato, poiché ha un effetto a cascata anche su livelli inferiori. Questo è facile risolvere utilizzando degli identificatori end-to-end, scambiando dei \textit{context tags} shim6 che possono essere utilizzati per identificare un contesto e quindi una comunicazione specifica, potendo cambiare dinamicamente i vari indirizzi. 

\subsection{Transizione}

Il livello di rete ha la caratteristica di essere uniformante, tutte le macchine intermedie devono avere lo stesso protocollo per poter parlare IPv4 o IPv6. 
Per cui sono necessari meccanici di transizione per realizzare questa transizione da IPv4 a IPv6, poiché è estremamente difficile cambiare protocollo a questo livello. 

IPv6 deve essere compatibile a IPv4 e deve permette il passaggio da IPv4 per la sua adozione. 

Adesso IPv6 è adottato in parallelo rispetto a IPv4, il processo di transizione potrebbe durare decenni. 

Il processo di transizione è diviso in tre fasi
In un momento IPv6 componeva delle isole separate nell'internet dove si può comunicare con IPv6, dove utilizza prevalentemente i servizi esistenti di IPv4. 
Nella seconda fase i due protocolli coesistono nella diffusione globale, le varie isole di IPv6 si consolidano ed è possibile comunicare nella maggior parte di internet solamente con IPv6. 
Nella terza fase l'adozione di IPv6 supera la diffusione di IPv4, che rimane utilizzato su delle isole, e le reti IPv4 si appoggiano sull'infrastruttura IPv6. 


Si ha la possibilità di realizzare apparecchiatura dual stack, con due pile protocollari, IPv4 e IPv6. Altri meccanismi utilizzati sono i tunnel, in disuso, configurati manualmente per superare oceani in modo da comunicare solamente su uno stesso protocollo. Altri meccanismi possibili i traduttori di protocollo, come SIIT, NAT64. 


Il dual stack è l'approccio più semplice, ma non riduce il fabbisogno degli indirizzi IPv4, rimane il problema di IPv4. Le applicazioni che supportano IPv6 possono utilizzare entrambi i protocolli. 
Anche se è molto semplice, richiede una doppia gestione dell'infrastruttura. Non integra la rete IPv6 con quella IPv4. 

I client su di un host dual stack tentano di stabilire una connessione IPv6, e sol se non ci riesce stabilisce una connessione IPv4. 
Il comportamento è descritto da RFC 6555, se il server risponde con un ack ad entrambi i protocolli, resetta una delle due connessioni. 


Supponendo di essere in una fase avanzata, con una rete di backbone di IPv6, e parti periferiche con IPv4. Queste due reti non hanno apparecchiature dual stack, per cui bisogna usare dei protocolli di traduzione, che si comportano come un NAT, facendo passare tutto il traffico attraverso il nodo traduttore. 

Lavorando a livello tre ci sono due soluzioni, SIIT e NAT64. Queste mappano indirizzi IPv4 nello spazio IPv6, essendo molto più grande. 
Ci sono vari modi ufficiali e non ufficiali. In un NAT normale c'è uno stato, e questo ne limita l'utilizzo. 

% dettaglio traduzione ICMP per esempio time exceeded sul nodo di traduzione 

Il primo meccanismo si chiama \textit{Stateless IP/ICMP Translation} (SIIT), generale, che offre la possibilità di comunicare attraverso un traduttore. 

Tutto lo spazio indirizzamento IPv4 è mappato dentro una porzione di IPv6. Gli ultimi 6 byte sono composti da \texttt{::ffff:a.b.c.d}. 
La macchina traduttrice si occupa di inoltrare questo indirizzo mappato. 
I nodi ottengono indirizzi IPv4 temporanei che vengono mappati in indirizzi IPv6 IPv4-\textit{translated} del tipo \texttt{::ffff:0:a.b.c.d} e usati come indirizzo sorgente. 
Il traduttore traduce i pacchetti in transito, con una traduzione stateless, non è necessario salvare informazioni aggiuntive. Inoltre, non è importante la macchina da cui entra o esce, poiché il processo è stateless. 
Questo richiede modifiche alle implementazioni IPv6, e richiede la presenza di assegnazione dinamica di indirizzi temporanei, questi devono essere inoltrati fuori come se fossero appartenenti alla rete. 
Richiede di gestire il routing per gli indirizzi IPv4-translated all'interno del site. 


Il NAT64 è più elegante, ma richiede uno stato parziale. Si chiama così poiché ricorda il NAT, e fonde le soluzioni del SIIT con il NAT. 

Il nodo traduttore dispone di un pool di indirizzi IPv4 che vengono assegnati ai nodi che lo utilizzano, ed il NAT64 mantiene lo stato delle associazioni. 
Gli indirizzi IPv4 vengono rappresentando i 32 bit dell'indirizzo ad un prefisso di 96 bit di instradamento verso il traduttore. 

La traduzione dei pacchetti avviene come in SIIT. 

Ci vuole uno speciale DNS chiamato DNS64, che aggiunge delle funzionalità, pensato ad un client IPv6 per connettersi ad un servizio IPv4. 

Il DNS64 server consulta il DNS normale, cercando di capire gli indirizzi della macchina del servizio, poiché potrebbe avere indirizzi IPv6. Se ha solo indirizzi IPv4 nota il problema. Allora restituisce invece l'indirizzo IPv6 corrispondente che codifica la destinazione. 

%% TODO NAT64, rewording

\clearpage

\section{TCP}

\subsection{Trasmissioni Efficienti}

La socket è vista dall'applicazione come un file descriptor, una sequenza di 16 bit, associato ad un'istanza di conversazione. 
Quando si vuole mandare un messaggio ad una macchina remota, l'applicazione scrive il messaggio su una di queste socket, con gli stessi comandi per la scrittura su di un file. 
Quando si scrive un blocco di dati, questi dati vengono messi in un buffer di uscita da quella socket, e sarà il livello quattro ad occuparsi di inoltrarli al livello quattro. 

I pacchetti TPC si chiamano segment, e possono essere scomposti in diversi pacchetti, in base alla massima dimensione di un pacchetto MSS, stabilita durante il three-way handshake. 

Il pacchetto TPC contiene la porta sorgente e mittente, queste sono due etichette che identificano il processo sulla macchina corrispondente relativa alla connessione. 
Un'etichetta serve solo a denotare un'istanza di comunicazione. La conversazione in sé viene definita sia dalla porta che dagli indirizzi. 

La connessione dipende dallo stato di questi due host, su due flussi di comunicazione completamente indipendenti. Si potrebbe chiudere la conversazione in un verso solo, ma quando si chiude da un verso normalmente si chiude anche nell'altro, poiché non avrebbe senso continuare la conversazione. 


TCP è uno strato complesso, nella scelta delle tempistiche e delle strategie, mentre è semplice rispetto ai pacchetti. 
Per un periodo sembrava un sistema igà studiato, ma ci sono scoperte nuove strategie per velocizzare la comunicazione. 

Per rendere più efficiente il protocollo si vorrebbero mandare pacchetti con tanto payload, essendo un protocollo per trasferire dati. Gli strati inferiori non vedono questa problematica. Quindi solo TCP può realizzare questa strategia. 

Si vuole ridurre il numero di pacchetti inviati, quindi si vogliono inviare pacchetti quasi sempre di dimensione massima. 
Si può realizzare riducendo il numero di notifiche, ed evitando il numero di pacchetti perduti con varie strategie. 
In generale il livello IP è best effort, quando un router è congestionato, butta i pacchetti in maniera casuale, senza neanche mandare ICMP. IP non garantisce il servizio di consegna, invece è garantito da TCP. Questo è un sistema critico ed è necessario garantire che la sequenza dei byte sia uguale tra mittente e destinazione. 
È il primo livello a rilevare le congestioni e poter agire a riguardo. 

Si possono implementare strategie di attesa, temporizzando i pacchetti. Le prestazioni dei servizi TCP cambiano in maniera significativa quando si cambiano queste policy. 


Il TCP mittente può aspettare che i dati si accumulino prima di inviarli, ad eccezione di dati urgenti, analogamente per il destinatario in lettura. 

Si può utilizzare il campo window per comunicare il buffer disponibile in lettura o scrittura. In questo modo avendo un mittente veloce ed un destinatario lento, questo metodo blocca il traffico. 
Può essere utilizzato in maniera strategica, quando un server instaura una connessione, mostra prima una finestra piccola, per evitare possibili attacchi. 


%% TODO smt

Leggendo il carattere il server telnet invia un notifica di cambiamento di flusso, inviando 40 byte per pacchetto, con un solo byte significativo passato sulla rete. 


Per ovviare a questo problema si utilizzano riscontri ritardati, di solito le notifiche di variazione dei controlli di flusso e gli ack sono ritardati di qualche centinaio di millisecondi. 

L'algoritmo di Nagle ha lo scopo di ridurre il numero di pacchetti che viaggiano al produttore al consumatore del flusso. 
Questo algoritmo invia il primo troncone di dati ed i successivi si lasciano accumulare nel buffer. Il segment successivo è inviato slo se il precedente è stato riscontrato, oppure se è stat raggiunta la dimensione di spedizione massima per la spedizione di un segment nella coda. 
Questo algoritmo è molto usato, ma disabilitato in applicazioni fortemente interattive, potrebbe infatti provocare movimenti incontrollabili del cursore. 

Il problema simmetrico consiste in un'applicazione mittente che produce molti dati. L'applicazione ricevente li usa un byte alla volta. Il problema è il buffer di ingresso del ricevente pieno, con la corrispondente finestra di controllo di flusso pari a zero. Leggendo un byte alla volta, invia una notifica ogni volta che un byte si libera, ed il mittente invia un singolo byte. 

L'algoritmo di Clark risolve questo problema a lato server. Se a lato server bisogna notificare la modifica della finestra, si invia solo se la finestra raggiunge la metà dell'ampiezza massima, oppure un MSS. 

\subsection{Controllo di Congestione}


Durante una connessione la porzione di banda fornite a TCP può variare, è dinamica, e deve determinare quanti pacchetti può inviare sulla banda. Avendo un meccanismo di riscontro caratterizzato da un timeout, un ritardo notevole nell'identificazione di pacchetti mancanti. 

Quando un router è congestionato è costretto a scartare dei pacchetti se non può gestirli, prendendoli casualmente dalla coda di pacchetti. 


% TCP aiuta al controllo della congestione di rete

TCP usa una seconda finestra scorrevole per il controllo di congestione, con una limitazione arbitraria definita dal router. Questa finestra non viene condivisa nel pacchetto TCP, ma è unica per una entità TCP. Quando rileva che la rete è congestionata diminuisce la sua finestra di congestione. 
La finestra che viene usata per spedire dati è la più piccola tra le due. 


Può essere espressa in numero di segment, quando un pacchetto viene riscontrato, aumenta il valore della finestra, diminuita quando ne invia uno. 


L'algoritmo di \textit{slow start} inizializza le finestre di congestione alla dimensione del più grande segment utilizzabile. Ogni ack prima del timeout aumenta la finestra di un MSS, anche se il pacchetto non conteneva tutti i byte di un MSS. Se un segment viene perso, ritorna al valore iniziale. 
Se la trasmissione procede senza perdite, il numero di segment cresce esponenzialmente nel tempo, proporzionale al throughput, fino al limite della connessione. 

Prima dello slow start le macchine mandavano pacchetti fino all'esaurimento della finestra di controllo. Prima si usava slow start solo sulle reti geografiche. Non è ottimale, poiché riparte da un singolo pacchetto alla volta. 

L'obiettivo è stimare nel più breve tempo possibile la banda effettivamente disponibile, quindi si unisce ad un ulteriore parametro \texttt{ssthresh}, un valore inizialmente scelto supponendo sia ottimale. 
Quando un segment è riscontrato ed aumenta il \texttt{cwnd}, la finestra di controllo di congestion, cresce e se è minore della soglia scelta aumenta di uno, mentre se è maggiore della soglia aumenta di un valore del quadrato di un MSS, diviso per il valore attuale della finestra, per evitare congestioni. 
Se si rileva una congestione la soglia è portata alla metà del minimo tra la finestra di controllo di flusso e di congestione. E si porta \texttt{cwnd} ad un MSS. Questa crescita porta a stabilizzarsi in condizioni ottimali ad un intorno del valore ottimale. 


Supponendo di essere nello stato di congestion avoidance e che la finestra valga \texttt{cwnd}. Si possono spedire tutti i pacchetti determinati dalla finestra di congestione. Supponendo che siano tutti riconosciuti, la finestra cresce globalmente di:
\begin{gather*}
    \frac{\text{cwnd}}{\text{mss}}\frac{\text{mss}^2}{\text{cwnd}}=\text{mss}
\end{gather*}
Quindi si ha una crescita costante lineare, anche se non propriamente è lineare poiché ogni pacchetto successivo ha una \text{cwnd} diversa. 
Il comportamento è esponenziale per il slow start fino a raggiungere il congestion avoidance dove è lineare. 



È molto più difficile stimare il tempo di timeout
%% TODO smt
Il roundtrip time stimato per una connessione è la stima corrente, calcolato secondo l'algoritmo di Jackson. 
Se si realizza una media bisogna tenere in considerazione gli ultimi dati, dandogli un peso maggiore. 

Si vorrebbe scegliere un timeout pari al \textit{round trip time}. Nelle prime implementazioni una volta calcolato il rtt, si considerava il timeout un valore $\beta\times$rtt. Ma questo non è efficacie poiché $\beta$ non può essere costante dovrebbe dipendere dalla deviazione standard della distribuzione dei tempi di ack. 
Varie implementazioni di TCP usano un timeout pari a rtt$+4D$. Dove $D$ è detta deviazione media, una stima velocemente calcolabile della deviazione standard:
\begin{gather*}
    D=\alpha D+(\-\alpha)|\text{rtt}-M|
\end{gather*}


Quando un segment è ritrasmesso non è chiaro a quale istanza di trasmissione si riferisce il suo ack. Questo influenza il rtt. Quando si ha un fallimento di invio, a quello specifico segment si applica un timeout raddoppiato ogni volta che non riesce a passare, questa è una variante facile da implementare per l'algoritmo di Karn. 


Quando arriva un segmento fuori sequenza viene generato immediatamente un ack, duplicato, questo non arriva mai in ritardo. Quando arriva un segment fuori sequenza potrebbe provocare l'invio di un ack duplicato. 
Il riscontro è cumulativo, quindi non si deve riscontrare, ma genera automaticamente il riscontro ripetuto sull'ultimo ack fornito. 
Questo è un pacchetto in più, questo determina che il mittente riceve un ack duplicato capisce di aver ricevuto una perdita al terzo ack ripetuto, quindi il quarto ack con lo stesso numero di sequenza. Quindi si capisce di aver perso un solo pacchetto. Non ha il tempo di un timeout, ma di un roundtrip, nel caso peggiore. Poiché si ha una pipe di pacchetti, notificando il mittente in modo immediato. 

Una volta individuato questo, il mittente effettua due operazioni. Il \textit{fast retransmit} ed il \textit{fast recovery}. Per il primo, quando rileva una perdita ritrasmette subito il pacchetto che si suppone sia perso, senza attendere che scada il timeout, il ricevente invierà un ack cumulativo per l'intera sequenza. 
L'algoritmo di fast recovery non si porta al minimo \texttt{cwnd}, ma si esegue un congestion avoidance, poiché si suppone si sia perso un solo segment e quindi è troppo drastico far ripartire lo slow start. 
Questi due algoritmi vengono implementati insieme. 


Se la connessione è stabile si impiega metà della banda effettiva, in un andamento a dente di sega, aumentando linearmente fino a quando non si raggiunge il doppio della soglia e ritornando giù, utilizzando quindi tre quarti della banda disponibile. Generalmente è tre, ma non sempre poiché dipende dalla crescita lineare dell'uso della banda. L'intuizione è usare ack duplicati per percepire le perdite. 
%% TODO spiegare meglio andamento a dente di sega



\clearpage

\section{Livello Applicativo}

I servizi basati sul web sono cruciali ed è importante avere la possibilità di scalare. 

Con hit si intende la singola richiesta da parte del client, con page request si indica una richiesta che consiste di varie hit. Una sessione è la sequenza di page request consecutive da parte dello stesso client. Gli oggetti possono essere statici o dinamici, o sicuri. Ci si concentra principalmente su di oggetti statici e dinamici. 
La pagina stessa è dinamica poiché dipende dall'accesso, unendo dei dati appresi dal server. 

Il contenuto dinamico si vede in qualunque sito che ha una qualche forma di login. 


Per rendere un sistema web più scalabile dal punto di vista del fornitore del servizio, si può analizzare il comportamento normale di una richiesta dell'utente comporta l'interazione con un DNS prima di ottenere l'indirizzo del web server ed iniziare una connessione TCP per HTTP. 
Una singola sessione richiede molte hit singole, ed ognuna di questa genera una nuova connessione, e viene terminata dopo molto poco, con un timeout che spreca risorse. 

Per risolvere questo problema si utilizzano connessioni TCP persistenti con HTTP 1.1, in modo da effettuare un numero arbitrario di richieste, in modo che tutte le hit per una stessa page request viaggino su una stessa connessione TCP, risparmiando risorse sul client, sul servizio, e sulla rete, con un migliore uso della banda. 

Permette di effettuare slow-start TCP per ogni richiesta, con un migliore uso di banda. 

C'è un tradeoff da voler raggiungere, per decidere quando mantiene attiva una connessione, e quanto tempo la mantiene dopo la fine delle richieste. Un web server come Apache crea un nuovo processo con ogni nuova connessione, e tenendole attive tutte queste possono causare uno spreco di risorse al lato server. 
Su HTTP si può specificare un tempo per mantenere attiva la connessione, in genere di qualche minuto e poi il server butta giù la connessione del client. 

Per effettuare più connessioni contemporaneamente un client può aprire connessioni multiple con lo stesso server, e si creano comunque meno connessioni di quante sono le hit. Se viene permesso, dal lato server si potrebbero permettere un numero arbitrario di nuove connessioni, quindi vengono limitata al lato server. 

Questi tipi di scalabilità sono al lato client. Pre rendere più veloce questo processo si può effettuare \textit{client-side caching}. 

Il server ci avvisa tramite il contenuto cosa può essere salvato in cache e suggerisce al browser quanto tenere in vita una cache. 

Si usa una cache anche per il DNS locale, o il resolver locale, solitamente si fidano del TTL che gli viene fornito, anche se nella realtà non è così semplice. 


Risorse statiche usano un ETag, negli header della richiesta, dov'è contenuto l'hash di questo file. 
In HTTP esiste un metodo HEAD per richieste solamente l'header della pagina. Mettere l'ETag nell'header fa lavorare la cache. I browser moderni effettuano prima una HEAD, e se il valore dell'ETag è uguale a quello noto, prende il contenuto dalla cache, altrimenti effettua una nuova richiesta. 


In un contesto aziendale si usano proxy web, anche  se ormai quest'architettura non viene più utilizzata. Questo proxy ha una sua cache, ed in caso non è presente in cache effettua tutto il percorso di richiesta del client precedente, quando ottiene la richiesta, oltre ad inviarla al cliente, la salva in cache. 


Quando si inserisce un layer di cifratura, questa lavora end-to-end, quindi non si può usare un proxy intermedio, altrimenti si dovrebbe rompere la cifratura. 



Un servizio web scalabile è composto da vari server, un meccanismo per lo scheduling, per assegnare la richiesta al server migliore, determinato da un algoritmo di scheduling, ed un'entità che esegue l'algoritmo ed il relativo meccanismo di scheduling. 

% L'entità può essere cloudflare


Si potrebbero avere meccanismi basati sulla risoluzione di nomi, gestito dal DNS, al livello di sessione. 
Si possono avere dei meccanismi anycast BGP, dove si annunciano di proposito due prefissi da due punti diversi che sono lo stesso prefisso, in modo che automaticamente i router nei dintorni scelgano il server migliore. Si basa sull'idea che lo stesso indirizzo IP si può attribuire a più server. L'entità è a livello di routing, ed anche in questo caso si lavora a livello di sessione. 
Si possono avere meccanismi di HTTP redirection, con un web server a livello di page request, per un livello di granularità elevato. 
Per packet indirection localmente viene gestito da un load balancer, e ha un effetto a livello di sessione, page request o hit. 


I web server possono avere una distribuzione locale con dei cluster, scheduling a livello di load balancer o/e redirection. Mentre con una distribuzione globale, si hanno server distribuiti globalmente, utilizzando tecniche di mirroring, redirection, DNS o anycast. 

\subsection{Scalabilità Locale}

Per avere una scalabilità locale, un requisito è avere un cluster di server nella stessa locazione fisica, i server possono essere macchine fisiche o virtuali. 
Il mondo esterno vede un solo indirizzo virtuale, chiamato \textit{Virtual IP} (VIP), a cui provvederà il load balancer a determinare a quale server inviare quella richiesta. 

Si potrebbero specializzare i server, potrebbero essere per tipo di richiesta, così che il load balancer quando legge un pacchetto lo invia al server specifico in base alla richiesta. Altre tecniche di load balancing sono Round Robin, oppure conoscendo lo stato dei server, inviando la richiesta al server meno carico. 

Se si divide il carico in modo tale che le richieste vadano sullo stesso server, si può effettuare caching molto più facilmente. 

Si possono avere dei load balancer hardware oppure software su un normale sistema operativo. Possono realizzare un controllo sulle richieste, chiamati \textit{Web Switch} (WS). Con dei load balancer di livello quattro lo possono aprire fino al livello di trasporto. Ma non si può fare load balancing in base al contenuto della richiesta. Per realizzare questo si usano load balancer di livello 7 che possono leggere il tipo di richiesta o anche sui cookies, quindi sulle identità del client. 

I load balancer di livello quattro lavorano al livello delle connessioni TCP, e deve avere una tabella per ricordarsi a quale server inviare quella connessione, poiché TCP è stateful il load balancer si deve ricordare a chi ha assegnato le connessioni. 
Per determinare una nuova connessione ed inserire nuovi elementi sulla tabella si guardano ai link di connessione. Se passa un FIN rimuove quella entry nella tabella. 

Ci sono due possibili architetture, l'architettura a due vie, dove i pacchetti in arrivo ed in partenza attraversano sempre il load balancer. Questo però non è necessario, poiché quando arriva una richiesta ad un web server questo la può inviare direttamente a chi ha effettuato la richiesta. Tuttavia, questo non è semplice da realizzare. 

L'architettura a due vie si implementa con un NAT, bisogna ricalcolare la checksum TCP poiché dipende anche dall'indirizzo IP, ma per i numeri di sequenza, anche se sono inizializzati random, il WS può inviare al server un SYN con lo stesso numero di sequenza per averli già sincronizzati. 

A livello TCP la scelta avviene dal primo SYN, altrimenti bisognerebbe tenerlo in memoria. Si creano due connessioni TCP con gli stessi numeri di sequenza, in modo da non doverli modificare. 


L'architettura ad una via non ha problemi dal punto di vista di TCP poiché si usano gli stessi numeri di sequenza. L'indirizzo IP della connessione è del VIP, ma non è del web server, quindi dovrebbe mandare un pacchetto con un indirizzo IP che non è suo. 
Sui server si può inserire sulla loopback o su di un'altra interfaccia l'indirizzo IP del load balancer. Non possono accettare connessioni da fuori su questo indirizzi, ma a questo punto sono in grado di creare un pacchetto con quell'indirizzo IP sorgente. 

Il meccanismo è basato sul MAC, il forwarding del load balancer è effettuato al livello MAC, usando il MAC del server destinatario, non è necessario riscrivere il livello IP, e non server ricalcolare la checksum. I load balancer ed i server devono appartenere alla stessa rete fisica per poter instradare a livello due. 

Questo non è un comportamento standard, non è possibile farlo realizzare ad un computer general purpose, poiché quando ricevono un pacchetto lo aprono e lo inviano alla pila ISO-OSI. 


Algoritmi di scheduling possono essere random, se uniformemente casuali, si comportano come round robin, per gli algoritmi statici. Si potrebbero realizzare algoritmi dinamici, basati su informazione dei clienti o lo stato del server, come un round robin pesato, o partizionando i client in base al loro indirizzo IP. 


I load balancer di livello sette devono iniziare loro la connessone TCP, aprire il pacchetto HTTP e capire in base alle informazioni a quale web server inviarlo. Questo permette di realizzare politiche  più efficienti. 
Dopo il three-way handshake con il client il LB effettua lo stesso con il server, ed al termine invia la sua risposta con i dati al client. 
Tuttavia, in questo modo si introduca una latenza alla risposta del client, che deve aspettare un altro three-way handshake. 

Poiché sono connessioni diverse si possono pre-istanziate dal giorno in cui si accende, potenzialmente tenute aperte per sempre, dopo aver ricevuto una richiesta, avendo una sessione già aperta con tutti i server, la risposta è diretta. La connessione tra il WS in questo caso, ed il server è diretta, già attiva. La problematica diventa il tradurre i numeri di sequenza. Si toglie la latenza introdotta nella versione base. 

Anche con un load balancer di livello sette si potrebbe realizzare un'architettura a due vie, ma non è efficiente per le capacità del load balancer. 

È possibile cambiare server durante una sessione tra il client ed il WS, poiché sono indipendenti, per ri-allocare un server. 


Si usano dei SAN, che contengono gli hard disk fisici, connessi virtualmente su richiesta ad un server, per evitare di perdere i dati in caso di guasto del server, ed è utile per condividere facilmente i dati e migrare facilmente macchine virtuali, avendo accesso alla stessa memoria di massa virtuale. 

Per realizzare algoritmi di scheduling, a conoscenza delle informazioni del client, si potrebbero dividere le richieste in base al contenuto richiesto. 

Si potrebbe identificare un utente per sessione, dividendo sessioni con lo stesso cookie, assegnate allo stesso server. 

Questi algoritmi non sono uno migliore dell'altro, dipendono dal loro utilizzo. 

Un altro algoritmo \textit{locality-aware request distribution} assegna la prima richiesta di una certa risorsa al server meno carico, le richieste successive alla stessa risorsa, vengono assegnate allo stesso server. 


Un'altra tecnica, cache affinity, si basa sul cache manager a cui è nota la situazione di cache del server. 


Nel momento in cui si va sul cloud, a seconda dei tipi di cloud si possono realizzare operazioni diverse. Un cluster elastico mette a disposizione un numero di server virtuali dinamico nel tempo, in base al carico delle richieste. 


\subsection{Distribuzione Globale}

Invece di avere i server su uno stesso datacenter, si spargono in area geografiche diverse, per bilanciare la latenza media percepita dagli utenti, aumentando l'usabilità. 

I meccanismi di distribuzione globale si possono comporre su più gerarchia, basandosi su meccanismi di distribuzione locale. 

Se su di un DNS sono inseriti due o più record A per un nome, vengono restituiti RR, potenzialmente una distribuzione globale con questa tattica può avere prestazioni peggiori. 



La distribuzione globale più semplice possibile sono i siti mirror, registrando nomi multipli con un indirizzo IP diverso per ogni server. Lo scheduling è lasciato all'utente che sceglie il server, normalmente da una pagina di partenza. Non è più utile poiché si usano siti non statici, con pagine statiche era sufficiente scrivere la pagina statica sul server mirror. 

Sono due siti separati che offrono lo stesso condiviso, ma con pagine dinamiche e database si vuole avere informazioni condivise su tutti i server. 
Inoltre, non c'è una replicazione visibile per l'utente ed il controllo della distribuzione del carico non possono essere implementati. 


Un'altra tecnica consiste nella ridirezione HTTP, utilizzando i codici di errore 301 e 302, codici che indicano che una risorsa è stata spostata ad un'altra posizione, la prima è temporanea, la seconda è definitiva. 
Si può ridirezionare la richiesta su un altro server, per assegnare la richiesta ad un server migliore. Dalla seconda connessione in poi è già noto il server giusto. 

Si potrebbe utilizzare un sistema centralizzato, con un'entità che conosce lo stato dei server, per distribuire il carico, è un single point of failure, e deve conoscere lo stato di tutti i server. 
Oppure si può avere un sistema distribuito, in base a criteri come il sovraccarico di un server. Si può scegliere quali page request di cui effettuare il redirect, se sono di elevata dimensione, allora è efficiente scegliere un server con più prestazioni e meno latenza. Oppure si può effettuare per per le sole pagine accedute di frequente. 


È perfettamente compatible con ogni browser, e non introduce punti critici di vulnerabilità, distribuiti. Consente di ridirigere solo richieste HTTP, e può aumentare il traffico ed il tempo di risposta, il client instaura due connessioni HTTP per ogni richiesta. Questa tecnica ad oggi è poco utilizzata. 


Lo scheduling basato su DNS si basa su due meccanismi, senza ridirezione basato su A o AAAA, e con ridirezione con CNAME. 
Si usano i record CNAME per diminuire il numero di record A o AAAA da modificare, poiché assegnando un alias bisogna solo cambiare il suo record. 


Quando un client farà il lookup di una risorsa chiede l'indirizzo IP corrispondente al nome del sito, riceve un opportuno indirizzo ed il TTL. La difficoltà sono i DNS server intermedi, che inseriscono questi indirizzi in cache per tutto il TTL. 



Si può usare un TTL molto basso, ma la maggior parte dei TTL moderni non si interessano del TTL dei record, allo stesso modo i browser o i sistemi operativi che ignorano il TTL in cache. 
Oppure si può utilizzare un TTL adattivo, in base alla frequenza delle richieste o il carico del server. 

Si impostano diversi DNS server sparsi per il mondo, configurati statici con un indirizzo IP diverso dall'altro. Si possono impostare diversi indirizzi per un record, questi vengono permutati anche ad intervalli corti, quindi producono riposte diverse. 


%% TODO fix dns, reword, add smt
Si usano i CNAME per risolvere problema della cache, quando un resolver riceve v il CNAME, ricomincia il processo usando il nome canonico. 

Questo permette di ridirezionare il processo di risoluzione verso server secondari, in grado di effettuare uno scheduling locale. 

La difficoltà principale è il TTL, ed il fatto di usar eun certo numero di resolver intermedi, che spesso 

Il DNS su cui viene adattata la risposta è il resolver, spesso è quello dell'operatore, con questo tipo di distribuzione è facile peggiorare l'arrivo dei contenuti. 

Ci sono molti server DNS pubblici. 



L'anycast è uno die meccanismi di ridirezione più famosi al mondo, questo lavora con BGP, uno stesso prefisso viene annunciato da più AS, che contiene la replica del servizio web. il BGP di ogni AS in Internet sceglie l'annuncio che corrisponde alla metrica migliore. Si porta nei punti di scambio di traffico importanti un server ed un router che solamente annunciano in modo indipendente il loro prefisso. All'utente sembra che il traffico punta sempre allo stesso indirizzo IP, che in realtà è replicato, ognuna che si gestisce una porzione del globo. Un solo nome, un solo IP, e BGP che effettua la ridirezione. 

Il conflitto di IP se configurato bene, funziona correttamente. BGP effettua sempre la sua scelta deterministica, e la mantiene senza altri cambiamenti. I conflitti di indirizzi IP creano problemi quando ci sta ambiguità, potendo inviare una parte della richiesta. 


Se non è possibile scegliere, quindi quando non sono note le scelte ottimali e si vuole una situazione semplice che funziona, si usa un sito mirror o IP anycast. Invece è possibile effettuare una scelta vera e propria con HTTP redirect, dopo aver inviato i pacchetti HTTP ed instaurato la connessione TCP, quindi tardi, oppure prima ancora di aver inviato la richiesta con DNS. 



Le difficoltà dipendono da una buona allocazione del client al server, a causa del carico o per la prossimità tra i due. 


%% TODO smt

Si vorrebbe prevedere il carico del server, per poter distribuire le richieste, in base al giorno ed ora, ai fusi orari e la distribuzione geografica degli utenti. 


Algoritmi di scheduling sono round robin o con funzioni di hash, dove la scelta è compresa interamente da questa funzione. Algoritmi dinamici che dipendono dalla conoscenza dello stato del client o server. 


Tutti questi si basano sulla stima della distanza tra il client ed il server. Si potrebbe determinare dall'indirizzo IP del cliente, il numero di hop che separano client e server, ma si dovrebbe far aspettare il cliente. 


Alternativamente si può usare il TTL per determinare la distanza, una stima se nessuno ha modificato le impostazioni del sistema operativo. Windows e Linux hanno due default diversi, il TTL parte da 64 o 128. 
Anche scegliendo il minimo numero di hop non garantisce che si tratti del server a latenza minima. 
Il tempo di latenza roundtrip è largamente indipendente dalla prossimità geografica. 

Informazioni da misure attive come il tempo di latenza del roundtrip, della richiesta, cambiano nel tempo, può anche dipendere dalla banda nota disponibile sui link. Hanno bisogno di tempo e traffico addizionale per la valutazione. 


Lo scheduling generico può utilizzare più meccanismi in successione, a più livelli. Si può scegliere con uno scheduling basato su DNS, seguito da uno scheduling basato sull'HTTP redirect. Oppure a tre livelli utilizzando come a onte uno scheduling basato su anycast. 

Computer moderni in realtà realizzano molte query extra per dare l'idea di andare più velocemente. 

Si possono usare dei web cluster distribuiti per sommare le due tecnologie, avendo uno scheduling a livello globale per identificare quale specifico cluster da interrogare, ed in seguito si usa uno scheduling a livello locale per scegliere lo specifico server del cluster da richiedere. 


\clearpage

\section{Kathar\'{a}}

Una rete è composta da diversi apparati, computer, router, switch, ecc., ognuno con differenti interfacce, diversi protocolli attivi sulla rete, diverse connessioni fisiche che generano una topologia complessa. 
L'internet è una rete best effort, non è stabile, ma si voglio garantire le sue prestazioni. 
I router sono automi a stati finiti, non si ha il tempo di computazione per gestire tutti i pacchetti nel modo per garantire le migliori funzionalità e prestazioni. Quindi per garantire queste caratteristiche bisogna lavorare dal punto di vista della struttura della rete e le loro interazioni. 
Ma effettuare sperimentazioni di questo tipo usando tecnologie dal vivo è molto costoso, per cui si vorrebbe realizzare ciò tramite dei modelli locali, o principalmente localizzati per diminuire la necessità di apparati costosi. 
Per creare modelli di rete si può scegliere di emulare o di simulare la rete. Una simulazione riproduce le prestazioni, mentre l'emulazione riproduce le funzionalità. Non si può emulare tutto, un processore general purpose non ha le caratteristiche necessarie per emulare milioni di pacchetti come quelli di un router, che effettuano queste operazioni dal lato hardware. O si toglie il processamento di pacchetto e quindi la funzionalità, oppure si affronta la logica e si mantengono le prestazioni. 

Kathar\'{a} è un sistema per emulare le reti. Quindi ne rappresenta le funzionalità, su di un qualsiasi calcolatore general purpose, senza rappresentare le effettive prestazioni della rete. 
Viene utilizzato per valutare la loro struttura, e le qualità derivanti delle funzionalità descritte della rete. 
Ogni apparato di rete è in un suo container docker separato, e può avere il ruolo di un qualsiasi apparato nella rete, un calcolatore, un router, un DNS, un web server, ecc. Queste funzionalità sono disponibili in base all'immagine del container. 

Ogni dispositivo emulato ha una sua console, una memoria, un filesystem, e può avere, o anche non avere, un certo numero di interfacce di rete, per comunicare con altri gli altri dispositivi emulati. Queste connessioni avvengono tramite domini di collisione emulati, a cui possono essere connesse le interfacce, ognuna connessa ad al massimo un singolo dominio. 

Per usare Kathar\'{a}: \href{https://github.com/00Darxk/Reti-di-Calcolatori/blob/main/Esercizi/Esercizi_Kathará.pdf}{appunti introduttivi} dal corso di Reti di Calcolatori. 

Per visualizzare le informazioni sui pacchetti si può utilizzare \texttt{tcpdump}, specificando varie flag:
\begin{minted}{bash}
    tcpdump {flags}
\end{minted}
\begin{itemize}
    \item \texttt{-e}: include gli headers del livello link, per osservare gli indirizzi MAC, se presenti
    \item \texttt{-i} \verb|{interfaccia}|: analizza i pacchetti solo su una data interfaccia
    \item \texttt{-n}: non converte indirizzi con DNS
    \item \texttt{-t}: non stampa un timestamp per ogni pacchetto
    \item \texttt{-v}: stampa un output prolisso, contenente opzioni e vari campi per i singoli pacchetti
\end{itemize}
Altri comandi utili sono \texttt{traceroute}, \texttt{ping}, ecc. 
% tcpdump {flags}
% -t : no timestamp
% -e : link-level headers
% -n : no protocol name
% -n : no DNS lookup
% -i : sniff su {interfaccia}

\subsection{Configurare un Lab}

Un modello di rete si chiama \textit{lab} in Kathará. Questo viene descritto da un file di configurazione \texttt{lab.conf}, situato alla radice del lab. 
In questo file possono essere presenti una serie di assegnazioni del tipo:
\begin{quotation}
\begin{minted}{c}
    machine[arg] = value
\end{minted}
\end{quotation}

Per indicare parametri o opzioni da attivare per un certo dispositivo emulato nel progetto. Si possono condividere file tra il filesystem interno dei dispositivi e quello esterno del calcolatore con le cartelle \texttt{/shared}, abilitato di default, e \texttt{/hostname}, per ogni dispositivo, disattivato di default. Tutto ciò che è contenuto in sottocartelle in quest'ultimo viene copiato e non riflesso anche nel filesystem esterno. 
Nella stessa directory può essere inserito un file bash \verb|{hostname}.startup| che indica i comandi da eseguire all'avvio del progetto. 
Si usano per configurare la tabella di instradamento statica e gli indirizzi per le interfacce della macchina:
\begin{minted}{bash}
ip address add {indirizzo-ip}/{netmask} dev {interfaccia}
ip route add {indirizzo-dest}/{netmask} via {indirizzo-src} dev {interfaccia}
\end{minted}
Per aggiungere delle rotte di default si usa l'opzione \texttt{default} per l'indirizzo di destinazione 

Inoltre si può usare per avviare servizi, come web server, routing frr, ecc. Queste macchine sono basate su linux e \texttt{systemd} come gestore dei servizi. Per avviare un servizio bisogna inserire in questo file:
\begin{minted}{bash}
    systemctl start {servizio}
\end{minted}

Esistono strumenti per comporre file \texttt{lab.conf} in maniera grafica come, accessibili dal \href{https://github.com/KatharaFramework/Kathara?tab=readme-ov-file#external-tools}{GitHub di Kathará}


Esistono tre livelli per configurare una macchina, si può interagire da utente, dove si possono effettuare comandi come \texttt{ping} e \texttt{traceroute} per verificare la struttura e la raggiungibilità della rete, e controllare gli altri utenti che la stanno utilizzando. 
Elevando i privilegi ad amministratore si possono interrogare direttamente le tabelle di instradamento del router. Per modificare la configurazione stessa bisogna elevare ancora i privilegi per poter modificare la configurazione corrente. Le configurazioni che vengono applicate a questo stadio non sono immediate, solo dopo aver confermato, tutte le configurazioni aggiunte o modificate verranno attivate. 
Questo è rilevante, poiché se si è connessi in SSH alla macchina, è possibile che il canale di comunicazione venga tagliato, e quindi è necessario fisicamente resettare il router per poter connettersi nuovamente. 

\subsection{FRRouting}

Un router ha tante interfacce e per gestire i pacchetti tra tutte queste e scegliere a quale inviarli. Questo viene effettuato grazie ad una tabella di routing. 
Una rete però non è una struttura statica ed è necessario modificare ed aggiornare questa tabella di routing dinamicamente. I protocolli di routing hanno questo scopo. 
Su Kathará ogni macchina che esegue un protocollo di routing identifica un router per la rete.  

La suite di protocolli \textit{FRRouting} (FRR) è open-source e disponibile per piattaforme Linux e Unix. 
Questo implementa vari protocolli di routing, RIP, OSPF, IS-IS, BPG, ecc. 
Ha le sue radici nel progetto quagga, non più supportato, ma dovendo rimanere compatibile con macchine esistenti sulla rete sistemi e protocolli obsoleti, come IPv4, devono continuare ad essere supportati per mantenere la rete funzionante. 
Quagga a sua volta si basava su un progetto chiamato \textit{Zebra}, che l'ha superato, ed è ancora in uso. 

Il protocollo FRR gestisce la condizione di informazioni di routing tra vari protocolli di rete diversi, utilizzando Zebra per unire i loro risultati. 
Ogni suo protocollo ha un demone indipendente, che utilizza un suo file di configurazione sulla macchina. 

Zebra deve unire varie tabelle di routing ottenute dai demoni di BGP, RIP, OSPF, ed ogni altro protocollo abilitato per quella macchina. Genera una tabella generale da iniettare al kernel aggiungendola alla tabella statica. Gli indirizzi IP delle interfacce di rete impostate generano automaticamente queste entry statiche. Questa tabella viene chiamata tabella di instradamento o del data-plane. Le tabelle di instradamento in Zebra sono virtuali, si trovano nel control-plane, su un software. 
% I protocolli di routing per funzionare devono poter comunicare con l'esterno. 


Per configurare FRR su Kathará bisogna creare una cartella \texttt{/etc/frr} nel filesystem degli host predisposti come router, contenente i vari file di configurazione. Il primo file, \texttt{daemons}, determina i demoni dei vari protocolli di routing da avviare, nel formato \verb|{daemon}={'no'/yes}|. 
Quando vengono etichettati, vengono avviati da Zebra, questi demoni si trovano su di una specifica interfaccia, a cui viene connessa la macchina tramite loopback. I vari servizi si trovano in \texttt{/etc/service}. 
La configurazione per FRR è operativa e non dichiarativa, non si può definire il comportamento del router, ma solo usare dei comandi per avviare il router. 
Inoltre non si possono rimuovere comandi, ma per ometterli bisogna inserire la stringa \texttt{no} prima del comando. 
Invece di creare file di configurazioni separati per ogni protocollo, si può abilitare \texttt{vtysh} per gestire allo stesso modo questi protocolli. Per abilitarlo, o disabilitarlo, si inserisce nel file \texttt{vtysh.conf} la seguente: \verb|{ /no} service integrated-vtysh-config|. 
In questo modo si può usare un unico file \texttt{frr.conf} per gestire tutte le configurazioni dei vari demoni. 
Per osservare la configurazione attuale, e verificare quali comandi sono stati accettati o rifiutati si può usare \texttt{show running-config}. 
Si può effettuare un primo debugging osservando le differenze tra l'output di questo comando, e la configurazione inserita nei file di avvio. 
Il linguaggio di questa shell non è \textit{context free}, dipende dal contesto i cui ci si trova, e quindi dai comandi precedenti. 
Generalmente non si configura manualmente in questo modo interattivo su di una shell, è più efficiente modificare il file di configurazione e riavviare il router. 


Per avviare FRR, bisogna inserire nel file di avvio della macchina \texttt{systemctl start frr}, per gestire i vari protocolli si può usare la shell \texttt{vtysh}, se abilitata, che gestisce tutti i protocolli attivi di routing, compreso Zebra. 
Per visualizzare le tabelle di instradamento composte dai singoli protocolli si può usare \verb|show ip {protocollo} {opzioni}|, dentro a questa shell. Per visualizzare la tabella di instradamento complessiva si usa \texttt{show ip route}, quest è diversa dalla tabella iniettata sul kernel, poiché alcune rotte possono essere ripetuto, e Zebra seleziona quale tra queste rotte iniettare. 
Per configurare un protocollo si usa il comando \texttt{configure}, per scegliere che tipo di protocollo, in questo caso di routing, si usa \verb|routing {protocollo}|. Per aggiungere una rotta statica ad uno di questi protocollo si usa \verb|route {prefisso}/{netmask}|. 
Accanto ad ogni rotta, viene inserita la sua origine, può essere del kernel segnata con K, oppure può essere ottenuta da uno devi vari protocolli di rete. 
Su \texttt{vtysh}, si può usare il carattere \texttt{?} per mostrare le possibili alternative per completare un comando. 
Modificando un file di configurazione modificato su una macchina virtuale, è necessario copiarlo su una cartella per condividerlo con il filesystem esterno, altrimenti alla terminazione di Kathará la configurazione sarà persa. 

Oltre a questa modalità di interazione, si può invocare la shell con la flag \texttt{-e} per eseguire un comando senza avviare la shell interattiva: \verb|vtysh -e "{comando}"|
Si può reindirizzare con per scrivere l'output su di un file, che può essere utilizzato da altri programmi \verb|... > {file}|, oppure indirizzandolo ad altri comandi sulla shell con \texttt{... | ...}. Per cercare un dato utile sul database, è utile il comando \texttt{grep}, che seleziona solo le linee contenenti una certa stringa o espressione regolare passata come parametro. 

\subsection{RIP}

% RIPv2

RIP è un protocollo di routing distance vector, che può essere gestito da FRR. 
Nel file di configurazione di FRR bisogna avviare RIP ed impostare la rete su cui può mandare pacchetti multicast:
\begin{minted}{bash}
    router rip
    network {prefisso}/{netmask}
\end{minted}
All'avvio di FRR quindi la macchina si comporta autonomamente come un router, utilizzando il protocollo RIP ed inviando periodicamente i suo distance vector. 

\subsection{OSPF}

OSPF è un protocollo di routing link state packet, che può essere gestito da FRR. 
Per funzionare invia in multicast pacchetti contenti il suo stato attuale, interfacce e reti raggiungibili. Ed ogni router si genera il suo database per calcolarsi un albero dai cammini minimi. 

Alcuni comandi utili per OSPF, da eseguire direttamente sulla shell della macchina o su \texttt{vtysh} sono:
\begin{minted}{bash}
    show ip ospf {route/interface/neighbor/database}
\end{minted}

Per ogni rete un'interfaccia viene promossa un'interfaccia come router designato (DR), per gestire il database. Questo può essere scelto in diversi modi, solitamente per priorità si sceglie anche uno o più router di backup, tra quelli a priorità più alta. 
Viene cambiato DR ogni volta che viene modificata la topologia della rete, identificato dall'invio di altri pacchetti di stato. Per questo cambiano raramente. 
Questo DR viene scelto per ogni sotto-rete, e per ogni rete il suo indirizzo è quello del suo DR. Si può osservare dal comando \verb|... database|, questo è uguale per ogni router. 
Per scegliere un DR ogni router invia un pacchetto di ``presentazione'' sulla LAN, l'interfaccia con l'indirizzo più alto che invia questi pacchetti diventa il DR. Per gli spareggi si utilizza l'ID del router a cui appartiene l'interfaccia considerata, e si sceglie in base all'ID più alto tra questi. 
Inoltre si può configurare una priorità, per indicare quanto un router sia propenso a diventare il DR. 

Aree, router e LAN si etichettano con ID, che coincidono con certi indirizzi IP, per i router questo è l'indirizzo IP di una loro interfaccia, per le LAN è l'indirizzo del DR associato. Questi ID possono coincidere. 
Vengono scelti per un router come l'indirizzo dell'interfaccia più alta che ha, mentre la LAN lo sceglie come l'interfaccia con indirizzo più alto che vede. 

Con il comando \texttt{... route} si possono vedere tutte le LAN raggiungibili e la loro area di appartenenza, tutte le reti presenti nell'area di backbone dovrebbero essere presenti, altrimenti la configurazione è errata. 

Per configurare questo protocollo nel file di configurazione di FRR, si inserisce \texttt{router ospf} per indicare che si utilizza il protocollo, ed in seguito si possono definire le interfacce che appartengono ad una determinata area, tutte quelle che ricadono nel prefisso specificato:
\begin{minted}{bash}
    network {prefisso}/{netmask} area {area-id}    
\end{minted}
Per selezionare ogni interfaccia si usa \texttt{0.0.0.0/0}, per router con interfacce su più aree è necessario specificare singolarmente o a gruppi le interfacce. 
Inoltre per definire il tipo di un'area backbone, stub o transit si usa la notazione:
\begin{minted}{bash}
    area {area-id} {area-type}    
\end{minted}
Questo non è richiesto per la backbone. 
Da questa configurazione, all'avvio del lab, i router invieranno gli opportuni pacchetti link state e realizzeranno la loro tabella di instradamento. 

Aree di tipo \texttt{stub} non vengono usate per il transito, questi sono connetti ad un solo router, e visibili specificando l'opzione \texttt{router} al comando per visualizzare il database OSPF. 
% chi inietta la default
Al livello di controllo non c'è una rotta di default, si assume che tutti i router negli stub abbiano una rotta di default che punta all'esterno della rete. Ai router nelle aree stub viene offerta una rotta di default, che manca ai router nella backbone. Queste rotte puntano alla backbone, che deve gestire i collegamenti tra le varie aree. 
Quando vengono iniettate le rotte verso altre aree, con pacchetti link state, questi vengono non vengono inseriti nella tabella di instradamento per aree stub, sono presenti solamente i router direttamente connessi e la rotta di default. %% TODO forse, controllare

Quando vengono iniettate rotte dall'esterno, il costo della rotta è in base al costo specificato dal protocollo esterno e configurabile manualmente, a questo viene aggiunto il costo di default per OSPF. 
A parità di costo per spareggiare si usa il costo dell'OSPF. %% TODO ??
%% TODO comandi BGP per comunicare/iniettare le rotte BGP su OSPF

\subsection{BGP}

Per configurare BGP, si utilizza sempre \texttt{frr.conf}, per cominciare la configurazione si utilizza \verb|router bgp {ASN}|. Inserendo un comando non di BGP si esce automaticamente all'ambiente BGP. 
Si dichiara subito l'ASN, a differenza degli OSPF. Per impostare i vicini si utilizza la sintassi:
\begin{minted}{bash}
    neighbor {ip-vicino} remote-as {asn-vicino}    
\end{minted}
Si può includere anche una descrizione, per aiutare a riconoscere i vari ASN
\begin{minted}{bash}
    neighbor {ip-vicino} description {descrizione}    
\end{minted}
La connessione tra due router BGP è simmetrica, se i numeri IP non combinano non si alza la connessione. 

Nella configurazione \texttt{daemons} devono essere abilitati sia Zebra che BGP. 

Le rotte statiche si inseriscono con un comando di tipo \texttt{network}:
\begin{minted}{bash}
    network {indirizzo-ip} mask {netmask}
    network {indirizzo-ip}/{netmask}    
\end{minted}
BGP effettua un controllo su questa rotta, controllando se l'indirizzo è nella tabella di instradamento, per evitare di condividere una rotta che non può soddisfare. Se non è presente la raggiungibilità nel data plane, non si possono eseguire queste operazioni nel control plane. 
Questo è abilitato per sicurezza, per disabilitarlo e testare altre configurazioni si può usare:
\begin{minted}{bash}
    no bpg network import-check
\end{minted}
Disabilitando questa configurazione si possono trasmettere rotte non locali o non esistenti. 

Un altro comando, di default abilitato è:
\begin{minted}{bash}
    no bpg egbp-requires-policy
\end{minted}
Questa configurazione quando attiva, impedisce di passare informazioni ad un vicino, se non sono presenti policy.

Il comando \texttt{network} non modifica le rotte nel kernel. 

Nei log di Zebra non vengono inseriti i pacchetti scartati, mentre si possono vedere con FRR. 

% si parte dal router fa un route
% ~/# route 
% ...
% se non si vede la rotta annunciata c'è un problema da indagare

Per debuggare problemi di BGP si comincia dal comando \texttt{route}, per controllare le tabelle di instradamento, se non sono presenti, si prova a connettersi con un \texttt{ping} o \texttt{traceroute}. 
Per indagare questi errori bisogna interrogare con il demone per controllare se sono presenti le rotte BGP che ci si aspetta di aver appreso con \texttt{show ip route}. 
Per controllare perché non ci sono si controllano le configurazioni BGP con \texttt{show ip bgp}. Se ci sono le rotte le alternative corrette allora il problema risiede in un altro punto. Se mancano alcune rotte, si può vedere nel \texttt{summary} che mancano delle rotte. 

% TODO passo successivo, zebra




%% TODO BGP

Il router BGP per capire quando deve cambiare nexthop, prende un annuncio da un'interfaccia e lo deve rimandare indietro dalla stessa interfaccia. 
\texttt{s-path} ed il percorso del traffico non sono sempre la stessa cosa. 

Nel momento in cui si lavora in iBGP, l'attributo \texttt{next-hop} non cambia in uno stesso autonomous system. 
In iBGP i peering devono essere in full mesh, poiché sono tunnel TCP, non si considera la topologia interna dell'AS. 
Il nexthop coincide con l'interfaccia da cui si sta facendo uscire l'annuncio, poiché il peering è eBGP.  
Quando questo annuncio viene ricevuto da un router BGP in un AS, questo viene propagato ed il campo nexthop rimane invariato. 
In AS quando un router iBPG riceve un annuncio, per inserirlo nel data plane, deve conoscere il prefisso, il nexthop e l'interfaccia. 
Il nexthop di questa entry, ricerca nella sua tabella di instradamento come raggiungere il prefisso, tramite un processo di \textit{recursive lookup}. Se non lo può raggiungere non può usare quella rotta, mentre se lo può raggiungere dalla rotta ottenuta inserisce il nexthop risultante. 
Non sempre è lo stesso che viene installato nella rotta del kernel, uno ottenuto dall'annuncio nel control plane, ed un altro nel data plane dalla tabella di instradamento. 

Il campo \texttt{origin} descrive l'origine dell'annuncio, può essere \texttt{igp}, dichiarato interno dall'AS di origin; \texttt{bgp}, se è iniettato su BGP da parte di EGP, per retrocompatibilità, ormai inutilizzato; \texttt{incomplete} se è generato da una ridistribuzione di un protocollo IGP. 


L'attributo \texttt{aggregator} si manifesta in situazioni particolari, quando vengono aggregati due prefissi insieme, inserisce la sua firma, ed indica che è stato lui ad effettuare questa aggregazione. Questa firma corrisponde al BGP router ID. 


Per scegliere la best route, un router BGP riceve un numero arbitrario di rotte per raggiungere quel prefisso. 
Non può applicare un criterio casuale, ma usare un protocollo deterministico. La migliore rotta è l'unica che verrà propagata ai vicini. Questi annunci devono essere relativi allo stesso prefisso. 

Il processo decisionale di un router per determinare la rotta segua una preferenza specifica, ed il processo passa a passi sotto-stanti in caso di parimerito: 
\begin{enumerate}
    \item \textit{Largest Local Preference}: dato che vive solamente dentro un AS, questo dipende dal costo delle reti connesse, assegnando una preferenza maggiore a costi minori
    \item \textit{Locally Originated}: per determinare la rotta per un prefisso, si usa il prefisso annunciato dallo stesso router, invece di usare rotte annunciate da altri router
    \item \textit{Shortest} \texttt{as-path} \textit{Length}: vince l'annuncio con il \texttt{as-path} più corto. Se si vuole abbassare la preferenza di un annuncio che si passa fuori è possibile appendere il numero AS del router più volte, allungando virtualmente l'\texttt{as-path}
    \item \textit{Lowest Origin}: secondo l'ordine \texttt{igp}$<$\texttt{egp}$<$\texttt{incomplete}, questo è un attributo che non può essere determinato nel momento in cui viene inoltrato l'annuncio
    \item \textit{Lowest Multi-Exit-Discriminator} (MED): solamente per gli stessi AS vicini, vince chi è meno penalizzato. Questo attributo non è transitivo. Si appende ad un annuncio quando si viene inviato fuori da un AS. La MED è un attributo facoltativo, quindi non necessariamente è possibile confrontarli. Lo scopo principale è il link principale ed i link di backup, si scelgono anche in base alla banda, e definiscono quale link in uscita si preferisce usare
    \item \textit{Prefer eBGP over iBGP}: si preferisce un routing esterno, poiché mantenere un AS è un costoso, e si preferisce di avere un traffico basso. Si vuole fare bella figura con l'esterno, e mantenere la rete interna efficiente
    \item \textit{Lowest IGP Metric}: ad un certo punto bisogna avere dei fattori deterministici, per cui si decide il nexthop in base alla metrica del protocollo usato, che sia RIP o OSPF, e si sceglie l'annuncio con la metrica più bassa
    \item \textit{Lowest Router ID}: questo ha l'unico scopo di dividere la perfetta parità, il router più basso è puramente arbitrario, si è scelto come normativa, non è possibile avviare BGP su una rete con due router dallo stesso ID
\end{enumerate}

Per i router Cisco, esiste un altro parametro \textit{weight}, proprietario, che viene inserito per primo per decidere quale rotta usare. 


Le policy di input permettono di filtrare gli annunci in input, prima che entrino nel processo decisionale BGP. Per ogni coppia di annunci si che sono passati si esegue il processo decisionale, e si iniettano le rotte nel kernel. A questo punto si applicano i filtri in uscita e si inoltrano le rotte agli altri AS. 

\subsubsection{AS-path filtering}

Si possono filtrare gli annunci per vari motivi, si può filtrare l'\texttt{as-path} per motivi politici. I pacchetti passanti per la rete non sono filtrati, a meno che non siano cifrati end-to-end. 
Per cui è possibile sniffare del traffico, e anche cifrato per estrarre informazioni cruciali. 
Delle potenze ostili tra di loro quindi vogliono evitare che informazioni critiche passino attraverso le altre. 
Gli USA quando è nato internet l'hanno accomunato al servizio postale; se la posta ha come indirizzo destinazione e sorgente un indirizzo statunitense, non può passare per suolo straniero. Quindi non si può passare legalmente per AS stranieri quando gli indirizzi sorgenti e destinazione sono entrambi sul suolo americano. 
Per queste ed altre decisioni politiche si utilizzano dei filtri per evitare che il traffico passi per certi AS. 
Per realizzare questi filtri si usano elementi delle normali espressioni regolari, \texttt{regexp}. 

Tutte queste politiche hanno alla fine un \texttt{deny all} implicito. 
\begin{minted}{bash}
    neighbor {indirizzo} filter-list {nome-lista} in
    bgp as-path access-list {nome-lista} permit {regexp}    
\end{minted}


Si possono configurare le \texttt{route-map} come:
\begin{minted}{bash}
    neighbor {indirizzo} route-map {nome-map} {in/out}
    route-map {nome-map} {permit/deny} {seq-number}
        match {proprietà annuncio}
        set   {opzione attributo}
\end{minted}
Si può effettuare un match su qualsiasi proprietà dell'annuncio, ed eventualmente con \texttt{set} si può modificare arbitrariamente l'annuncio, anche realizzando annunci non validi secondo BGP. Si può alterare completamente l'annuncio. 
Anche il \texttt{match} è opzionale, in questo caso si comporta come un filtro, applicando le operazioni della \texttt{set} a tutti i pacchetti. Pià \texttt{match} di fila si comportano come un or logico. 



È conveniente utilizzare delle \texttt{access-list} o \texttt{prefix-list} per realizzare operazioni su più indirizzi contemporaneamente
Le access list matchano il contenuto di tutti i prefissi possibili contenuti, con le prefix list si fanno match esatti per prefisso, mentre con access si matchano anche tutti i suoi sotto-prefissi. 

\subsubsection{Stub AS}

In un mercato di acquisto vendita, gli ISP salgono e scendono da provider a customer, in base alle loro richieste ed offerte. 
Questi accordi commerciali definiscono le connessioni peer-to-peer tra i vari provider. Queste vengono mantenute segrete dai provider, e per motivi politici ed economici possono cambiare. 
Si possono stimare studiando lo storico degli annunci BGP, cercando di capire i provider ai vari livelli di gerarchia, divisi in cinque livelli. 

C'è una sorta di grafo completo di AS che ricopre la rete con connessioni peer-to-peer. 

Nella gerarchia da partire da un certo livello non si ha la default, gli AS di più alto livello non hanno un upstream a cui consegnare tutto, sono loro l'upstream. Per determinare la default si considera un prefisso che non è annunciato in rete. Se non è annunciato allora facendo un traceroute su questo prefisso, che non ha macchine, si passa solo per la default, il primo router che invia una risposta che l'indirizzo non è raggiungibile si capisce che si è raggiunto un router senza la default, quindi appartiene ad un livello alto. 

Uno stub AS è una zona con un unico link con altri AS, ed a priori potrebbero non usare BGP, poiché comunicano con un solo provider. In queste condizioni generalmente si usa il routing statico in single peering. 

In questo gioco di ISP chi è in più tempo in esercizio ha un vantaggio, ed ha un numero di AS maggiore, ed è salito di più sulla gerarchia. 
Un AS con un numero basso è più vecchio di uno con numero elevato. 

Uno stub AS si configura anche senza una policy eBGP, queste rotte vengono considerate con il comando \texttt{network}. Si assume che tutti i prefissi vengano considerati da questi comandi, ma non verificano che la LAN indicata sia posseduta da questo AS, non è certificato. Questo può quindi essere annunciato ad un router di frontiera, bisogna verificarlo alla fonte con un certificato di proprietà, ma solo nel momento in cui si utilizza. Ma questi certificati possono essere duplicati e modificati, per modificare anche la distanza. 
Questo porta a problemi di sicurezza per BGP. 
\begin{minted}{bash}
    router bgp {id-stub}
    no bgp ebgp-requires-policy
    network {prefisso-stub}/{netmask-stub}
    neighbor {indirizzo-isp} remote-as {id-isp}
\end{minted}

I router di frontiera connessi con questi stub AS devono avere dei filtri e configurazioni di sicurezza, per garantire che riceve messaggi da indirizzi contenuti nel prefisso annunciato dallo stub AS, questo non può essere controllato automaticamente e si utilizzano dei filtri per realizzarlo. Disattivando l'opzione \texttt{bgp network import-check}, si possono annunciare anche rotte non presenti nel kernel, poiché definendo la rotta di default con \texttt{network}, questa non viene iniettata nel kernel. 
Si mostrano questi filtri, realizzando due prefix list \texttt{customerIn} per ali annunci in entrata proveniente dallo stub, e \texttt{defaultOut} per gli annunci in uscita dal provider, contenente la rotta di default. 
Si assegna la default per mostrare il funzionamento, ma ben pochi router possono avere questa configurazione con la default. 
\begin{minted}{bash}
    router bgp {id-isp}
    no bgp network import-check
    
    network {prefisso-isp}/{netmask-isp}
    network 0.0.0.0/0

    neighbor {indirizzo-stub} remote-as {id-stub}
    neighbor {indirizzo-stub} default-originate
    neighbor {indirizzo-stub} prefix-list customerIn in
    neighbor {indirizzo-stub} prefix-list defaultOut out

    ip prefix-list customerIn permit {prefisso-stub}/{netmask-stub}
    ip prefix-list defaultOut permit 0.0.0.0/0
\end{minted}

Una prefix list è composta da una serie di comandi permit e deny, con sottinteso \texttt{deny any} alla fine. Gli ultimi due comandi di configurazione filtrano il traffico per la LAN che è effettivamente presente. La default non viene annunciata direttamente verso il basso, poiché mostrerebbe nell'\texttt{as-path} i vari AS contenuti, e dato che si vogliono mantenere segreti, si propaga, identificandosi come origine del default. Nel momento in cui si propaga la default quindi si taglia l'\texttt{as-path}. 
Per rapporti di tipo commerciale questo è usato per non far conoscere da dove proviene. 

La rotta di default dovrebbe essere dichiarata alla radice della gerarchia, e propagata verso i livelli sottostanti, mentre i livelli intermedi non dovrebbero utilizzare il comando \texttt{network}, altrimenti i router preferirebbero la rotta generata localmente, e si rimuoverebbe la rotta annunciata da fuori. 
Il comando \texttt{default-originate} è un comando accessorio che non inserisce la default nella tabella locale del BGP, né nel kernel. Tuttavia se si ha la rotta di default, si comporta come se si abbia utilizzato il comando \texttt{network}, nascondendo l'\texttt{as-path}. 
Questo comando ha lo stesso effetto di \texttt{network} e può generare la default anche quando non viene usato il comando \texttt{network}, e quando è presente sovrascrive l'effetto di una default dichiarata localmente, sempre senza inserirla nel kernel, dato che le annuncia. Mentre nel cliente che le ha ricevute, vengono inserite nel kernel. 

Se un router intermedio perde il link all'upstream contenente la rotta di default, continua ad annunciare la rotta di default con \texttt{default-originate}, ma non può effettivamente instradare il traffico alla rotta adi default, poiché ha perso il collegamento. 


Il secondo comando per influenzare le policy è \texttt{route-map}, oltre ad essere è un filtro si comporta come modificatore, per esprimere una preferenza. 
La rotta di default viene trattata come ogni altra rotta se è generata da \texttt{network}, mentre con \texttt{default-originate} è trattata da un'altra \texttt{route-map}:
\begin{minted}{bash}
    neighbor {indirizzo} default-originate route-map {nome} in
\end{minted}

Non si possono attaccare due \texttt{route-map} ad uno stesso prefisso, come per le \texttt{prefix-list}. 


Con il comando \texttt{network} le policy sono applicate sulle route \texttt{in} e \texttt{out}, mentre applicando policy speciali su \texttt{default-originate}, si hanno anche le rotte specifiche per questa. 

\subsubsection{Stub AS Static}

In queste situazioni semplici potrebbe essere più conveniente configurare rotte statiche verso e dallo stub. È sufficiente una default statica che punta al provider come next hop, per cui non è necessario utilizzare BGP:
\begin{minted}{bash}
    route add default gw {indirizzo-isp}
\end{minted}
In questo modo non si lancia un protocollo di instradamento nel customer, almeno se non serve per comunicare con i suoi vicini interni. 

\subsubsection{Multi-Homed Stub AS}

Un altro tipo di AS si chiama \textit{multi-homed}, presente più link con uno o più provider. 
Per cui non si può filtrare direttamente il traffico, poiché uno dei due link potrebbe cadere. In generale questo avviene in grosse organizzazioni, che chiedono al provider che questi link viaggino per due strade fisiche diverse, in modo da non concentrare i guasti in una stessa zona geografica. 

Ma il fatto che possano guastarsi singolarmente implica che deve essere possibile utilizzare uno solo dei due per mantenere tutto il traffico. Quindi non si può usare una \texttt{prefix-list}, poiché vincolano il traffico ad un solo link, bisogna usare delle policy per effettuare load balancing o altre operazioni simili, quando i link sono verso lo stesso provider. 
Quando questi due link sono verso due provider diversi, è improbabile che uno sia il backup dell'altro, quindi si usano in parallelo, si vuole bilanciare il traffico verso i due, sia in entrata che in uscita. Nell'eventualità che un link cada, si vuole che il link verso l'altro provider regga tutto il resto del traffico. 
Inoltre, non si vuole che il provider lo stub come tramite per comunicare con l'altro provider connesso. Quindi non si vuole che gli annuncino vengono propagati dallo stub verso l'esterno, tramite speciali filtri per annunci che non devono realizzare dei percorsi. 
Questa è quindi una situazione più difficile. 



Lo stub è responsabile delle macchine offerta dall'ISP, questi due link possono essere realizzati da un singolo router, o due router, per mitigare i guasti del router. 
Tutto ciò che entra nello stub ha due modi per entrare nello stub, e quindi bisogna scegliere quale link usare. 
Se si usasse IGP, si sceglie quale link usare in base alla distanza e non si possono implementare policy, quindi è possibile che il traffico tra i due router dell'ISP passi attraverso questo router dello stub. 
Invece con rotte statiche non sarebbe possibile configurare tutto manualmente ed aggiornarlo in caso di eventuali guasti. 


Per gestirlo come primario e secondario si utilizza BGP, annunciando un prefisso aggregato su ogni link, il primario effettua l'annuncio normale, mentre il secondario aumenta la metrica negli annunci esterni, per ridurre la preferenza locale, secondo la gerarchia per la scelta delle best da parte di BGP. 
Se uno dei due link fallisce, l'annuncio del prefisso aggregato permette di mantenere la connessione tra provider e stub. 
Si può valutare rispetto alla metrica solo se l'annuncio arriva dallo stesso AS. 
In base a questi valori di MED, lo stub probabilmente sceglierà il primario con la metrica più bassa. 
Il customer assegna una preferenza minore al link di backup, questo influisce sugli annunci in entrata ed il traffico in uscita, preferendo link con valori maggiori. 

\begin{minted}{bash}
    router bgp {id-stub}
    
    neighbor {indirizzo-isp-primario} remote-as {id-isp}
    neighbor {indirizzo-isp-backup} remote-as {id-isp}    

    network {prefisso-stub}/{netmask-stub}
\end{minted}



Non si possono inserire due route map sullo stesso peering, o due prefix list. Il nome delle route map e delle prefix list è case sensitive, ed in caso sia sbagliato, nel loro utilizzo, non le applica. Per cui bisogna fare particolarmente attenzione al nome di queste etichette. 
\begin{minted}{bash}
    neighbor {indirizzo-isp-primario} prefix-list mineOutOnly out
    neighbor {indirizzo-isp-primario} prefix-list default in
    neighbor {indirizzo-isp-backup} prefix-list mineOutOnly out
    neighbor {indirizzo-isp-backup} route-map metriOut out
    neighbor {indirizzo-isp-backup} prefix-list defaultIn in
    neighbor {indirizzo-isp-backup} route-map localPrefIn in    
\end{minted}


Si usa una route map che fa uso di un aggregato che viene definito da un access list:
\begin{minted}{bash}
    access-list myAggregate permit {prefisso-stub}/{netmask-stub}

    ip prefix-list mineOutOnly permit {prefisso-stub}/{netmask-stub}
    ip prefix-list defaultIn permit{prefisso-stub}/{netmask-stub}
    
    route-map metricOut permit 10
    match ip address myAggregate
    set metric 10

    route-map localPrefIn permit 10
    set local-preference 90
\end{minted}


Verso il provider invia solo la propria LAN, mentre dal provider prende solo la default, quindi non può rimbalzarla, quindi non può essere utilizzato per farsi attraversare. 

Usando la route map \texttt{metricOut}, si inviano annunci uscenti verso il link di backup aumentano la metrica. 
Mentre usando la mappa \texttt{localPrefIn}, si diminuisce la preferenza locale in ingresso per il link di backup. 
Queste si attaccano sullo stesso peering sullo stesso link di backup. 


Tutti questi scenari sono configurati in modo sia determinabile con quale interfaccia si sita facendo peering. 


Si rappresenta ora un laboratorio più grande sommando le varie tecnologie trattate in precedenza. 
Questo lab è composto da tre AS: AS20, AS100, e AS200, quest'ultimi sono due stub, ovvero non hanno a loro volta customer. 
%% TODO add img bgp-multi-homed-stub-large

Viene usato RIP sia in AS20 che in AS100, bisognerebbe configurare RIP in questi due AS, in AS20 è semplice avendo due router, mentre in AS100 con tre router, RIP ha uno scopo molto più forte. 
Questi router vengono configurati con RIP e per distribuire le rotte annunciate da BGP, con RIP:
\begin{minted}{bash}
    router rip
    network {prefisso}/{netmask}
    redistribute bgp    
\end{minted}
Questo per i router di frontiera, per i router interni che non devono parlare BGP si ha invece:
\begin{minted}{bash}
    router rip
    network {prefisso}/{netmask}
    redistribute connected    
\end{minted}

Bisogna ignorare il \texttt{network import-check}, poiché si usano dei prefissi aggregati per gli indirizzi delle connessioni, e quindi non sono presenti nella tabella di instradamento. 
Uno dei due peering viene definito primario, e l'altro secondario, tra i router di AS20. Si ha una politica semplice per il neighbor primario ed una più complessa per il neighbor secondario. 
\begin{minted}{bash}
    debug bgp keepalives
    debug bgp updates in
    debug bgp updates out

    router bgp 100
    no bgp network import-check 

    neighbor {indirizzo-isp-primario} remote-as 20
    neighbor {indirizzo-isp-backup} remote-as 20
\end{minted}

Si vuole evitare che il traffico per un link diretto a AS100 rimbalzi e ritorni ad AS20:
\begin{minted}{bash}
    neighbor {indirizzo-isp-primario} prefix-list mineOutOnly out
    neighbor {indirizzo-isp-backup} prefix-list mineOutOnly out

    ip prefix-list mineOutOnly permit {prefisso-stub}/{netmask-stub}
\end{minted}

Poiché le tabelle di instradamento possono essere di elevate dimensioni, per AS piccoli è conveniente avere un unica rotta di default in entrata ai router di frontiera, per delegare l'instradamento esclusivamente ai router superiori. Questo si effettua creando un'altra prefix list in entrata:
\begin{minted}{bash}
    neighbor {indirizzo-isp-primario} prefix-list defaultIn in
    neighbor {indirizzo-isp-backup} prefix-list defaultIn in

    ip prefix-list defaultIn permit 0.0.0.0/0
\end{minted}

Per impostare i link primari e secondari bisogna impostare la MED e la preferenza locale del link scelto come secondario. 
La default che arriva dal link primario si vuole preferire, quindi la local preference in arrivo sul link primario deve essere più alta. Si potrebbe alzare, oppure, come in questo caso, si diminuisce nel link di backup. Il default è 100. 
\begin{minted}{bash}
    neighbor {indirizzo-isp-backup} route-map localPrefIn in

    route-map localPrefIn permit 10
    set local-preference 90
\end{minted}

Gli annunci in uscita invece devono passare esclusivamente sul link primario, quindi bisogna modificare la scelta che faranno i router dell'AS superiore, per preferire il link primario. Questo si effettua modificando la MED, diminuendo la MED del link primario o aumentando la MED del link secondario. Il default è 0. Questa si inserisce solo sugli annunci sugli indirizzi della propria LAN. 
\begin{minted}{bash}
    neighbor {indirizzo-isp-backup} route-map metricOut out
    access-list myAggregate permit {prefisso-stub}/{netmask-stub}
    
    route-map metricOut permit 10
    match ip address myAggregate
    set metric 10
\end{minted}
BGP spesso su configurazioni realistiche ha una serie di controlli ulteriori per evitare errori di tipo fat finger. 


L'unico router di AS200 deve avere la flag disattivata di \texttt{ebgp-requires-policy}, per permettere alle rotte annunciate da BGP di essere inserite come fossero definite da \texttt{network}. 
I peering iBGP sono obbligatori, altrimenti BGP non funziona, mentre i peering eBGP sono opzionali, in full mesh, ovvero se sono presenti tre router, bisogna realizzare tre link, tutti connessi con tutti, con un albero ricoprente completo. 

I router di AS20 hanno quindi peering tra di loro ed anche con i router di frontiera dei router stub. Si considera il router connesso sia ad AS100 che AS200:
\begin{minted}{bash}
    router bgp 20
    no bgp network import-check 

    neighbor {indirizzo-stub-as100} remote-as 100
    neighbor {indirizzo-stub-as200} remote-as 200
    neighbor {indirizzo-as20} remote-as 20
\end{minted}
Questi router devono dichiarare le LAN interne, e le LAN di peering. Queste nella vita reale non vengono mai annunciate, poiché potrebbe essere possibile tagliare la connessione tra due router BGP, poiché viaggia su TCP, sarebbe possibile tagliarlo con tcp-reset. Per motivi di sicurezza le LAN di peering non sono annunciate, sono solo disponibili direttamente connesse. 
\begin{minted}{bash}
    network {LAN-as20}
    network {LAN-peering-as100}
    network {LAN-peering-as200}
    network 0.0.0.0/0
\end{minted}

Si definiscono le liste di prefissi per poter annunciare permettere alle LAN stub di poter annunciare solo i loro prefissi:
\begin{minted}{bash}
    neighbor {indirizzo-as200} default-originate
    neighbor {indirizzo-as200} prefix-list as200In in
    neighbor {indirizzo-as200} prefix-list defaultOut out
    neighbor {indirizzo-as100} default-originate
    neighbor {indirizzo-as100} prefix-list as100In in
    neighbor {indirizzo-as100} prefix-list defaultOut out
    
    ip prefix-list as200In permit {LAN-as200}
    ip prefix-list as100In permit {LAN-as100}
    ip prefix-list defaultOut permit 0.0.0.0/0
\end{minted}
Poiché annuncia la rotta di default deve disabilitare il controllo sulle rotte del kernel. 

Con \texttt{sh ip bgp} in \texttt{vtysh} si possono vedere le rotte inserite, quelle denotate con \texttt{i} sono interne, quindi annunciate da router interni alla LAN. Questi prefissi sono arrivati da iBGP, mentre se il campo path ha una \texttt{i} l'attributo origin del pacchetto è igp. 
Le rotte indicate da \texttt{>} sono quelle installate nel kernel, come preferite. Il campo local preference se è vuoto ha il valore di default, ma non era contenuto nel pacchetto di annuncio. 

% BGP internamente lavora come un ASF, e può scambiare prefissi quando si trova in un certo stato, nel summary di bgp mostra quanti prefissi ottiene da uno stato

%% !! BGP: MULTI-HOMED

Per resistere ai guasti un AS stub potrebbe usare due provider contemporaneamente, potendoli usare come primario e backup, oppure in modo più complesso con load balancing. 

Per impostare i due link in entrata si usa la local preference, mentre per gli annunci in uscita dallo stub, non si può usare la MED, poiché si utilizza solamente quando due link partono dallo stesso AS. 
Generalmente questi due link si realizzano su due router diversi, altrimenti si introduce nuovamente un single point of failure. 

Si vuole evitare la situazione dove un pacchetto rimbalza e attraversa il customer per passare tra i due provider, analogamente si vuole evitare che un pacchetto per passare tra due host dell'AS stub passi attraverso i due provider. 

Per gestire questi due link si considera l'idea del load sharing, una policy del tipo active-active, tenendo accesi entrambi i link, poiché essendo provenienti da provider diversi vengono pagati entrambi sempre. 
In questo modo si inoltra il traffico sui due link. 
Si potrebbe realizzare dividendo la LAN in due, ed attribuendo queste metà ai due link, senza avere un hardware apposito non è possibile realizzare una divisione accurata. Questa divisione si effettua solo su BGP. 
Data una /$n$, si ottengono due /$n+1$ annunciate sui due link. La prima metà passa per il primo link, e la seconda metà passa per il secondo link. Inoltre si manda la /$n$ su entrambi, meno specifica quindi non viene usata per instradare, nel momento in cui una delle /$n+1$ non viene tagliata la /$n$ che aggrega tutto si prende il traffico e quindi si ottiene piena connettività. 


Si considera un laboratorio con un AS radice AS1, con due AS di transito AS30 e AS40, entrambi servono l'AS stub AS300. 

I router di AS300 devono avere in uscita solamente le proprie LAN, ed in entrata solo l'AS30 o l'AS40. 
Entrambi questi router di frontiera annunciano la propria metà /$n+1$ ed il prefisso aggregato /$n$:
\begin{minted}{bash}
    neighbor {indirizzo-as30/as40} prefix-list mineOutOnly out
    neighbor {indirizzo-as30/as40} prefix-list defaultIn in

    ip prefix-list mineOutOnly permit {prefisso-n}/{n}
    ip prefix-list mineOutOnly permit {prefisso-n+1}/{n+1}
    ip prefix-list defaultIn permit 0.0.0.0/0
\end{minted}
Applicando queste politiche su entrambi i router di frontiera, nel momento in cui cade uno di questi due link, l'altro link ed il rispettivo provider si prende il carico del traffico totale. 

I router interni ad AS300 non usano BGP, usano solamente RIP, e dato che parlando direttamente sul prefisso /$n$, non sono necessari ridistribuzioni del kernel, con \texttt{redistribute connected}. 

Avendo due router BGP è necessario un peering iBGP, ma in questo caso non è presente, poiché è necessario un pezzo di BGP ancora da trattare, che gestisce race condition, in questi casi potrebbe creare problemi, in situazioni come questa vengono specificato in maniera chiara. 


Per i router di transito verso l'alto, in uscita, non vengono inserite politiche, solo un filtro in ingresso, per comunicare direttamente tutto quello che gli passa il customer. Manda verso l'alto tutti i prefissi propri, ed i prefissi ottenuti dai propri customer. 

\subsubsection{Pitfalls}

Per ogni neighbor, per applicare comportamenti complessi bisogna utilizzare una sola route map o prefix list, poiché dichiarazioni successive sullo stesso neighbor sovrascrivono le precedenti. 
Alcuni software di router BGP permettono di scrivere codice, con la stessa flessibilità di un linguaggio di programmazione, FRR è flessibile, ma non è Turing completo, senza l'utilizzo di cicli. 

FRR non genera errori, silenziosamente sovrascrive la prima configurazione con la seconda. 
Per vedere quale configurazione si sta utilizzando, si utilizza il comando \texttt{show running-config}, nella shell \texttt{vtysh}. 


Le liste di prefissi si attaccano ad un neighbor, si possono agganciare in ingresso o in uscita. Vanno attaccate, e poi vanno definite. Non si possono definire in mezzo alle righe di neighbor, altrimenti si perdono, poiché si esce dalla parte di router BGP. 
Guardando la configurazione da \texttt{vtysh} vengono espresse in modo esplicito le \texttt{exit}, quindi si notano questi fallimenti totalmente nascosti, scartando le righe successive. 

L'indentazione è pura estetica, viene usata solo per migliorare la leggibilità. Cià che conta è l'ordine dei comandi. 
Prima bisogna dichiarare un neighbor, e poi vengono modificati i vari campi. 

I comandi \texttt{network} devono essere inseriti dentro BGP, quindi prima di comandi per le access list e prefix list. 
La prefix list può essere composta da più statement, che hanno ciascuno un sequence number:
\begin{minted}{bash}
    ip prefix-list {nome} seq {numero} permit {prefisso}/{netmask}
\end{minted}
Questi statement vengono eseguiti in base al sequenze number. 



Prefix list si usa per matchare prefissi esatti, per identificare indirizzi più specifici si usano le access list. Una prefix list negativa si realizza con un deny seguito dai prefissi da rifiutare, seguita da un \texttt{permit any}, altrimenti rifiuterebbe tutti gli indirizzi della lista, avendo un \texttt{deny any} implicito finale. 
Il primo prefisso matchato fa uscire dalla prefix list. 
Se si attacca ad un neighbor una prefix list che non esiste, automaticamente si ha un \texttt{deny any}, come implicito finale. 


Una route map può avere zero o più azioni di match, e zero o più azioni di set. Analogamente alle prefix list hanno un numero di sequenza, il primo matchato esce dalla sequenza. 

Una route map con un solo match è implicitamente un filtro, senza un secondo blocco di route map che non match niente, ha un \texttt{deny any} implicito. 

Se già si è inserita con un sequence number più basso una che fa un match con tutti gli indirizzi, effettivamente non filtra niente. 


Condizioni tipiche di set sono \texttt{prepend}, per aggiungere in modo virtuale lo stesso numero di AS nell'as path, tuttavia è possibile inserire AS fittizi nell'AS path, e gli annunci potrebbero avere le loro conseguenze. 


Tutte le match sono in and logico tra di loro, tuttavia più condizioni sullo stesso oggetto risultano in un or logico, per esempio matchando una tra più prefix list. 


Si usano le access list anche per matchare le rotte più specifiche, si può scrivere sulle access list \texttt{exact-math} per avere un match esatto dei prefissi. 

\subsubsection{Transit AS}

Un AS di transito si occupa di propagare tutti gli annunci ed il traffico ad altri AS. 
Si può distribuire la tabella di instradamento BGP sul protocollo IGP, ma questo causa un aumento delle dimensioni delle tabelle IGP, e gli aggiornamenti di BGP hanno ripercussioni anche su IGP. 
Si può realizzare incapsulando il traffico in altri pacchetti, creando un tunnel, che comunica solamente tra i router di frontiera, oppure senza usare link intermedi, quindi avendo un link diretto tra i router di frontiera. 


Avendo un AS di transito, ci sono degli AS periferici con cui comunica, attraverso i router di frontiera. 
Se viene distribuito BGP dentro IGP, i router di frontiera si comportano come magneti poiché si comportano come destinazione delle rotte che distribuiscono ed attraggono tutto il traffico verso quelle rotte. È possibile che un router di frontiera quando propaga le rotte su IGP il router next hop punti al router di frontiera che ha inviato il pacchetto, provocando un ciclo. 

Può essere che le macchine non distribuiscano quello che hanno appresso con eBGP e non iBGP, tuttavia non esiste il comando per propagare eBGP, ma per iBGP. 
Di default per una macchina CISCO la propagazione di iBGP è disattivata. 


Per distribuire solo eBGP, evitando il problema dei rimbalzi, si crea una route map che permette solo rotte avendo come next hop le altre LAN di peering:
\begin{minted}{bash}
    ip prefix-list myNeighbors permit {peering-LAN} le 32
    route-map eBGP permit 10
        match ip next-hop prefix-list myNeighbors
    router rip 
        network {LAN}
        redistribute connected
        redistribute bgp route-map eBGP
\end{minted}


% Usando MPLS si riesce ad attraversare
% soluzione per realizzare questi tunnel, crea un link diretto virtuale tra i router di frontiera. -> non c'è più il problema del rimbalzo. 

Quando si usano interfacce di loopback per gli indirizzi di peering BGP su un AS, bisogna settare il next hop come self, in modo da poter realizzare recursive lookup sull'indirizzo della macchina. In questo modo la connessione TCP rimane attiva nonostante la topologia della rete AS sottostante possa cambiare. 

\subsection{WebServer}

Utilizzare un oggetto di livello applicativo è molto utile, poiché è molto più semplice testare regole BGP su oggetti di livello applicativo. 
In questo corso si vedranno dal punto di vista applicativo i WebServer, e verranno utilizzati per simulare dei servizi all'interno del datacenter. 

Il server di default è \texttt{apache2}, il client usa \texttt{links}, un browser da linea di comando. Per avviare il webserver, si avvia il servizio di Apache con:
\begin{minted}{bash}
    systemctl start apache2
\end{minted}

Una macchina webserver non è un router, solitamente, quindi non ha bisogno di un demon di routing in esecuzione, quindi ha bisogno di avere una tabella di instradamento popolata. Ha bisogno del default gateway. 
Si inserisce la pagina HTML su \texttt{/var/www/html/index.html}, sovrascrivendo la pagina di default di Apache. È sufficiente inserire testo per distinguere un webserver da un altro:
\begin{minted}{html}
    <html>
        <body>
            <h1>Hello!</h1>
        </body>
    </html>
\end{minted}
Questo è necessario per valutare i load balancer per differenziare su quale server si è stati indirizzati. 

Si possono monitorare gli accessi al webserver con:
\begin{minted}{bash}
    tail -f /var/log/apache2/access.log
\end{minted}
Inoltre, si può controllare il file \texttt{error.log} sulla stessa directory. 
Si può osservare la configurazione con \texttt{apache2 -l}. 

Apache è estremamente configurabile con file \texttt{.htaccess}, ma proprio per questo è molto più lento di Ngnix. Poiché Apache controlla su ogni directory se è presente questo file, fino alla radice del filesystem, mentre su Ngnix il file di configurazione è unico. 



\end{document}